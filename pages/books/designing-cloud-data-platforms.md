# Designing Cloud Data Platforms

## 1 - Introducing the data platform

- Les **analytics** permettent essentiellement d’obtenir des métriques pour faire des choix business.
  - Avant l’avènement des ordinateurs, les entreprises utilisaient des moyens manuels, et leur intuition.
  - Dans les années 80 on a vu émerger le concept de data warehouse, qui est une base centralisée de données venant de diverses sources.
- Les **data warehouses** posent de plus en plus de **problèmes** de nos jours.
  - Les tendances suivantes y contribuent :
    - Les données sont issues de sources de diverses nature, y compris certaines d’entre-elles non structurées, et leur volume est de plus en plus important.
    - Le découpage des applications en microservices fait que collecter des données revient forcément à devoir agréger de multiples sources.
    - Les data scientists ont aussi besoin d’accéder à une version brute de la donnée, et cet usage ne peut pas passer par un data warehouse.
  - Elles ont du mal avec les **3V** (Variety, Volume, Velocity).
    - **Variety** : les data warehouses ne supportent que les _structured data_ dont le schéma est stable, c’est-à-dire en pratique qui sont issues de DB relationnelles.
      - Or avec l’avènement des SaaS, des réseaux sociaux, et de l’IoT, on se retrouve avec :
        - Des _semistructured data_ du type JSON, Avro etc, dont le schéma varie souvent.
        - Des _unstructured data_ comme le binaire, le son, la vidéo.
    - **Volume** : le fait que dans un data warehouse, la puissance de calcul et le stockage doivent se trouver sur **la même machine physique**, implique qu’on ne peut pas scaler les deux séparément, et donc les coûts explosent.
      - Même les petites organisations peuvent être amenées à traiter plusieurs TB de données.
    - **Velocity** : les data warehouses ne sont pas adaptées aux analytics en mode real time, elles sont plus orientées batch processing.
    - Le machine learning en particulier pose tous les problèmes en même temps : il nécessite une grande quantité de données variées, et accapare la puissance de calcul du data warehouse.
- Les **data lakes** répondent en partie à ces problèmes.
  - L’idée principale des data lakes c’est qu’on **stocke de la donnée telle quelle** (ou quasi), et qu’on essayera de la traiter et de lui coller un schéma dès qu’on en aura besoin.
  - Les data lakes se sont généralisés à partir de 2006 avec l’arrivée de **Hadoop**, qui est un **filesystem distribué sur plusieurs machines** pas chères.
    - Hadoop répond en partie aux 3V :
      - A la _Variety_ par l’écriture schema-less.
      - Au _Volume_ par le fait que ce soit distribué sur des machines pas chères.
      - A la _Velocity_ par la facilité de streaming à partir du filesystem distribué.
    - Mais il a aussi des problèmes :
      - C’est un système complexe qu’il faut installer sur un datacenter et gérer par des Ops expérimentés.
      - D’un point de vue business, c’est plus difficile de travailler avec les outils qui traitent les données non structurées qu’avec du SQL comme dans un data warehouse.
      - Bien qu’il soit distribué sur de petites machines pas chères, le computing et le stockage ne sont pas séparés, ce qui limite quand même la réduction de coût quand on a besoin de beaucoup de l’un sans l’autre.
  - Le **cloud public** vient répondre aux problèmes de Hadoop.
    - Les data warehouses et les data lakes ont été proposés par les cloud providers, avec de nombreux avantages :
      - La possibilité de scaler la puissance de calcul et le stockage séparément.
      - Payer uniquement à l’usage des machines qu’on emprunte.
      - Ne plus avoir à gérer la complexité de l’infrastructure.
      - Des outils et frameworks avancés développés par les cloud providers autour de leurs produits.
    - Exemple : **AWS EMR** permet de lancer un cluster sur lequel on va pouvoir exécuter des jobs **Hadoop** et **Spark**,
      - On a juste à indiquer le nombre de nœuds qu’on veut, et les packages qu’on veut installer dessus.
      - Et on a la possibilité de faire des allers-retours vers **S3** pour scaler différemment le calcul et le stockage.
- La **cloud data platform** moderne utilise à la fois le data warehouse et le data lake, hébergés dans un cloud public, chacun d’entre eux remplissant un usage particulier.
  - Pour être polyvalente et pas chère, la data platform doit avoir des **4 composants principaux faiblement couplés**, interagissant entre-eux avec une API bien définie.
    - **Ingestion layer** : on va chercher les données chez les différents types de sources (DB relationnelle, DB NoSQL, API externes etc.).
      - On va en général utiliser un ensemble d’outils open source ou commerciaux pour chaque type de données à aller chercher.
      - Il ne faut **surtout pas altérer la donnée à cette étape**, pour que la donnée brute soit disponible pour les data scientists qui en auraient l’usage.
    - **Storage layer** : on utilise le stockage cloud comme stockage de notre _data lake_, dans lequel on met ce qu’on a ingéré.
      - Le stockage cloud a l’avantage de ne pas avoir besoin de planifier la capacité de stockage : il grossit automatiquement au besoin.
    - **Processing layer** : on transforme la donnée pour la rendre utilisable par la plupart des clients de la plateforme.
      - C’est la partie calcul de notre _data lake_, il va lire depuis le cloud storage puis écrire à nouveau dedans.
      - Dans le cas du **streaming**, on ne passe pas par le storage layer qui prend trop de temps, mais on envoie la donnée **directement au processing layer**, qui va ensuite la rendre disponible au layer d’après.
      - Le processing est généralement fait avec des outils open source, les plus connus étant **Spark**, **Beam** et **Flink**.
    - **Serving layer** : on rend la donnée disponible sous divers formats, selon les besoins des clients de la plateforme.
      - Les usages peuvent être :
        - Des analystes qui ont besoin d’exécuter des requêtes SQL sur la donnée.
          - On peut charger la donnée dans un _data warehouse_ chez le cloud provider.
        - Des applications qui ont besoin d’un accès rapide à la donnée.
          - On peut la charger dans une key / value DB, ou une document DB.
        - Des équipes de data scientists / engineers ont besoin de transformer la donnée eux-mêmes.
          - On peut leur donner accès au storage du _data lake_, et les laisser utiliser **Spark**, **Beam** ou **Flink**.
  - La cloud data platform répond aux 3V :
    - L’ingestion layer couplé au stockage sans schéma permet une grande _Variety_ des données.
    - La séparation calcul / stockage et le fait de ne payer que ce qu’on utilise permet d’optimiser les coûts, et d’avoir un gros _Volume_.
    - La possibilité d’envoyer directement au _processing layer_ permet de la _Velocity_.
    - On peut aussi prendre en compte deux autres V :
      - La _Veracity_ qui indique le niveau de _data governance_, c’est-à-dire la qualité de la donnée. On l’obtient itérativement, au cours d’étapes au sein du data lake.
      - Et la _Value_ qu’on peut tirer de la donnée, qui peut être plus élevée si on prend plus de données en amont de notre processus de nettoyage.
- Il faut comprendre les **cas d’usages principaux** d’un _data lake_, pour éviter de le transformer en _data swamp_.
  - Parmi les plus courants il y a la **vue 360° des clients**, où il s’agit de récupérer toutes les données d’interaction avec eux, pour proposer ensuite des services plus personnalisés, vendre plus etc.
  - Il y a aussi les **données venant d’IoT**, qui ont la particularité d’être incertaines et d’avoir un gros volume, ce qui rend l’utilisation du _data warehouse_ peu intéressante.
  - Et enfin il y a le **machine learning** qui a besoin d’une très grande quantité de données, et qui tire avantage de puissance de calcul séparée des autres use-cases grâce au _data lake_.

## 2 - Why a data platform and not just a data warehouse

- Ce chapitre donne des **arguments pour le choix d’une _cloud data platform_, plutôt qu’une simple _data warehouse_**.
- On implémente les deux solutions pour une situation d’**exemple** qu’on va utiliser dans ce chapitre :
  - Nous sommes l’équipe data, et le département marketing a besoin que nous récupérions deux sources de données et qu’on les corrèle régulièrement.
    - L’une des sources est une table de campagnes de marketing, issue d’une DB MySQL interne.
    - Et l’autre est constituée de fichiers CSV de clics utilisateurs, issus de logs applicatifs (et donc _semistructured_).
  - On part sur Microsoft Azure pour les deux solutions.
  - Concernant l’implémentation _data warehouse only_ :
    - 1 - On va utiliser deux **Azure Data Factory** pour récupérer la donnée dans le serveur de DB et dans les fichiers CSV dans le serveur SFTP. C’est notre _ingest layer_.
    - 2 - Ensuite on redirige ça vers l’**Azure Synapse**, qui est la data warehouse de chez Azure. Elle va faire office de _store layer_, _process layer_ et _serve layer_.
  - Concernant l’implémentation _cloud data platform_ :
    - 1 - On a notre _ingest layer_ avec **Azure Data Factory**, qui redirige les données vers le _store layer_.
    - 2 - Le _store layer_ est implémenté avec **Azure Blob Storage**. Il s’agit d’un stockage de type _data lake_.
    - 3 - On a un _process layer_ qui utilise **Azure Databricks**, et qui fait tourner **Spark**.
    - 4 - Le _serve layer_ utilise enfin **Azure Synapse** qui est le data warehouse.
- Concernant l’**ingestion**.
  - Pour la version _data warehouse only_ :
    - La pipeline contient :
      - Des _linked services_ : ici la _data source_ MySQL en entrée, et la _data sink_ **Azure Synapse** en sortie.
      - Des _data sets_ : il s’agit de la description du schéma de données d’entrée et de sortie, et leur mapping.
    - Si le schéma de la DB source change, il faudra mettre à jour le schéma défini dans la pipeline et le mapping.
      - Mais surtout il faudra **gérer soi-même la migration** du _data sink_.
  - Pour la version _cloud data platform_ :
    - Cette fois le _data sink_ est un **Azure Blob Storage**.
      - Il n’y a plus besoin de spécifier les schémas et le mapping entre input et output puisque l’output accueille la donnée telle quelle.
    - Si le schéma de la DB source change, il n’y a **rien à faire côté ingestion** : on écrira de toute façon la donnée dans un nouveau fichier.
      - On déplace le problème de mapping plus loin.
- Concernant le **processing**.
  - Dans la version _data warehouse only_ :
    - On va charger les deux données :
      - La DB MySQL sans charger sa structure parce qu’elle est déjà relationnelle.
      - La donnée CSV semistructurée dans des rows de type texte qu’on parsera en JSON avec une fonction SQL built-in.
    - La **requête SQL** qu’on va écrire aura les désavantages suivants :
      - Elle sera **peu lisible**, à cause du code de parsing nécessaire.
        - On pourrait la rendre plus lisible en pré-parsant la donnée, mais ça veut dire plus de temps et des coûts plus élevés.
        - Une autre solution de lisibilité pourrait être d’ajouter des UDF (User Defined Functions), qu’il faudrait maintenir et déployer sur chaque instance d’**Azure Synapse**.
      - Elle sera **difficile à tester**.
      - Elle risque de ne pas profiter de la **performance** offerte par la structure en colonne du data warehouse, parce que les données texte qu’on parse en JSON ne sont pas organisables physiquement en colonnes.
  - Dans la version _cloud data platform_ :
    - On a la possibilité d’utiliser un _distributed data processing engine_ comme **Apache Spark**.
      - On pourra écrire des requêtes SQL pour des expérimentations rapides.
      - Et on pourra aussi écrire du code **lisible, maintenable et testable** dans un langage comme Python ou Scala, quand il s’agit de projet de plus long terme.
- Concernant l’**accès à la donnée**.
  - Il peut y avoir plusieurs types de consommateurs :
    - Des utilisateurs plutôt **orientés business** comme des équipes marketing.
      - Ils vont préférer utiliser des outils de reporting type **Power BI**, et donc auront besoin de la donnée sous forme relationnelle, par exemple dans **Azure Synapse**.
    - Des utilisateurs orientés **data analyse / data science**.
      - Ils pourront bénéficier de SQL qu’ils utilisent souvent directement, au travers de **Spark SQL**.
      - Ils pourront avoir accès à des données non filtrées pour leur projets data science, grâce **Spark** directement.
    - Au final la _cloud data platform_, qui contient à la fois la donnée sous forme brute dans le _data lake_, et la donnée dans le _data warehouse_, est **adaptée à chaque usage**.
- A propos des **coûts financiers**.
  - Il est difficile de comparer les coûts des services cloud.
    - En général on constate que le stockage est plutôt pas cher, et que l’essentiel des coûts se trouve dans les calculs.
  - L’**elastic scaling** consiste à pouvoir calibrer le service pour l’usage exact qu’on en a, et de ne pas avoir à payer plus.
    - C’est un des éléments qui permet de vraiment optimiser les coûts.
  - Pour la version _data warehouse only_, l’essentiel des coûts va aller dans **Azure Synapse**.
    - Le scaling de ce service peut prendre des dizaines de minutes, donc c’est quelque chose qu’on ne peut faire que de temps en temps.
  - Pour la version _cloud data platform_, l’essentiel des coûts est porté par le _processing layer_, par exemple **Spark**.
    - **Spark** est particulièrement élastique, au point où il est commun de démarrer une instance juste le temps d’une requête.
