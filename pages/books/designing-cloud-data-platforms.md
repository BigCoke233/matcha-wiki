# Designing Cloud Data Platforms

## 1 - Introducing the data platform

- Les **analytics** permettent essentiellement d’obtenir des métriques pour faire des choix business.
  - Avant l’avènement des ordinateurs, les entreprises utilisaient des moyens manuels, et leur intuition.
  - Dans les années 80 on a vu émerger le concept de data warehouse, qui est une base centralisée de données venant de diverses sources.
- Les **data warehouses** posent de plus en plus de **problèmes** de nos jours.
  - Les tendances suivantes y contribuent :
    - Les données sont issues de sources de diverses nature, y compris certaines d’entre-elles non structurées, et leur volume est de plus en plus important.
    - Le découpage des applications en microservices fait que collecter des données revient forcément à devoir agréger de multiples sources.
    - Les data scientists ont aussi besoin d’accéder à une version brute de la donnée, et cet usage ne peut pas passer par un data warehouse.
  - Elles ont du mal avec les **3V** (Variety, Volume, Velocity).
    - **Variety** : les data warehouses ne supportent que les _structured data_ dont le schéma est stable, c’est-à-dire en pratique qui sont issues de DB relationnelles.
      - Or avec l’avènement des SaaS, des réseaux sociaux, et de l’IoT, on se retrouve avec :
        - Des _semistructured data_ du type JSON, Avro etc, dont le schéma varie souvent.
        - Des _unstructured data_ comme le binaire, le son, la vidéo.
    - **Volume** : le fait que dans un data warehouse, la puissance de calcul et le stockage doivent se trouver sur **la même machine physique**, implique qu’on ne peut pas scaler les deux séparément, et donc les coûts explosent.
      - Même les petites organisations peuvent être amenées à traiter plusieurs TB de données.
    - **Velocity** : les data warehouses ne sont pas adaptées aux analytics en mode real time, elles sont plus orientées batch processing.
    - Le machine learning en particulier pose tous les problèmes en même temps : il nécessite une grande quantité de données variées, et accapare la puissance de calcul du data warehouse.
- Les **data lakes** répondent en partie à ces problèmes.
  - L’idée principale des data lakes c’est qu’on **stocke de la donnée telle quelle** (ou quasi), et qu’on essayera de la traiter et de lui coller un schéma dès qu’on en aura besoin.
  - Les data lakes se sont généralisés à partir de 2006 avec l’arrivée de **Hadoop**, qui est un **filesystem distribué sur plusieurs machines** pas chères.
    - Hadoop répond en partie aux 3V :
      - A la _Variety_ par l’écriture schema-less.
      - Au _Volume_ par le fait que ce soit distribué sur des machines pas chères.
      - A la _Velocity_ par la facilité de streaming à partir du filesystem distribué.
    - Mais il a aussi des problèmes :
      - C’est un système complexe qu’il faut installer sur un datacenter et gérer par des Ops expérimentés.
      - D’un point de vue business, c’est plus difficile de travailler avec les outils qui traitent les données non structurées qu’avec du SQL comme dans un data warehouse.
      - Bien qu’il soit distribué sur de petites machines pas chères, le computing et le stockage ne sont pas séparés, ce qui limite quand même la réduction de coût quand on a besoin de beaucoup de l’un sans l’autre.
  - Le **cloud public** vient répondre aux problèmes de Hadoop.
    - Les data warehouses et les data lakes ont été proposés par les cloud providers, avec de nombreux avantages :
      - La possibilité de scaler la puissance de calcul et le stockage séparément.
      - Payer uniquement à l’usage des machines qu’on emprunte.
      - Ne plus avoir à gérer la complexité de l’infrastructure.
      - Des outils et frameworks avancés développés par les cloud providers autour de leurs produits.
    - Exemple : **AWS EMR** permet de lancer un cluster sur lequel on va pouvoir exécuter des jobs **Hadoop** et **Spark**,
      - On a juste à indiquer le nombre de nœuds qu’on veut, et les packages qu’on veut installer dessus.
      - Et on a la possibilité de faire des allers-retours vers **S3** pour scaler différemment le calcul et le stockage.
- La **cloud data platform** moderne utilise à la fois le data warehouse et le data lake, hébergés dans un cloud public, chacun d’entre eux remplissant un usage particulier.
  - Pour être polyvalente et pas chère, la data platform doit avoir des **4 composants principaux faiblement couplés**, interagissant entre-eux avec une API bien définie.
    - **Ingestion layer** : on va chercher les données chez les différents types de sources (DB relationnelle, DB NoSQL, API externes etc.).
      - On va en général utiliser un ensemble d’outils open source ou commerciaux pour chaque type de données à aller chercher.
      - Il ne faut **surtout pas altérer la donnée à cette étape**, pour que la donnée brute soit disponible pour les data scientists qui en auraient l’usage.
    - **Storage layer** : on utilise le stockage cloud comme stockage de notre _data lake_, dans lequel on met ce qu’on a ingéré.
      - Le stockage cloud a l’avantage de ne pas avoir besoin de planifier la capacité de stockage : il grossit automatiquement au besoin.
    - **Processing layer** : on transforme la donnée pour la rendre utilisable par la plupart des clients de la plateforme.
      - C’est la partie calcul de notre _data lake_, il va lire depuis le cloud storage puis écrire à nouveau dedans.
      - Dans le cas du **streaming**, on ne passe pas par le storage layer qui prend trop de temps, mais on envoie la donnée **directement au processing layer**, qui va ensuite la rendre disponible au layer d’après.
      - Le processing est généralement fait avec des outils open source, les plus connus étant **Spark**, **Beam** et **Flink**.
    - **Serving layer** : on rend la donnée disponible sous divers formats, selon les besoins des clients de la plateforme.
      - Les usages peuvent être :
        - Des analystes qui ont besoin d’exécuter des requêtes SQL sur la donnée.
          - On peut charger la donnée dans un _data warehouse_ chez le cloud provider.
        - Des applications qui ont besoin d’un accès rapide à la donnée.
          - On peut la charger dans une key / value DB, ou une document DB.
        - Des équipes de data scientists / engineers ont besoin de transformer la donnée eux-mêmes.
          - On peut leur donner accès au storage du _data lake_, et les laisser utiliser **Spark**, **Beam** ou **Flink**.
  - La cloud data platform répond aux 3V :
    - L’ingestion layer couplé au stockage sans schéma permet une grande _Variety_ des données.
    - La séparation calcul / stockage et le fait de ne payer que ce qu’on utilise permet d’optimiser les coûts, et d’avoir un gros _Volume_.
    - La possibilité d’envoyer directement au _processing layer_ permet de la _Velocity_.
    - On peut aussi prendre en compte deux autres V :
      - La _Veracity_ qui indique le niveau de _data governance_, c’est-à-dire la qualité de la donnée. On l’obtient itérativement, au cours d’étapes au sein du data lake.
      - Et la _Value_ qu’on peut tirer de la donnée, qui peut être plus élevée si on prend plus de données en amont de notre processus de nettoyage.
- Il faut comprendre les **cas d’usages principaux** d’un _data lake_, pour éviter de le transformer en _data swamp_.
  - Parmi les plus courants il y a la **vue 360° des clients**, où il s’agit de récupérer toutes les données d’interaction avec eux, pour proposer ensuite des services plus personnalisés, vendre plus etc.
  - Il y a aussi les **données venant d’IoT**, qui ont la particularité d’être incertaines et d’avoir un gros volume, ce qui rend l’utilisation du _data warehouse_ peu intéressante.
  - Et enfin il y a le **machine learning** qui a besoin d’une très grande quantité de données, et qui tire avantage de puissance de calcul séparée des autres use-cases grâce au _data lake_.

## 2 - Why a data platform and not just a data warehouse

- Ce chapitre donne des **arguments pour le choix d’une _cloud data platform_, plutôt qu’une simple _data warehouse_**.
- On implémente les deux solutions pour une situation d’**exemple** qu’on va utiliser dans ce chapitre :
  - Nous sommes l’équipe data, et le département marketing a besoin que nous récupérions deux sources de données et qu’on les corrèle régulièrement.
    - L’une des sources est une table de campagnes de marketing, issue d’une DB MySQL interne.
    - Et l’autre est constituée de fichiers CSV de clics utilisateurs, issus de logs applicatifs (et donc _semistructured_).
  - On part sur Microsoft Azure pour les deux solutions.
  - Concernant l’implémentation _data warehouse only_ :
    - 1 - On va utiliser deux **Azure Data Factory** pour récupérer la donnée dans le serveur de DB et dans les fichiers CSV dans le serveur SFTP. C’est notre _ingest layer_.
    - 2 - Ensuite on redirige ça vers l’**Azure Synapse**, qui est la data warehouse de chez Azure. Elle va faire office de _store layer_, _process layer_ et _serve layer_.
  - Concernant l’implémentation _cloud data platform_ :
    - 1 - On a notre _ingest layer_ avec **Azure Data Factory**, qui redirige les données vers le _store layer_.
    - 2 - Le _store layer_ est implémenté avec **Azure Blob Storage**. Il s’agit d’un stockage de type _data lake_.
    - 3 - On a un _process layer_ qui utilise **Azure Databricks**, et qui fait tourner **Spark**.
    - 4 - Le _serve layer_ utilise enfin **Azure Synapse** qui est le data warehouse.
- Concernant l’**ingestion**.
  - Pour la version _data warehouse only_ :
    - La pipeline contient :
      - Des _linked services_ : ici la _data source_ MySQL en entrée, et la _data sink_ **Azure Synapse** en sortie.
      - Des _data sets_ : il s’agit de la description du schéma de données d’entrée et de sortie, et leur mapping.
    - Si le schéma de la DB source change, il faudra mettre à jour le schéma défini dans la pipeline et le mapping.
      - Mais surtout il faudra **gérer soi-même la migration** du _data sink_.
  - Pour la version _cloud data platform_ :
    - Cette fois le _data sink_ est un **Azure Blob Storage**.
      - Il n’y a plus besoin de spécifier les schémas et le mapping entre input et output puisque l’output accueille la donnée telle quelle.
    - Si le schéma de la DB source change, il n’y a **rien à faire côté ingestion** : on écrira de toute façon la donnée dans un nouveau fichier.
      - On déplace le problème de mapping plus loin.
- Concernant le **processing**.
  - Dans la version _data warehouse only_ :
    - On va charger les deux données :
      - La DB MySQL sans charger sa structure parce qu’elle est déjà relationnelle.
      - La donnée CSV semistructurée dans des rows de type texte qu’on parsera en JSON avec une fonction SQL built-in.
    - La **requête SQL** qu’on va écrire aura les désavantages suivants :
      - Elle sera **peu lisible**, à cause du code de parsing nécessaire.
        - On pourrait la rendre plus lisible en pré-parsant la donnée, mais ça veut dire plus de temps et des coûts plus élevés.
        - Une autre solution de lisibilité pourrait être d’ajouter des UDF (User Defined Functions), qu’il faudrait maintenir et déployer sur chaque instance d’**Azure Synapse**.
      - Elle sera **difficile à tester**.
      - Elle risque de ne pas profiter de la **performance** offerte par la structure en colonne du data warehouse, parce que les données texte qu’on parse en JSON ne sont pas organisables physiquement en colonnes.
  - Dans la version _cloud data platform_ :
    - On a la possibilité d’utiliser un _distributed data processing engine_ comme **Apache Spark**.
      - On pourra écrire des requêtes SQL pour des expérimentations rapides.
      - Et on pourra aussi écrire du code **lisible, maintenable et testable** dans un langage comme Python ou Scala, quand il s’agit de projet de plus long terme.
- Concernant l’**accès à la donnée**.
  - Il peut y avoir plusieurs types de consommateurs :
    - Des utilisateurs plutôt **orientés business** comme des équipes marketing.
      - Ils vont préférer utiliser des outils de reporting type **Power BI**, et donc auront besoin de la donnée sous forme relationnelle, par exemple dans **Azure Synapse**.
    - Des utilisateurs orientés **data analyse / data science**.
      - Ils pourront bénéficier de SQL qu’ils utilisent souvent directement, au travers de **Spark SQL**.
      - Ils pourront avoir accès à des données non filtrées pour leur projets data science, grâce **Spark** directement.
    - Au final la _cloud data platform_, qui contient à la fois la donnée sous forme brute dans le _data lake_, et la donnée dans le _data warehouse_, est **adaptée à chaque usage**.
- A propos des **coûts financiers**.
  - Il est difficile de comparer les coûts des services cloud.
    - En général on constate que le stockage est plutôt pas cher, et que l’essentiel des coûts se trouve dans les calculs.
  - L’**elastic scaling** consiste à pouvoir calibrer le service pour l’usage exact qu’on en a, et de ne pas avoir à payer plus.
    - C’est un des éléments qui permet de vraiment optimiser les coûts.
  - Pour la version _data warehouse only_, l’essentiel des coûts va aller dans **Azure Synapse**.
    - Le scaling de ce service peut prendre des dizaines de minutes, donc c’est quelque chose qu’on ne peut faire que de temps en temps.
  - Pour la version _cloud data platform_, l’essentiel des coûts est porté par le _processing layer_, par exemple **Spark**.
    - **Spark** est particulièrement élastique, au point où il est commun de démarrer une instance juste le temps d’une requête.

## 3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google

- Il existe un trade off entre choisir des **services vendor-specific** de type PaaS, et choisir des **services open source**.
  - D’un côté on se couple au vendor mais on minimise les coûts d’Ops, et de l’autre on permet une meilleure portabilité mais on augmente les coûts d’Ops.
  - Les auteurs trouvent que la solution vendor-specific est celle qui a en général le moins de désavantages.
- Pour répondre aux problématiques de la data moderne, il faut une **architecture en 6 couches**.
  - **1 - Data ingestion layer**.
    - Son but est de :
      - Se connecter aux sources et récupérer la donnée dans le data lake sans trop la modifier.
      - Enregistrer des statistiques et un statut dans le _metadata repository_.
    - Selon les auteurs, il vaut mieux mettre en place **à la fois un mécanisme de type batch et un mécanisme de type streaming**.
      - L'industrie est en train de se diriger vers le streaming, mais de nombreuses sources externes fournissent la donnée sous un format de type batch avec des éléments groupés, par exemple CSV, JSON, XML.
      - On pourrait utiliser la partie batch pour ingérer des données par petits batchs, et éviter de faire la version streaming. Mais ça créerait de la **dette technique** parce qu’on finira par avoir besoin du streaming à un moment ou un autre.
      - La _lambda architecture_ consiste à avoir la donnée qui passe à la fois par le mécanisme de batch et par le mécanisme de streaming.
        - Cette duplication était nécessaire parce que le streaming n’était pas fiable dans les débuts de Hadoop, mais ce n’est plus le cas.
        - Le _cloud data platform_ ne consiste pas à faire une telle duplication : selon la source, la donnée va passer par le mécanisme de streaming ou de batch.
    - On entend parfois plusieurs choses différentes quand on parle de _real time_ pour des analytics :
      - 1 - La _real time ingestion_ consiste à avoir la donnée disponible pour de l’analyse dès qu’elle arrive.
      - 2 - Le _real time analytics_ consiste à avoir des fonctionnalités d’analytics qui se mettent à jour à chaque arrivée de donnée.
        - Cette dernière est plus difficile à faire, donc il vaut mieux bien clarifier les besoins.
        - Exemple : détection de fraude en temps réel.
  - **2 - Storage layer**.
    - Son but est de :
      - Stocker la donnée pour du court terme et du long terme.
      - La rendre disponible pour la consommation streaming et la consommation batch.
    - Le **slow storage** est là pour le mode batch.
      - La donnée y est persistée pour pas cher, grâce à la possibilité de scaler le stockage sans ajouter de capacité de calcul.
      - Par contre les temps d’accès sont grands.
    - Le **fast storage** est là pour le mode streaming.
      - Il s’agit d’utiliser un outil qui est fait pour l’accès rapide, comme **Apache Kafka**.
      - Par contre, on n’a en général pas la possibilité de scaler le stockage sans ajouter de puissance de calcul, et donc les coûts sont plus grands.
      - On va donc purger régulièrement la donnée du fast storage, et de la transférer dans le slow storage.
  - **3 - Processing layer**.
    - Son but est de :
      - Lire la donnée depuis le stockage et y appliquer de la business logic.
      - Persister la donnée modifiée à nouveau dans le stockage pour un usage par les data scientists.
      - Délivrer la donnée aux autres consumers.
    - Il faut un ou plusieurs outils qui permettent de réaliser des transformations de données, y compris avec du calcul distribué.
      - Un exemple peut être **Google Dataflow**, qui est une version PaaS d’**Apache Beam**, qui supporte à la fois le mode streaming et le mode batch.
  - **4 - Technical metadata layer**.
    - Son but est de :
      - Stocker des informations techniques sur chaque layer.
        - Ça peut être les schémas d’ingestion, le statut de telle ou telle étape, des statistiques sur les données ou les erreurs, etc.
      - Permettre à chaque d’ajouter/modifier ou consulter des informations.
    - Par exemple, le processing layer peut vérifier dans la _technical metadata layer_ qu’une certaine donnée est disponible pour aller la chercher, plutôt que de demander à l’ingestion layer.
      - Ce qui permet un certain **découplage**.
    - D’autres exemples peuvent impliquer des usages de **monitoring**.
    - La _business metadata_ est une autre notion qui peut avoir son layer, mais qui n’est pas explorée dans ce livre.
      - Il s’agit d’identifier l’usage business qui est fait de chaque donnée qu’on récupère des sources, et d’en faire un catalogue.
    - Il n’y a pas vraiment d’outil unique qui permette de remplir ce rôle pour le moment, donc on devra sans doute en utiliser plusieurs.
      - Par exemple **Confluent Schema Registry** et **Amazon Glue** peuvent supporter certains des cas d’usages.
  - **5 - Serving layer**.
    - Son but est de :
      - Servir les consumers qui ont besoin de données relationnelles via une _data warehouse_.
      - Servir les consumers qui ont besoin de la donnée brute, en accédant directement au _data lake_.
        - Les data scientistes vont en général vouloir y accéder via le slow storage.
        - Et l’accès via le fast storage va plutôt intéresser les applications qui s’abonnent en mode streaming.
          - Par exemple un système de recommandation ecommerce en temps réel.
  - **6.1 - Orchestration overlay layer**.
    - Son but est de :
      - Coordonner l’exécution de jobs, sous la forme d’un graphe de dépendance.
      - Gérer les échecs et les retries.
    - C’est un peu le complément du _technical metadata layer_ pour permettre le faible couplage entre les layers.
    - L’outil le plus connu d’orchestration est **Apache Airflow**, adopté par Google Cloud Platform sous le nom de **Google Composer**.
      - AWS et Azure ont quant à eux choisi d’inclure des fonctionnalités d’orchestration dans leur outil d’ETL.
  - **6.2 - ETL overlay layer**.
    - Son but est de :
      - Prendre en charge les fonctionnalités de certains layers (ingestion, processing, metadata, orchestration) **avec peu ou pas de code**.
    - On pourrait faire l’ensemble de notre pipeline avec cet outil ETL, la question à se poser c’est : **à quel point il est ouvert à l’extension ?**
      - On peut vouloir à l’avenir par exemple utiliser un autre outil de processing, ou s’interfacer avec un outil open source.
      - Dans le cas où il y a une incompatibilité avec un usage qu’on a, on peut toujours l’implémenter à part de l’outil ETL.
        - Le problème c’est qu’au bout d’un moment, les usages à côté deviennent aussi complexes que la solution entière sans l’outil ETL, mais avec une **architecture spaghetti**.
    - Parmi les outils ETL il y a **AWS Glue**, **Azure Data Factory** et **Google Cloud Data Fusion**.
      - Il existe des solutions commerciales non cloud-natives comme **Talend** et **Informatica**, mais ce livre se limite au cloud-native et aux outils open source.
- Les **couches** doivent être bien **séparées et découplées**.
  - Une première raison est de pouvoir utiliser les outils les plus adaptés aux besoins de chaque couche.
    - Le cloud bougeant très vite, on voudra sans doute pouvoir changer seulement l’un d’entre eux quand on a une meilleure alternative pour une couche en particulier.
  - Une autre raison est qu’on peut avoir plusieurs équipes en charge de la data platform, et il vaut mieux qu’elles ne se gênent pas.
    - Par exemple, on voudra souvent avoir l’ingestion plutôt centralisée, et le processing plutôt en mode libre service pour chaque équipe qui en a besoin.
- Les **outils** pouvant servir dans une des couches de notre plateforme sont classés en 4 catégories (les auteurs les priorisent dans cet ordre) :
  - 1 - Solutions **cloud-native PaaS** d’AWS, GCP ou Azure.
    - Leur avantage principal c’est le gain de temps : on n’a pas à se préoccuper de la compatibilité. On configure très facilement et c’est en prod.
    - Par contre, c’est la solution qui va être la moins extensible : si par exemple un connecteur n’est pas supporté, on aura du mal à l’ajouter.
    - Elle est aussi peu portable, vu qu’on n’a pas les mêmes services d’un cloud provider à un autre.
  - 2 - Solutions **serverless**.
    - Il s’agit de pouvoir déployer son code custom, mais sans avoir à se préoccuper des serveurs, de leur configuration, du scaling etc.
    - C’est une solution intermédiaire d’un point de vue trade-offs sur la flexibilité, la portabilité et le gain de temps.
  - 3 - Solutions **open-source**.
    - Leur avantage c’est c’est la flexibilité et la portabilité maximales, mais de l’autre côté on a à gérer soi-même des VMs dans le cloud donc plus de travail d’Ops.
  - 4 - Solutions **SaaS commerciales**.
    - Elles peuvent avoir un intérêt si elles ont une fonctionnalité non disponible sous forme PaaS ou open source.
  - Dans les faits, on va utiliser un **mix de solutions des 4 catégories** en fonction des layers et des besoins qu’on a.
    - On a de plus en plus d’entreprises qui utilisent des solutions de **plusieurs cloud providers**. Par exemple le gros des services sur AWS, et le use-case machine learning sur GCP.
- Outils sur **AWS**.
  - Batch ingestion.
    - **AWS Glue** supporte l’ingestion à partir de **AWS S3**, ou à partir d’une connexion JDBC.
    - **AWS Database Migration Service** sert à la base à transférer ses DBs vers AWS, mais on peut l’utiliser comme ingestion layer.
    - **AWS DMS** permet d’implémenter un mécanisme de change data capture à partir d’une DB.
    - Si aucune des solutions PaaS ne supporte notre data source, on peut utiliser la solution serverless **AWS Lambda** où il faudra écrire et maintenir du code.
  - Streaming ingestion.
    - **AWS Kinesis** est un message broker pour lequel il faudra écrire du code pour publier dedans. Il a malheureusement très peu de connecteurs entrants.
      - En revanche il a des connecteurs sortants appelés **Kinesis Firehose**, qui permettent par exemple d’envoyer la donnée de Kinesis dans un **S3** sous format Parquet.
    - **AWS Managed Streaming for Apache Kafka (MSK)** est une version de **Kafka** entièrement managée.
      - On peut l’utiliser à la place de **Kinesis**, par exemple si on migre une application avec **Kafka** vers AWS.
  - Storage.
    - **AWS S3** permet de stocker de la donnée de manière scalable, avec la possibilité de choisir entre plusieurs formules avec des latences plus ou moins grandes.
  - Batch processing.
    - **AWS Elastic MapReduce (EMR)** est une version managée de **Spark**.
      - On va en général lire la donnée depuis **S3**, faire le calcul, puis détruire le cluster **EMR**.
  - Streaming processing.
    - **AWS Kinesis Data Analytics** permet de se brancher sur **Kinesis**, et de faire du processing en streaming.
    - Si on utilise **AWS MSK**, on peut brancher dessus **Kafka Streams** pour le processing en streaming.
  - Data warehouse.
    - **AWS Redshift** est un data warehouse distributé sur plusieurs noeuds.
      - **Redshift Spectrum** permet de faire des requêtes depuis **Redshift** pour obtenir des données qui sont en fait sur **S3**.
        - Il faudra définir des “tables externes”, et la performance de la query sera moins bonne, mais ça permet d’économiser de la place dans le data warehouse.
  - Direct access.
    - **AWS Athena** permet de faire une requête SQL distribuée en utilisant directement la donnée sur **S3**.
      - On lance l’instance le temps de la requête, puis on détruit l’instance.
  - ETL overlay et metadata repository.
    - **AWS Glue** est un outil d’ETL complet.
      - Il est construit autour de **Spark**, et possède des templates pour faciliter de nombreuses transformations.
        - Il a aussi des add-ons **Spark** non-standards, ce qui nuit à la portabilité par rapport à un simple **Spark** managé.
      - Il maintient un _Data Catalog_ à partir des données disponibles sur **S3**.
      - Il maintient un ensemble de statistiques sur l’exécution des jobs.
  - Orchestration.
    - **AWS Step Functions** permet de créer des workflows qui mettent en jeu différents services, y compris ceux qui ne seraient pas gérés par **Glue** comme **AWS Lambda** avec du code custom.
  - Consumers.
    - Pour les outils comme **Tableau** qui ont besoin d’une connexion JDBC/ODBC qui supporte SQL, elles peuvent se connecter à **Redshift** ou **Athena**.
    - Pour du streaming avec faible latence, on peut envoyer la donnée dans un key/value store comme **DynamoDB**, ou dans une DB comme **AWS RDS** ou **AWS Aurora**.
- Outils sur **GCP**.
  - Batch ingestion.
    - **Cloud Data Fusion** est un ETL overlay qui permet d’ingérer des données depuis une DB relationnelle avec JDBC, des fichiers depuis **Google Cloud Storage**, et même depuis un FTP ou depuis **AWS S3**.
      - Il est basé sur un projet open source, et donc supporte des connecteurs custom.
    - **BigQuery Data Transfer Service** permet d’ingérer de la donnée depuis les services SaaS de Google, et depuis des centaines d’autres services SaaS connus grâce à un partenariat avec Fivetran.
      - Par contre, la donnée va directement dans le data warehouse, ce qui ne permet pas vraiment l’architecture modulaire qu’on vise.
    - **Cloud Functions** représente l’équivalent d’**AWS Lambda**, avec le désavantage d’avoir une limite de temps d’exécution des fonctions serverless.
  - Stream ingrestion.
    - **Cloud Pub/Sub** est un broker équivalent à **AWS Kinesis**.
  - Storage.
    - **Google Cloud Storage** est un équivalent à **AWS S3**.
  - Batch processing.
    - **Dataproc** est un **Spark** managé équivalent à **AWS EMR**.
    - **Cloud Dataflow** est un **Apache Beam** managé.
      - **Beam** a l’avantage d’offrir une même API pour le batch processing et le streaming processing, là où **Spark** ne supporte que le batch mais est une techno plus mature.
  - Streaming processing.
    - **Cloud Dataflow** représente la manière clou-native de faire du streaming sur GCP.
    - **Dataproc** avec **Spark Streaming** peut représenter une alternative, mais il s’agit en fait de micro-batch et non pas de traiter les messages un par un.
      - Les auteurs conseillent **Beam**, sauf si on a déjà investi en temps ou connaissances sur **Spark**.
  - Data warehouse.
    - **BigQuery** est un équivalent à **AWS RedShift**.
      - Il a l’avantage de scaler le nombre de nœuds tout seul.
      - Par contre il a un modèle de facturation basé sur la donnée lue par chaque requête, ce qui peut rendre les coûts difficiles à prédire.
  - Direct access.
    - GCP ne propose pas de services pour accéder au _data lake_ directement avec du SQL.
      - On peut éventuellement créer des tables vers de la donnée externe (donc dans le _data lake_) à partir de **BigQuery**.
      - On peut aussi utiliser **Spark SQL** pour identifier et lire de la donnée sur le _data lake_.
  - ETL overlay et metadata repository.
    - **Cloud Data Fusion** est un ETL overlay équivalent à **AWS Glue**. Il fournit une UI qui permet de configurer la pipeline.
      - Il met à disposition un moyen d’analyser quelle partie de la pipeline peut affecter telle ou telle donnée.
      - Il met aussi à disposition des statistiques sur l’exécution des jobs.
  - Orchestration.
    - **Cloud Composer** permet de créer des flows d’orchestration entre jobs.
      - Il est basé sur **Apache Airflow**.
  - Consumers.
    - **BigQuery** n’a pas de connexion JDBC/ODBC pour y connecter un outil BI par exemple.
      - Il a une API REST, et il est directement compatible avec certains outils BI.
    - Si on veut consommer la donnée avec une faible latence, on peut la mettre dans le key/value store **Cloud Bigtable**.
- Outils sur **Azure**.
  - Batch ingestion.
    - **Azure Data Factory** est un ETL overlay permettant de faire de l’ingestion depuis diverses sources (DB, SaaS externes, **S3**, **GCS** etc.).
      - Il est celui qui a le plus de connecteurs comparé à **AWS Glue** et **Cloud Data Fusion**.
    - **Azure Functions** est l’équivalent d’**AWS Lambda**.
      - Il ne supporte que Java et Python.
  - Streaming ingestion.
    - **Azure Event Hubs** est équivalent à **AWS Kinesis**.
      - Il a la particularité d’être compatible avec **Apache Kafka**.
  - Storage.
    - **Azure Blob Storage** est équivalent à **AWS S3**.
    - **Azure Data Lake Storage** est une version améliorée qui supporte mieux le calcul distribué avec de grandes quantités de données.
  - Batch processing.
    - Pour le batch processing, Azure a choisi de miser sur un partenariat avec **Databricks**, qui est un service créé par les créateurs de **Spark**.
      - La version managée de **Databricks** est disponible sur AWS et Azure, mais elle est celle par défaut sur Azure, donc mieux supportée par son écosystème.
  - Streaming processing.
    - Azure Stream Analytics se branche sur Event Hubs et permet de faire du streaming processing.
  - Data warehouse.
    - **Azure Synapse** est le _data warehouse_ d’Azure.
      - Il est entre **AWS Redshift** et **Google BigQuery** dans la mesure où il nécessite de choisir la capacité de calcul, mais il scale l’espace disque tout seul.
  - Direct access.
    - **Azure Databricks** est la manière privilégiée d’accéder à la donnée sur le _data lake_, soit par l’API native de **Spark**, soit en SQL avec **Spark SQL**.
  - ETL overlay et metadata repository.
    - **Azure Data Factory** est équivalent à **AWS Glue**.
      - Il s’intègre parfaitement avec **Databricks** pour les transformations complexes.
      - Il fournit des métriques sur la data pipeline.
  - Orchestration.
    - La partie orchestration des jobs est prise en charge par Azure Data Factory.
  - Consumers.
    - **Azure Synapse** fournit une connexion JDBC/ODBC pour connecter les outils de BI.
      - **Azure Databricks** fournit la même chose, mais il faut un cluster Spark toujours allumé, ce qui peut coûter cher.
    - **Cosmos DB** est une DB orientée document où on peut stocker les résultats de processings pour un accès faible latence.
- Alternatives **commerciales** ou **open source**.
  - Certains logiciels open source sont trop difficiles à mettre en place, par exemple un _data warehouse_ distribué comme **Apache Druid**.
  - Batch ingestion.
    - Il existe pas mal d’outils open source et commerciaux qui permettent d’ingérer des données, leur valeur ajoutée étant en général le grand nombre de sources supportées.
    - **Apachi NiFi** est une solution open source qui supporte de nombreuses sources, et permet d’en ajouter soi-même en Java.
    - Il existe de nombreux outils SaaS commerciaux qui gèrent l’ingestion.
      - Ces outils vont souvent envoyer la donnée directement dans un data warehouse.
      - Il faut bien réfléchir à la problématique de la sécurité.
  - Streaming ingestion.
    - **Apache Kafka** est le principal outil utilisé en dehors d’une solution managée de streaming.
      - Il a l’avantage de pouvoir se connecter à de nombreuses sources avec **Kafka Connect**, et il a un moyen d’implémenter des applications de streaming avec **Kafka Streams**.
      - Les raisons de choisir **Kafka** plutôt qu’une solution cloud-native peuvent être l’investissement qu’on a déjà dans **Kafka** (par exemple connaissances), ou le besoin de performance nécessitant le fine-tuning du serveur **Kafka**.
  - Orchestration.
    - **Apache Airflow** est le principal outil utilisé en dehors d’une solution managée d’orchestration.
      - La raison de l’utiliser en mode non managé peut être de profiter de sa flexibilité, avec ses fichiers en Python.

## 4 - Getting data into the platform

- Le layer d’ingestion peut avoir besoin d’ingérer différents types de données :
  - **1 - Les bases de données relationnelles**.
    - Leurs données sont organisées en colonnes et typées, mais chaque vendor a des types à lui.
      - Il y a donc un **mapping** à faire entre le type de chaque colonne et notre modèle.
      - Ce mapping va changer régulièrement en fonction des évolutions fonctionnelles des applications qui utilisent cette DB.
    - Vu que la donnée est normalisée, elle se trouve dans des centaines de tables qu’on peut joindre au moment des queries.
      - Il faudra donc **automatiser le mapping** pour éviter de le faire à la main.
    - La donnée change régulièrement dans la DB, pour refléter l’état de l’application, elle est **volatile**.
      - Il faudra donc aller chercher régulièrement les derniers changements.
  - **2 - Les fichiers.**
    - Les fichiers sont structurés selon divers types de format texte ou binaire (CSV, JSON XML, Avro, Protobuf etc.) qui ne contiennent pas d’information de type.
      - Il faut donc pouvoir **supporter le parsing de tous ces formats**.
    - Les fichiers ne garantissent aucun schéma, et on voit beaucoup plus souvent des changements dans celui-ci que pour les DB relationnelles.
      - Il faut donc gérer les **changements de schéma fréquents**.
    - Les fichiers représentent en général de la **donnée figée**.
      - La nouvelle donnée est écrite dans un autre fichier, donc on se retrouve à devoir ingérer **de nombreux fichiers**.
  - **3 - La donnée SaaS via API.**
    - Les données SaaS sont en général disponibles via une API REST, qui renvoie du JSON.
    - Chaque provider a sa propre API, et son propre format. Il faudra donc **implémenter la partie ingestion pour chacun des providers**.
      - Il faudra faire la validation du schéma à chaque fois.
      - Il faudra la tenir à jour en fonction des changements d’API.
  - **4 - Les streams**.
    - Les mêmes données peuvent arriver plusieurs fois, donc il faut que notre pipeline puisse **gérer les duplicatas**.
    - Les events des streams sont immutables, et peuvent être corrigés en ajoutant un autre message modifié au stream.
      - Donc il faut que notre pipeline **gère la réconciliation entre plusieurs versions d’un même message**.
    - Les données de streaming ont en général un **grand volume**, donc il faut une infrastructure qui le supporte.
- Concernant le cas des **bases de données relationnelles**.
  - Il y a deux moyens d’ingérer de la donnée depuis une DB relationnelle :
    - **1 - L’utilisation de requêtes SQL**.
      - Il s’agit d’avoir un composant qui va :
        - 1 - Exécuter la requête vers la DB concernée.
          - Ca peut être un simple :
            - `SELECT * FROM table`
        - 2 - Récupérer la donnée sous un format qu’il comprend.
        - 3 - Mapper la donnée dans le bon format pour la stocker sur le _storage layer_.
        - Il y a donc **2 mappings** qui se produisent pendant l’opération.
      - Alors que la donnée opérationnelle s’intéresse à l’état actuel (“Quels sont les articles dans le panier ?”), **la donnée analytique s’intéresse à l’évolution de l’état dans le temps** (“Quels articles ont été ajoutés ou enlevés et dans quel ordre ?”).
        - Il faut donc un moyen pour capturer l’évolution de la donnée dans le temps.
      - Une 1ère solution pour garder l’évolution dans le temps est de faire une **full table ingestion**.
        - On va récupérer l’ensemble des données d’une table à intervals réguliers, sauver ces snapshots dans le _data lake_, et les charger dans le _data warehouse_.
        - Pour en tirer quelque chose, il faut** superposer les rows des snapshots** dans la même table du _data warehouse_.
          - Pour différencier les rows de chaque snapshot, on peut ajouter une colonne `INGEST_DATE`.
          - On peut directement utiliser du SQL pour obtenir les données qu’on veut, mais pour certains usages on aura besoin de faire une transformation dans le _processing layer_.
        - Parmi les données dérivées qu’on voudra créer, il peut y avoir :
          - Créer une _view_ qui ne montre que les rows du dernier snapshot.
          - De la donnée qui **identifie les suppressions**, en identifiant les rows qui existaient dans un snapshot et n’existaient plus dans le suivant.
          - Une version “compactée”, qui élimine les rows qui n’ont pas changé par rapport au snapshot précédent.
        - Le problème de la full table ingestion, c’est la charge sur la machine de DB, et l’**énorme quantité de données** qu’on finit par avoir.
      - Une autre solution peut être l’**incremental table ingestion**.
        - Il s’agit toujours de récupérer des snapshots à intervalles réguliers, mais **seulement de la donnée qui a changé** depuis le précédent snapshot.
        - Pour savoir quelle donnée a changé :
          - La table d’origine doit avoir un champ `LAST_MODIFIED`, mis à jour automatiquement par la DB.
          - En retenant le `MAX(LAST_MODIFIED)` du dernier run d’ingestion (qu’on appelle le _highest watermark_), on peut construire une query qui récupère uniquement les nouvelles données :
            - `SELECT * FROM subscriptions WHERE LAST_MODIFIED > "2019-05-01 17:01:00"`
          - On pourra mettre le _highest watermark_ dans le _technical metadata layer_.
            - **AWS Glue** gère nativement le stockage de ce genre de données, mais on peut le mettre dans une DB managée comme **Google Cloud SQL** ou **Azure SQL Database**.
        - Cette _incremental table ingestion_ permet d’ingérer moins de données dupliquées, mais elle a encore des inconvénients :
          - Il faut faire du processing pour faire apparaître les données supprimées, en comparant les snapshots entre eux.
          - Les données qui sont insérées puis supprimées entre deux snapshots ne seront pas capturées par ce mécanisme, donc **on perd des informations**.
    - **2 - Le Change Data Capture (CDC)**.
