(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[82],{7382:function(e,n,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/books/effective-kafka",function(){return s(3217)}])},9923:function(e,n,s){"use strict";s.d(n,{Z:function(){return c}});var r=s(5893);s(7294);let i="My detailed reading notes from computer science books",l="/reading-notes";var t=s(1163),a=s(5675),o=s.n(a);let d={logo:(0,r.jsx)(function(){return(0,r.jsx)(o(),{src:"".concat(l,"/logo.png"),alt:"Reading notes homepage",width:30,height:30})},{}),project:{link:"https://github.com/mkrtchian/reading-notes"},docsRepositoryBase:"https://github.com/mkrtchian/reading-notes/blob/main",footer:{text:"Made by Roman Mkrtchian"},head:function(){let e="Reading notes";return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("meta",{name:"msapplication-TileColor",content:"#fff"}),(0,r.jsx)("meta",{httpEquiv:"Content-Language",content:"en"}),(0,r.jsx)("meta",{name:"description",content:i}),(0,r.jsx)("meta",{property:"og:title",content:e}),(0,r.jsx)("meta",{property:"og:description",content:i}),(0,r.jsx)("meta",{name:"apple-mobile-web-app-title",content:e}),(0,r.jsx)("link",{rel:"icon",type:"image/x-icon",href:"".concat(l,"/favicon.ico")})]})},feedback:{content:()=>(0,r.jsx)(r.Fragment,{children:"Question? Give me feedback →"}),labels:"feedback"},useNextSeoProps:function(){let{route:e}=(0,t.useRouter)(),n={description:i};return"/"!==e?n.titleTemplate="%s – Reading notes":n.titleTemplate="%s",n},i18n:[]};var c=d},3217:function(e,n,s){"use strict";s.r(n);var r=s(5893),i=s(2673),l=s(902),t=s(9923);s(9966);var a=s(1151);s(5675);let o={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,a.ah)(),e.components);return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)},pageOpts:{filePath:"pages/books/effective-kafka.md",route:"/books/effective-kafka",headings:[{depth:1,value:"Effective Kafka",id:"effective-kafka"},{depth:2,value:"1 - Event Streaming Fundamentals",id:"1---event-streaming-fundamentals"},{depth:2,value:"2 - Introducing Apache Kafka",id:"2---introducing-apache-kafka"},{depth:2,value:"3 - Architecture and Core Concepts",id:"3---architecture-and-core-concepts"},{depth:2,value:"4 - Installation",id:"4---installation"},{depth:2,value:"5 - Getting Started",id:"5---getting-started"},{depth:2,value:"6 - Design Considerations",id:"6---design-considerations"},{depth:2,value:"7 - Serialization",id:"7---serialization"},{depth:2,value:"8 - Bootstrapping and Advertised Listeners",id:"8---bootstrapping-and-advertised-listeners"},{depth:2,value:"9 - Broker Configuration",id:"9---broker-configuration"},{depth:2,value:"10 - Client Configuration",id:"10---client-configuration"}],pageMap:[{kind:"Meta",data:{index:"Introduction",books:"Reading notes"}},{kind:"Folder",name:"books",route:"/books",children:[{kind:"Meta",data:{"continuous-discovery-habits":"Continuous Discovery Habits","designing-data-intensive-applications":"Designing Data-Intensive Applications","effective-kafka":"Effective Kafka","get-your-hands-dirty-on-clean-architecture":"Get Your Hands Dirty on Clean Architecture","learning-domain-driven-design":"Learning Domain-Driven Design","monolith-to-microservices":"Monolith to Microservices",refactoring:"Refactoring: Improving the Design of Existing Code","reinventing-organizations":"Reinventing Organizations","team-topologies":"Team Topologies","the-design-of-web-apis":"The Design of Web APIs","unit-testing":"Unit Testing: Principles, Practices, and Patterns"}},{kind:"MdxPage",name:"continuous-discovery-habits",route:"/books/continuous-discovery-habits"},{kind:"MdxPage",name:"designing-data-intensive-applications",route:"/books/designing-data-intensive-applications"},{kind:"MdxPage",name:"effective-kafka",route:"/books/effective-kafka"},{kind:"MdxPage",name:"get-your-hands-dirty-on-clean-architecture",route:"/books/get-your-hands-dirty-on-clean-architecture"},{kind:"MdxPage",name:"learning-domain-driven-design",route:"/books/learning-domain-driven-design"},{kind:"MdxPage",name:"monolith-to-microservices",route:"/books/monolith-to-microservices"},{kind:"MdxPage",name:"refactoring",route:"/books/refactoring"},{kind:"MdxPage",name:"reinventing-organizations",route:"/books/reinventing-organizations"},{kind:"MdxPage",name:"team-topologies",route:"/books/team-topologies"},{kind:"MdxPage",name:"the-design-of-web-apis",route:"/books/the-design-of-web-apis"},{kind:"MdxPage",name:"unit-testing",route:"/books/unit-testing"}]},{kind:"MdxPage",name:"index",route:"/"}],flexsearch:{codeblocks:!0},title:"Effective Kafka"},pageNextRoute:"/books/effective-kafka",nextraLayout:l.ZP,themeConfig:t.Z};function d(e){let n=Object.assign({h1:"h1",h2:"h2",ul:"ul",li:"li",strong:"strong",em:"em",code:"code",a:"a",pre:"pre",span:"span"},(0,a.ah)(),e.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{children:"Effective Kafka"}),"\n",(0,r.jsx)(n.h2,{id:"1---event-streaming-fundamentals",children:"1 - Event Streaming Fundamentals"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"syst\xe8mes distribu\xe9s"})," sont plus complexes que les syst\xe8mes non distribu\xe9s, ils d\xe9placent une partie de la ",(0,r.jsx)(n.strong,{children:"complexit\xe9 du local vers le global"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La raison pour laquelle on les utilise c’est qu’ils permettent de d\xe9composer le syst\xe8me en plus petits probl\xe8mes qu’on va pouvoir diviser entre plusieurs \xe9quipes."}),"\n",(0,r.jsx)(n.li,{children:"La complexit\xe9 globale peut \xeatre r\xe9duite par certaines techniques, par exemple les messages asynchrones."}),"\n",(0,r.jsx)(n.li,{children:"On y trouve des \xe9checs partiels, intermittents, ou m\xeame byzantins (les nœuds envoient des informations fausses)."}),"\n",(0,r.jsx)(n.li,{children:"Le probl\xe8me le plus important est sans doute celui de la consistance."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’",(0,r.jsx)(n.strong,{children:"event-driven architecture"})," (EDA) consiste \xe0 avoir des ",(0,r.jsx)(n.em,{children:"emitters"})," envoyant des notifications d’event \xe0 des ",(0,r.jsx)(n.em,{children:"consumers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les emitters n’ont aucune connaissance des consumers. Et de m\xeame les consumers n’ont pas connaissance des emitters."}),"\n",(0,r.jsx)(n.li,{children:"Les notifications d’event sont immutables, que ce soit c\xf4t\xe9 emitter ou consumer."}),"\n",(0,r.jsxs)(n.li,{children:["L’EDA est la mani\xe8re ",(0,r.jsx)(n.strong,{children:"la plus d\xe9coupl\xe9e"})," de faire communiquer des composants entre eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le seul couplage sera dans le contenu des messages qui transitent."}),"\n",(0,r.jsxs)(n.li,{children:["Imaginons un syst\xe8me d’e-commerce, avec une plateforme BI et un CRM. Il leur suffira de consommer les events d’achat et d’y r\xe9agir en toute ind\xe9pendance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les autres possibilit\xe9s qu’on aurait pour l’exemple e-commerce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut les mettre dans un monolith (non-modulaire), mais la complexit\xe9 risque d’augmenter \xe0 mesure que le mod\xe8le global est enrichi."}),"\n",(0,r.jsxs)(n.li,{children:["On peut utiliser des patterns d’int\xe9gration : des messages synchrones envoy\xe9s par le composant e-commerce ou par les deux autres. Dans ce cas on se rapproche du distributed monolith parce que les composants ne seront pas ind\xe9pendants.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"NDLR : toute communication synchrone rel\xe8verait du distributed monolith, un peu violent…"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut utiliser la ",(0,r.jsx)(n.em,{children:"data decapsulation"}),", o\xf9 les composants BI et CRM viennent lire la DB du composant e-commerce. Dans ce cas on se retrouve dans un mode “get rich quick scheme” qui m\xe8ne toujours \xe0 des pleurs. Le couplage est maximal."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Cet exemple montre que ",(0,r.jsx)(n.strong,{children:"l’EDA scale de mani\xe8re lin\xe9aire"}),", alors qu’avec les approches plus coupl\xe9es, la complexit\xe9 explose quand on scale le nombre de composants."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’EDA est beaucoup ",(0,r.jsx)(n.strong,{children:"plus r\xe9silient"})," que les approches coupl\xe9es : si un composant est en situation d’\xe9chec, il a peu de chances d’impacter d’autres composants.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si on reprend l’exemple d’e-commerce :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 le composant d’e-commerce est en situation d’\xe9chec, les autres composants vont continuer \xe0 pouvoir fonctionner, mais simplement ils ne recevront plus de nouveaux events."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 par exemple le CRM est en situation d’\xe9chec, les events continueront d’arriver, et il pourra toujours rattraper son retard d\xe8s qu’il est r\xe9tabli."}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi pr\xe9voir une mesure pour que si le message broker est en situation d’\xe9chec, l’\xe9metteur puisse publier les events localement, pour les mettre dans le message broker plus tard."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans un syst\xe8me coupl\xe9, un composant qui est en \xe9chec peut entra\xeener des ",(0,r.jsx)(n.em,{children:"correlated failures"})," chez les autres qui en d\xe9pendent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut aussi avoir des ",(0,r.jsx)(n.em,{children:"congestive collapses"})," dans le cas o\xf9 certains composants sont temporairement surcharg\xe9s, et que les requ\xeates synchrones m\xe8nent \xe0 avoir des timeouts, puis \xe0 envoyer plus de requ\xeates."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’EDA a aussi des avantages en termes de ",(0,r.jsx)(n.strong,{children:"consistance"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il favorise l’ownership d’un \xe9l\xe9ment stateful par un composant unique, les autres composants recevant les notifications d’event ne pouvant pas modifier cet \xe9tat."}),"\n",(0,r.jsxs)(n.li,{children:["En dehors du composant owner, les events sont rejouables ",(0,r.jsx)(n.strong,{children:"dans le bon ordre"}),", garantissant une ",(0,r.jsx)(n.em,{children:"sequential consistency"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’EDA n’est cependant pas adapt\xe9e dans certains cas.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Elle n’est ",(0,r.jsx)(n.strong,{children:"pas adapt\xe9e aux interactions synchrones"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Par contre, dans les cas o\xf9 on peut l’utiliser, elle permet des am\xe9liorations significatives des aspects non fonctionnels."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’",(0,r.jsx)(n.strong,{children:"event streaming"})," est un moyen d’obtenir un stream ",(0,r.jsx)(n.strong,{children:"durable"})," et ",(0,r.jsx)(n.strong,{children:"ordonn\xe9"}),", d’events ",(0,r.jsx)(n.strong,{children:"immutables"}),", d\xe9livr\xe9s aux consumers qui ont souscrit.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L’event streaming n’est pas n\xe9cessaire pour impl\xe9menter l’EDA, qui peut d’ailleurs \xeatre impl\xe9ment\xe9 dans un monolith (cf. outils comme React qui sont bas\xe9s sur des events)."}),"\n",(0,r.jsxs)(n.li,{children:["En revanche l’",(0,r.jsx)(n.strong,{children:"event streaming est pertinent"})," comme choix face aux solutions concurrentes (comme les message queues) ",(0,r.jsx)(n.strong,{children:"dans le cadre d’EDA distribu\xe9es"}),", parce qu’il a \xe9t\xe9 con\xe7u pour \xe7a.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L’event streaming supporte nativement l’immutabilit\xe9 des events."}),"\n",(0,r.jsx)(n.li,{children:"Il supporte la garantie d’ordre des events."}),"\n",(0,r.jsx)(n.li,{children:"Il supporte le fait d’avoir de multiples consumers."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2---introducing-apache-kafka",children:"2 - Introducing Apache Kafka"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Kafka est une plateforme d’event streaming, mais elle comprend aussi un \xe9cosyst\xe8me entier qui permet l’impl\xe9mentation d’EDAs."}),"\n",(0,r.jsxs)(n.li,{children:["L’event streaming est r\xe9cent compar\xe9 aux formes traditionnelles de messaging (MQ-style).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il n’y a pas de standard, mais Kafka est le leader du domaine, et son fonctionnement sert de mod\xe8le pour les solutions concurrentes comme ",(0,r.jsx)(n.strong,{children:"Azure Event Hubs"})," et ",(0,r.jsx)(n.strong,{children:"Apache Pulsar"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Historiquement, Kafka a \xe9t\xe9 open-sourc\xe9 en 2011 par LinkedIn, et confi\xe9 \xe0 la fondation Apache.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il avait \xe9t\xe9 con\xe7u notamment pour g\xe9rer les events d’activit\xe9 des utilisateurs."}),"\n",(0,r.jsx)(n.li,{children:"En 2019, LinkedIn op\xe9rait 100 clusters Kafka, pour un total de 100 000 topics et 7 millions de partitions."}),"\n",(0,r.jsxs)(n.li,{children:["Aujourd’hui Kafka est utilis\xe9 par des g\xe9ants de la tech, pour des usages comme le real-time analytics, la data ingestion, le log aggregation et le messaging pour l’EDA.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Uber par exemple l’utilise pour g\xe9rer au total plus de 1000 milliards d’events par jour."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Parmi les usages qui permettent l’EDA, Kafka supporte :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Publish-subscribe"})," : un emitter publie des events, et plusieurs consumers les consomment sans que ces noeuds se connaissent.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est notamment utilis\xe9 pour des microservices avec un faible couplage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Log aggregation"})," : un ensemble de sources publient des events sous forme de log (soit applicatifs, soit d’infrastructure), qu’on va ensuite agr\xe9ger au sein du m\xeame topic, pour le consommer dans une DB optimis\xe9e pour la lecture, comme ",(0,r.jsx)(n.strong,{children:"Elasticsearch"})," ou ",(0,r.jsx)(n.strong,{children:"HBase"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Log shipping"})," : il s’agit de streamer des logs depuis une DB master vers un topic o\xf9 plusieurs DB followers vont consommer et se mettre \xe0 jour.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce pattern permet notamment d’impl\xe9menter l’event sourcing."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SEDA pipelines"})," : le Stage Event-Driven Architecture est l’impl\xe9mentation d’une pipeline d’events, o\xf9 on fait une op\xe9ration \xe0 chaque \xe9tape, avant d'\xe9mettre un event modifi\xe9 pour l’\xe9tape suivante.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est typiquement utilis\xe9 avec les data warehouses, data lakes, le reporting et autres outils de BI."}),"\n",(0,r.jsx)(n.li,{children:"On peut voir le log aggregation comme une forme de SEDA."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CEP"})," : le Complex Event Processing consiste \xe0 un composant qui consomme des events de multiples sources, et en extrait l’information pertinente.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il a souvent besoin d’un stockage pour se rappeler les patterns d\xe9j\xe0 vus et y r\xe9agir."}),"\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre par exemple pour le trading algorithmique, l’analyse des menaces de s\xe9curit\xe9, l’analyse de fraude en temps r\xe9el etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Event-sourced CQRS"})," : Kafka se place entre la DB master et les DBs de projection, en permettant de les alimenter chacune au travers du concept de ",(0,r.jsx)(n.em,{children:"consumer groups"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La diff\xe9rence avec le log shipping c’est que le log shipping op\xe8re plut\xf4t \xe0 l’int\xe9rieur d’un subdomain, alors que le CQRS peut aussi op\xe9rer \xe0 travers les subdomains."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3---architecture-and-core-concepts",children:"3 - Architecture and Core Concepts"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Kafka est compos\xe9 de plusieurs types de noeuds :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Broker nodes"})," : ce sont les composants principaux de Kafka, ils s’occupent des op\xe9rations I/O et de la persistance.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ces nœuds sont des processus Java."}),"\n",(0,r.jsxs)(n.li,{children:["Chaque partition est sous la responsabilit\xe9 d’un nœud master qui peut \xe9crire dedans, les followers en ont une copie et peuvent \xeatre lus.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un m\xeame nœud peut \xeatre master pour certaines partitions, et follower pour d’autres."}),"\n",(0,r.jsx)(n.li,{children:"L’ownership peut passer \xe0 un autre nœud en cas de besoin (op\xe9ration sp\xe9ciale qui le n\xe9cessite ou \xe9chec du nœud qui \xe9tait master de la partition)."}),"\n",(0,r.jsxs)(n.li,{children:["Concernant l’attribution de l’ownership, \xe7a se fait d’abord en \xe9lisant un des nœuds comme ",(0,r.jsx)(n.em,{children:"cluster controller"}),", puis celui-ci assigne l’ownership des partitions au gr\xe9 des besoins."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Augmenter le nombre de nœuds constitue un moyen de scaler Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut am\xe9liorer la durability en ayant plusieurs copies de chaque partition (autant que le nombre de nœuds)."}),"\n",(0,r.jsx)(n.li,{children:"On peut am\xe9liorer l’availability pour les donn\xe9es en lecture."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Zookeeper nodes"})," : Zookeeper est un projet open source distinct de Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ses nœuds sont charg\xe9s d’\xe9lire le broker qui sera le ",(0,r.jsx)(n.em,{children:"cluster controller"}),", de garantir qu’il n’y en ait qu’un, et d’en r\xe9\xe9lire un s’il n’est plus op\xe9rationnel."]}),"\n",(0,r.jsx)(n.li,{children:"Ils fournissent aussi diverses m\xe9tadonn\xe9es \xe0 propos du cluster, par exemple l’\xe9tat des diff\xe9rents nœuds, des informations de quotas, les access control list etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Producers"})," : les applications clientes qui \xe9crivent dans les topics.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Un producer communique avec Kafka via TCP, avec une connexion par broker node."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consumers"})," : les applications clientes qui lisent des topics."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le fonctionnement de Kafka se base sur des notions d’ordering venant de la th\xe9orie des ensembles (set theory).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"total ordering"})," consiste \xe0 avoir un ensemble d’\xe9l\xe9ments dont une ",(0,r.jsx)(n.strong,{children:"seule configuration est possible"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut l’illustrer avec un set de nombres entiers ",(0,r.jsx)(n.code,{children:"{ 2, 4, 6 }"}),". Si on enl\xe8ve l’\xe9l\xe9ment 4, puis qu’on le remet, il ne pourra qu’\xeatre \xe0 la 2\xe8me place, avant le 6 et apr\xe8s le 2."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"partial ordering"})," consiste \xe0 avoir un ensemble d’\xe9l\xe9ments ordonn\xe9s selon un crit\xe8re sp\xe9cifique, mais dont ",(0,r.jsx)(n.strong,{children:"plusieurs configurations sont possibles"})," pour satisfaire le crit\xe8re.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple, si on a des entiers qu’on veut ordonner de mani\xe8re \xe0 ce que le diviseur d’un nombre soit toujours apr\xe8s ce nombre, et qu’on a ",(0,r.jsx)(n.code,{children:"[ 2, 3, 4, 6, 9, 8 ]"}),", on peut tout autant les organiser en ",(0,r.jsx)(n.code,{children:"[ 3, 2, 6, 9, 4, 8 ]"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La notion de ",(0,r.jsx)(n.strong,{children:"causal order"})," indique qu’on respecte le fait que certains \xe9l\xe9ments ont une relation ",(0,r.jsx)(n.em,{children:"happened-before"})," entre eux qui est respect\xe9e, quel que soit leur ordre d’arriv\xe9e \xe0 destination.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette notion vient de l’\xe9tude des syst\xe8mes distribu\xe9s (et non de la th\xe9orie des ensembles)."}),"\n",(0,r.jsx)(n.li,{children:"Elle est une forme de partial ordering."}),"\n",(0,r.jsx)(n.li,{children:"Elle est la cons\xe9quence du fait qu’il n’y ait pas d’horloge commune \xe0 l’ensemble des nœuds d’un syst\xe8me distribu\xe9, et que les events peuvent arriver dans le mauvais ordre."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"records"})," sont l’unit\xe9 principale de Kafka. Ils correspondent aux events.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils sont compos\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["D’attributs assez classiques : la ",(0,r.jsx)(n.em,{children:"value"})," qui peut \xeatre sous forme binaire, des ",(0,r.jsx)(n.em,{children:"headers"})," pour donner des m\xe9tadonn\xe9es, la ",(0,r.jsx)(n.em,{children:"partition"})," associ\xe9e au record, l’",(0,r.jsx)(n.em,{children:"offset"})," par rapport aux autres records de la partition, un ",(0,r.jsx)(n.em,{children:"timestamp"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La combinaison ",(0,r.jsx)(n.em,{children:"partition"})," + ",(0,r.jsx)(n.em,{children:"offset"})," permet d’identifier un record de mani\xe8re unique."]}),"\n",(0,r.jsxs)(n.li,{children:["L’",(0,r.jsx)(n.em,{children:"offset"})," est une valeur enti\xe8re qui ne peut qu’augmenter, m\xeame s'il peut y avoir des gaps entre deux offsets qui se suivent."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["D’un champ binaire un peu plus inhabituel qui est la ",(0,r.jsx)(n.em,{children:"key"}),", et qui est utilis\xe9e par Kafka pour associer les records avec une m\xeame partition."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Kafka est largement utilis\xe9 pour traiter des events \xe0 l’int\xe9rieur d’un bounded context, tout comme les events entre bounded contexts."}),"\n",(0,r.jsxs)(n.li,{children:["Il est aussi de plus en plus utilis\xe9 en remplacement des brokers traditionnels (",(0,r.jsx)(n.strong,{children:"RabbitMQ"}),", ",(0,r.jsx)(n.strong,{children:"ActiveMQ"}),", ",(0,r.jsx)(n.strong,{children:"AWS SQS/SNS"}),", ",(0,r.jsx)(n.strong,{children:"Google Cloud Pub/Sub"})," etc.). Dans ce cas, les records ne correspondent pas forc\xe9ment \xe0 des events, et on n’est pas forc\xe9ment dans de l’EDA."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"partitions"})," sont l’unit\xe9 de stream principale qui contiennent les records.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les records d’une m\xeame partition sont ",(0,r.jsx)(n.em,{children:"totally ordered"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Les records publi\xe9s dans une partition par un m\xeame producer seront donc aussi ",(0,r.jsx)(n.em,{children:"causally ordered"})," (la pr\xe9c\xe9dence respect\xe9e).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En revanche, si plusieurs producers publient dans la m\xeame partition sans eux-m\xeames se synchroniser entre eux, les records de chaque producer seront causally ordered pour un m\xeame producer, mais ne le seront pas entre les producers (\xe7a d\xe9pendra de qui l’a emport\xe9 pour publier plus vite)."}),"\n",(0,r.jsx)(n.li,{children:"Publier dans plusieurs partitions ne r\xe8gle pas ce probl\xe8me : les records de chaque producer ne seront pas causally ordered. Si on veut un tel ordre, il faut un seul producer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les ",(0,r.jsx)(n.strong,{children:"topics"})," sont des unit\xe9s logiques qui regroupent des partitions.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Vu qu’il s’agit d’une union de partitions qui sont chacune ",(0,r.jsx)(n.em,{children:"totally ordered"}),", les topics peuvent \xeatre consid\xe9r\xe9s comme ",(0,r.jsx)(n.em,{children:"partially ordered"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut donc \xe9crire dans les records de plusieurs partitions en parall\xe8le, et n’assurer que l’ordre des records dans chaque partition."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut indiquer \xe0 la main la partition vers laquelle on veut publier un record, mais g\xe9n\xe9ralement on indique la key, qui sera hash\xe9e pour correspondre avec une partition donn\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on ",(0,r.jsx)(n.strong,{children:"r\xe9duit le nombre de partitions"}),", les messages peuvent \xeatre ",(0,r.jsx)(n.strong,{children:"d\xe9truits"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on ",(0,r.jsx)(n.strong,{children:"augmente le nombre de partitions"}),", on peut ",(0,r.jsx)(n.strong,{children:"perdre l’ordre"})," qu’on voulait conserver avec nos keys, puisque la fonction de hash redirigera vers une autre partition."]}),"\n",(0,r.jsxs)(n.li,{children:["M\xeame si on a un nombre de partitions sup\xe9rieur au nombre de keys, il est possible que deux keys m\xe8nent vers la m\xeame partition.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La seule chose qui est garantie, c’est qu’avec la m\xeame key, et si le nombre de partitions ne change pas, l’ordre sera respect\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un consumer peut souscrire \xe0 un topic en tant que membre d’un ",(0,r.jsx)(n.strong,{children:"consumer group"}),", et b\xe9n\xe9ficier d’un m\xe9canisme de ",(0,r.jsx)(n.strong,{children:"load balancing"})," avec d’autres consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le 1er consumer qui souscrit se voit assigner toutes les partitions. Quand un 2\xe8me consumer souscrit au topic, il se voit assigner environ la moiti\xe9 des partitions qui \xe9taient assign\xe9es au 1er. et ainsi de suite."}),"\n",(0,r.jsxs)(n.li,{children:["Les consumers ne peuvent que lire les events sans impact sur eux.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Une des cons\xe9quences c’est qu’on peut en ajouter beaucoup sans stresser le cluster. Et c’est une des diff\xe9rences par rapport aux brokers classiques."}),"\n",(0,r.jsx)(n.li,{children:"Ils maintiennent les offsets de l\xe0 o\xf9 ils en sont pour chacune des partitions qu’ils sont en train de lire."}),"\n",(0,r.jsx)(n.li,{children:"Les consumers de diff\xe9rents consumer groups n’ont pas d’impact les uns sur les autres."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Kafka s’assure qu’il n’y a ",(0,r.jsx)(n.strong,{children:"qu’un consumer d’un m\xeame consumer group"})," qui peut lire dans une ",(0,r.jsx)(n.strong,{children:"m\xeame partition"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si un consumer ne lit plus de messages jusqu’\xe0 d\xe9passer un timeout, Kafka assignera ses partitions \xe0 un autre consumer, consid\xe9r\xe9 comme sain, du m\xeame groupe."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour que Kafka puisse r\xe9assigner une partition \xe0 un autre consumer en gardant le bon offset, ou redonner le bon offset \xe0 un consumer qui se reconnecte apr\xe8s s’\xeatre d\xe9connect\xe9, il faut que ",(0,r.jsx)(n.strong,{children:"les consumers communiquent leurs offsets \xe0 Kafka"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On appelle ce processus ",(0,r.jsx)(n.em,{children:"committing offsets"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir un contr\xf4le sur le ",(0,r.jsx)(n.strong,{children:"moment o\xf9 on va faire ce commit"}),", et donc agir sur la ",(0,r.jsx)(n.strong,{children:"garantie de delivery"})," des messages, c’est-\xe0-dire le fait qu’ils soient int\xe9gralement trait\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut passer d’une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-most-once"})," \xe0 une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-least-once"})," en faisant le commit apr\xe8s l’ex\xe9cution de la callback au lieu du moment o\xf9 le message est pris par le consumer."]}),"\n",(0,r.jsxs)(n.li,{children:["Par d\xe9faut, Kafka va faire un commit toutes les 5 secondes, sauf si un record est toujours en train d‘\xeatre ex\xe9cut\xe9, auquel cas il attendra la prochaine occasion 5 secondes plus tard.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut r\xe9gler cette dur\xe9e de 5 secondes \xe0 une autre valeur avec la configuration ",(0,r.jsx)(n.code,{children:"auto.commit.interval.ms"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"\xc7a implique que si le record est ex\xe9cut\xe9, et que dans les quelques secondes apr\xe8s, le cluster bascule la partition sur un autre consumer, on risque de ne pas avoir commit\xe9 et de r\xe9ex\xe9cuter la callback du record dans le nouveau consumer."}),"\n",(0,r.jsxs)(n.li,{children:["Si on veut avoir le contr\xf4le sur le moment exact o\xf9 on veut faire le commit, on peut d\xe9sactiver le commit automatique (configuration ",(0,r.jsx)(n.code,{children:"enable.auto.commit"})," \xe0 ",(0,r.jsx)(n.code,{children:"false"}),"), et le faire \xe0 la main dans le consumer."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le commit peut se faire via un canal in-memory asynchrone pour ne pas bloquer le consumer, avec la possibilit\xe9 de fournir une callback qui sera ex\xe9cut\xe9e par Kafka quand le commit aura \xe9t\xe9 pris en compte","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ou alors le consumer peut aussi utiliser un appel synchrone pour le commit."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un cas classique est de traiter les records avec une strat\xe9gie ",(0,r.jsx)(n.em,{children:"at-least-once"})," par batch, qu’on appelle ",(0,r.jsx)(n.em,{children:"poll-process loop"})," :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer garde un buffer de records qu’il prefetch en arri\xe8re-plan."}),"\n",(0,r.jsx)(n.li,{children:"Il traite les records un par un (ou parfois en parall\xe8le avec un pool de threads si c’est OK d’un point de vue business)."}),"\n",(0,r.jsx)(n.li,{children:"Quand on arrive au dernier record, il fait le commit de l’offset."}),"\n",(0,r.jsx)(n.li,{children:"Puis il prend le batch suivant et recommence."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["M\xeame si c’est moins courant, il est possible de souscrire un consumer ",(0,r.jsx)(n.strong,{children:"sans qu’il soit membre d’un consumer group"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans ce cas, il ne b\xe9n\xe9ficiera pas des divers m\xe9canismes associ\xe9s aux consumer groups : load balancing, rebalancing en cas d’\xe9chec, d\xe9tection de l’\xe9chec par inactivit\xe9, persistance de l’offset.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il devra indiquer les couples topic/partition auxquels il souscrit, et devra persister ses propres offsets lui-m\xeame dans un store."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il peut y avoir deux cas d’usages :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le besoin d’avoir vraiment le contr\xf4le sur la mani\xe8re de consommer les messages, en stockant soi-m\xeame son offset etc.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Mais ce cas d’usage est tr\xe8s rare, et difficile \xe0 impl\xe9menter correctement."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Un consumer \xe9ph\xe9m\xe8re qui est l\xe0 juste pour monitorer ou d\xe9bugger un topic, sans avoir besoin de persister d’offsets.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est ce que fait par exemple l’outil Kafdrop qui permet de visualiser les messages pr\xe9sents dans les partitions via une interface web : \xe0 chaque fois il attache un consumer sans groupe."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"4---installation",children:"4 - Installation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il y a 4 m\xe9thodes pour installer Kafka (et Zookeeper) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En utilisant les images Docker.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si on choisit une autre m\xe9thode que Docker, on aura juste besoin d’avoir d’avoir un JDK d’install\xe9."}),"\n",(0,r.jsx)(n.li,{children:"La m\xe9thode Kafka dans Docker est la plus imm\xe9diate pour avoir Kafka qui tourne, mais elle est aussi connue pour \xeatre difficile \xe0 configurer si on veut personnaliser."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"En utilisant un package manager (yum, apt, homebrew etc.)"}),"\n",(0,r.jsx)(n.li,{children:"En clonant le d\xe9p\xf4t git et en installant depuis les sources."}),"\n",(0,r.jsxs)(n.li,{children:["En t\xe9l\xe9chargeant des binaires sur le site de Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il suffit de t\xe9l\xe9charger un tar.gz et de le d\xe9sarchiver, pour obtenir les ex\xe9cutables de Kafka qu’on peut lancer avec notre JDK."}),"\n",(0,r.jsx)(n.li,{children:"Le livre part l\xe0-dessus."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration de Kafka peut se faire en changeant les fichiers de conf dans le dossier ",(0,r.jsx)(n.code,{children:"config/"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut voir les configs prises en compte dans les logs, \xe0 chaque fois qu’on d\xe9marre Kafka."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"5---getting-started",children:"5 - Getting Started"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On a du tooling livr\xe9 avec Kafka sous forme de scripts shell pour le g\xe9rer en CLI.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut par exemple cr\xe9er un topic puis y ajouter des records."}),"\n",(0,r.jsx)(n.li,{children:"On peut changer des offsets pour un consumer group."}),"\n",(0,r.jsx)(n.li,{children:"etc."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’auteur ",(0,r.jsx)(n.strong,{children:"d\xe9conseille de laisser Kafka cr\xe9er automatiquement les topics"})," (",(0,r.jsx)(n.code,{children:"auto.create.topics.enable"})," \xe0 ",(0,r.jsx)(n.code,{children:"true"}),") pour plusieurs raisons :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Les valeurs par d\xe9faut de Kafka remontent \xe0 sa cr\xe9ation, et n’ont pas forc\xe9ment \xe9t\xe9 pens\xe9s pour l’usage qu’il a en g\xe9n\xe9ral aujourd’hui."}),"\n",(0,r.jsx)(n.li,{children:"Quand on cr\xe9e un topic, on devrait d\xe9cider du nombre de partitions en fonction des crit\xe8res de parall\xe9lisation. Donc un nombre par d\xe9faut ne va en g\xe9n\xe9ral pas \xeatre satisfaisant."}),"\n",(0,r.jsx)(n.li,{children:"La cr\xe9ation de topic \xe0 la lecture est encore plus probl\xe9matique, puisqu’on va avoir des lecteurs qui croient lire quelque chose et qui ne lisent rien."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.em,{children:"lag"})," est la diff\xe9rence entre l’offset qui a \xe9t\xe9 commit\xe9 par un consumer sur une partition donn\xe9e et le ",(0,r.jsx)(n.em,{children:"high water mark"})," de la partition (c’est-\xe0-dire le dernier record dispo \xe0 la consommation)."]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"suppression d’un topic est asynchrone"}),", c’est-\xe0-dire qu’elle sera effectivement r\xe9alis\xe9e quelque part dans le futur par Kafka, apr\xe8s qu’on l’ait demand\xe9e.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour nos ",(0,r.jsx)(n.strong,{children:"tests d’int\xe9gration"}),", il va donc falloir trouver des solutions :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Supprimer le consumer group, les offsets enregistr\xe9s, ou mettre les offsets au high water mark (tous les trois ont le m\xeame effet)."}),"\n",(0,r.jsxs)(n.li,{children:["2 - Tronquer les partitions en avan\xe7ant le ",(0,r.jsx)(n.em,{children:"low water mark"})," (le record le plus ancien disponible \xe0 la consommation)."]}),"\n",(0,r.jsxs)(n.li,{children:["3 - Utiliser des noms de topics uniques, et les supprimer au fil de l’eau (si on ne les r\xe9utilise pas, le fait qu’ils soient supprim\xe9s de mani\xe8re asynchrone ne pose probl\xe8me).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette derni\xe8re option est celle recommand\xe9e par l’auteur."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Supprimer les offsets pour un consumer group et sur un topic donn\xe9, fait que la prochaine fois que ces consumers voudront consommer le topic, ils seront par d\xe9faut assign\xe9s au dernier record.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ou au premier en fonction de l’option ",(0,r.jsx)(n.code,{children:"auto.offset.reset"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Si on supprimer un consumer group, c’est comme si on supprimait ses offsets pour l’ensemble des topics o\xf9 il avait consomm\xe9 des records."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’essentiel des classes du client Java se r\xe9sument \xe0 :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["1 - L’interface ",(0,r.jsx)(n.code,{children:"Producer"}),", l’impl\xe9mentation ",(0,r.jsx)(n.code,{children:"KafkaProducer"}),", et la repr\xe9sentation du record ",(0,r.jsx)(n.code,{children:"ProducerRecord"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["2 - La m\xeame chose c\xf4t\xe9 consumer : ",(0,r.jsx)(n.code,{children:"Consumer"}),", ",(0,r.jsx)(n.code,{children:"KafkaConsumer"}),", ",(0,r.jsx)(n.code,{children:"ConsumerRecord"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Et c’est \xe0 peu pr\xe8s la m\xeame chose pour les autres clients qui s’en inspirent."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["L’option ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," \xe0 la cr\xe9ation du producer permet de garder des s\xe9quences pour les couples producer/partition, pour s’assurer qu’un record n’est pas publi\xe9 deux fois ou dans le mauvais ordre, dans le cas o\xf9 il y aurait un timeout pendant une publication.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L’auteur conseille de l’activer."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Il faut bien penser \xe0 fermer la connexion, sinon on risque de monopoliser des ressources c\xf4t\xe9 client et serveur."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"6---design-considerations",children:"6 - Design Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["A propos de la s\xe9paration des ",(0,r.jsx)(n.strong,{children:"responsabilit\xe9s"})," entre producers et consumers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Dans le cas d’un ",(0,r.jsx)(n.strong,{children:"event-oriented broadcast"}),", c’est le producer qui a la responsabilit\xe9 de la configuration du topic et du format des donn\xe9es publi\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est utile pour que les producers ne connaissent pas du tout les consumers, et qu’on reste sur du couplage faible."}),"\n",(0,r.jsxs)(n.li,{children:["Le fait qu’on puisse avoir plusieurs consumers aux int\xe9r\xeats diff\xe9rents montre qu’il est plus pertinent que le producer ait la responsabilit\xe9 des messages.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour autant, on peut se demander comment faire en sorte que les consumers soient tous satisfaits par le mod\xe8le propos\xe9 par le producer."}),"\n",(0,r.jsxs)(n.li,{children:["On peut mettre en place du ",(0,r.jsx)(n.strong,{children:"topic conditioning"}),", c’est-\xe0-dire compartimenter les probl\xe8mes li\xe9s \xe0 chaque consumer avec une architecture SEDA, contenant pour chaque consumer (ou groupe de consumers aux int\xe9r\xeats communs), un module de conditionnement publiant \xe0 son tour dans un topic pour le consumer vis\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette solution permet de s\xe9parer les responsabilit\xe9s, et laisser le producer avec son mod\xe8le, et chaque consumer avec le sien."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour du ",(0,r.jsx)(n.strong,{children:"peer-to-peer messaging"}),", c’est au contraire le consumer qui a la responsabilit\xe9 de la configuration du topic et du format de donn\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le consumer envoie des commandes au producer, pour que celui-ci lui pr\xe9pare des donn\xe9es qu’il mettra dans Kafka."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Dans tous les cas, les flows doivent \xeatre design\xe9s avec soin, en prenant en compte les besoins des producers et des consumers."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Concernant la question du ",(0,r.jsx)(n.strong,{children:"parall\xe9lisme"})," dans le cas o\xf9 on veut laisser plusieurs consumers consommer depuis plusieurs partitions, il y a des facteurs \xe0 prendre en compte pour obtenir quelque chose de performant.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L’organisation des partitions d’un topic est ",(0,r.jsx)(n.strong,{children:"consumer-driven"}),", du fait du design de Kafka. Le consumer se pose la question de la ",(0,r.jsx)(n.strong,{children:"bonne cl\xe9 de partitionnement"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En pratique, le consumer doit trouver une entit\xe9 suffisamment stable pour que son identifiant puisse servir de cl\xe9 de partitionnement."}),"\n",(0,r.jsx)(n.li,{children:"Par exemple, si on a des tournois de football, avec des events repr\xe9sentant ce qui se passe dans le jeu, on peut prendre le match comme entit\xe9 stable, et avoir tous les events d’un m\xeame match ordonn\xe9s dans une m\xeame partition."}),"\n",(0,r.jsxs)(n.li,{children:["Si on garde l’exemple mais qu’un consumer est int\xe9ress\xe9 par le d\xe9roulement du tournoi, alors il nous faudra garder l’ordre des matchs, et donc choisir comme entit\xe9 stable le tournoi.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Mais on aura alors moins de possibilit\xe9s de parall\xe9lisation puisqu’on ne pourra plus parall\xe9liser les matchs."}),"\n",(0,r.jsx)(n.li,{children:"L’autre possibilit\xe9 c’est de laisser le consumer qui a besoin de l’ordre des tournois le reconstituer lui-m\xeame, avec des infos qu’il a dans les events."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Se pose ensuite la question du ",(0,r.jsx)(n.strong,{children:"nombre de partitions du topic"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour rappel on ne peut pas enlever de partitions sans d\xe9truire de messages, et en rajouter fait que la fonction de hash n’envoie plus dans les m\xeames partitions qu’avant le rajout (donc il vaut mieux \xe9viter si on veut garder l’ordre des messages)."}),"\n",(0,r.jsxs)(n.li,{children:["Une solution peut \xeatre d’avoir d\xe8s le d\xe9but un ",(0,r.jsx)(n.strong,{children:"nombre suffisamment \xe9lev\xe9 de partitions par topic"}),", pour ne jamais avoir \xe0 les augmenter.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Attention cependant, trop de partitions peut causer des probl\xe8mes de performance."}),"\n",(0,r.jsxs)(n.li,{children:["Confluent recommande ",(0,r.jsx)(n.code,{children:"100 x b x r"})," partitions (avec ",(0,r.jsx)(n.code,{children:"b"})," le nombre de brokers du cluster, et ",(0,r.jsx)(n.code,{children:"r"})," le facteur de r\xe9plication)."]}),"\n",(0,r.jsx)(n.li,{children:"Si on atteint le nombre maximal de partitions qu’on avait pr\xe9vu, une technique peut \xeatre de cr\xe9er un nouveau topic avec plus de partitions, et de copier l’ensemble des messages de l’ancien topic vers le nouveau. \xc7a n\xe9cessite un peu d’effort."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le ",(0,r.jsx)(n.strong,{children:"nombre de consumers"})," dans un consumer group doit \xeatre au moins aussi grand que le nombre de partitions si on veut profiter du maximum de parall\xe9lisme.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par contre, allouer un tel nombre peut aussi mener \xe0 du g\xe2chis de ressources, vu que le broker ne fonctionne pas forc\xe9ment en flux tendu."}),"\n",(0,r.jsx)(n.li,{children:"On peut alors plut\xf4t allouer un nombre variable de consumers au groupe, bas\xe9 sur l’activit\xe9 du cluster."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Enfin on peut envisager d’avoir du ",(0,r.jsx)(n.strong,{children:"parall\xe9lisme \xe0 l’int\xe9rieur des consumers"}),", en g\xe9rant plusieurs threads, pour traiter plusieurs records en m\xeame temps."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la question de la ",(0,r.jsx)(n.strong,{children:"delivery des messages"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On parle ici de “delivery” au sens o\xf9 les messages sont trait\xe9s jusqu’au bout par les consumers, pas juste du fait qu’ils soient disponibles \xe0 la lecture (\xe7a, ils le restent de toute fa\xe7on pour tous les consumers d\xe8s lors que la publication a march\xe9)."}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir une delivery ",(0,r.jsx)(n.strong,{children:"at-most-once"}),", en faisant le commit d\xe8s le d\xe9but de la lecture.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est utile dans les cas o\xf9 la perte occasionnelle de donn\xe9e n’est pas grave, et ne laisse pas le syst\xe8me consommateur dans un \xe9tat inconsistant de mani\xe8re permanente."}),"\n",(0,r.jsx)(n.li,{children:"Ca peut \xeatre aussi parce que faire l’action deux fois pose probl\xe8me, alors le que le fait de la rater de temps en temps non."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On peut avoir une delivery ",(0,r.jsx)(n.strong,{children:"at-least-once"}),", en ne faisant le commit qu’apr\xe8s ex\xe9cution compl\xe8te de la callback du consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est utile dans le cas o\xf9 la perte de donn\xe9e n’est pas acceptable, et o\xf9 on est pr\xeat \xe0 recommencer certains messages pour l’\xe9viter."}),"\n",(0,r.jsx)(n.li,{children:"Par contre on doit \xeatre pr\xeat \xe0 avoir la callback potentiellement ex\xe9cut\xe9e plusieurs fois."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Et enfin, si on veut une delivery ",(0,r.jsx)(n.strong,{children:"exactly-once"}),", on ne peut malheureusement pas compter sur le message broker \xe0 lui seul, on doit s’assurer d’avoir un flow ",(0,r.jsx)(n.strong,{children:"idempotent"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On pourrait le vouloir pour avoir \xe0 la fois la consistance parce que la perte de donn\xe9e ou le fait de ne pas faire une action n’est pas acceptable, mais o\xf9 le fait de le faire deux fois n’est pas acceptable non plus."}),"\n",(0,r.jsxs)(n.li,{children:["Pour r\xe9ussir \xe7a, on a besoin d’avoir une ",(0,r.jsx)(n.strong,{children:"idempotence de bout en bout"}),", c’est \xe0 dire que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La callback du consumer ne doit faire que des changements idempotents. Par exemple un update en DB qui ne change pas l’\xe9tat de la DB quand il est jou\xe9 plusieurs fois."}),"\n",(0,r.jsx)(n.li,{children:"Le consumer doit v\xe9rifier si les side-effects qu’il fait ont d\xe9j\xe0 \xe9t\xe9 faits pour ne pas les refaire une 2\xe8me fois. Par exemple, Kafka offre un m\xe9canisme de transaction qui permet de ne publier qu’une fois dans un topic sortant pour un message d’un topic entrant."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas o\xf9 on ne peut pas savoir si le side-effect a d\xe9j\xe0 \xe9t\xe9 fait ou pas, il faut que le side-effect lui-m\xeame soit rendu idempotent de bout en bout."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"7---serialization",children:"7 - Serialization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le client Java a des serializers de base et une interface \xe0 impl\xe9menter pour cr\xe9er des serializers Kafka custom.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour l’auteur, m\xeame si cette approche est idiomatique, il vaut mieux avoir Kafka et tout ce qui y est li\xe9 isol\xe9 dans une couche de messaging pour que la logique business n’y soit pas li\xe9e et soit testable.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["L’auteur pr\xe9f\xe8re ",(0,r.jsx)(n.strong,{children:"laisser la s\xe9rialisation c\xf4t\xe9 logique business"}),", et donc conseille de ne pas utiliser les serializers custom de Kafka dans ce cas."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Et de la m\xeame mani\xe8re, les choses sp\xe9cifiques \xe0 Kafka comme le fait de mettre l’ID des customers comme cl\xe9, doivent \xeatre dans la couche de messaging pour \xeatre les m\xeames pour tous les use cases."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on est en mode ",(0,r.jsx)(n.strong,{children:"commit manuel"}),", on peut appeler la fonction qui fait le commit de mani\xe8re asynchrone ",(0,r.jsx)(n.strong,{children:"sans l’attendre"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a aura pour effet d’avoir plus d’offsets pas encore commit\xe9s mais un throughput plus \xe9lev\xe9."}),"\n",(0,r.jsx)(n.li,{children:"On respecte quand m\xeame le at-least-one delivery."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on utilise le m\xe9canisme de poll-process loop (o\xf9 on consomme les messages par batch), le client Java va avoir deux threads : un pour aller chercher plus de records et un autre pour faire le processing des records qui sont d\xe9j\xe0 l\xe0.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Il s’agit l\xe0 d’un m\xe9canisme de ",(0,r.jsx)(n.strong,{children:"pipelining"}),", o\xf9 la 1\xe8re \xe9tape va chercher de la donn\xe9e pour la mettre dans le buffer suivant jusqu’\xe0 ce que le buffer soit plein, auquel cas elle attend avant de continuer."]}),"\n",(0,r.jsxs)(n.li,{children:["L’auteur propose une version encore plus parall\xe9lis\xe9e, en ajoutant une 3\xe8me \xe9tape dans la pipeline pour s\xe9parer la d\xe9s\xe9rialisation du reste du traitement du message.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L’avantage c’est que \xe7a peut augmenter le throughput, mais l’inconv\xe9nient c’est une utilisation plus intensive du CPU."}),"\n",(0,r.jsx)(n.li,{children:"Il faut cr\xe9er un thread \xe0 la main, et g\xe9rer la communication inter-thread \xe0 travers un buffer, avec tous les edge cases li\xe9s au parall\xe9lisme."}),"\n",(0,r.jsxs)(n.li,{children:["Selon l’auteur, cette technique a du sens parce que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"L’utilisation de Kafka est souvent associ\xe9e \xe0 des cas d’usages qui ont besoin de performance."}),"\n",(0,r.jsx)(n.li,{children:"Elle ajoute de la complexit\xe9, mais qu’on n’a \xe0 faire qu’une fois et qu’on peut isoler dans un adapter qu’on r\xe9utilise."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"C\xf4t\xe9 publisher \xe7a aurait moins de sens vu que la s\xe9rialisation est moins co\xfbteuse que la d\xe9s\xe9rialisation."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il peut \xeatre pertinent de ",(0,r.jsx)(n.strong,{children:"filtrer des messages au niveau de la couche adapter"})," du consumer Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple, si le topic contient plus de messages que ce que le use-case qui le consomme peut ou veut d\xe9s\xe9rialiser.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre parce que le producer publie les messages plusieurs fois, en indiquant la version du sch\xe9ma dans le header, et qu’on ne veut en lire qu’une version sans avoir \xe0 parser les autres."}),"\n",(0,r.jsx)(n.li,{children:"\xc7a peut aussi \xeatre un topic qui contient plusieurs types de messages, dont on ne veut traiter qu’un type."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"8---bootstrapping-and-advertised-listeners",children:"8 - Bootstrapping and Advertised Listeners"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Chaque partition a un leader broker, et ",(0,r.jsx)(n.code,{children:"n"})," follower brokers qui contiennent sa donn\xe9e (avec ",(0,r.jsx)(n.code,{children:"n + 1"})," \xe9tant le ",(0,r.jsx)(n.strong,{children:"replication factor"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:["Pour pouvoir \xe9crire un record, un client publisher doit l’envoyer au broker leader de la partition qui l’int\xe9resse.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le leader transf\xe9rera aux followers, mais on ne peut pas compter sur un des followers pour transf\xe9rer d’abord au leader."}),"\n",(0,r.jsxs)(n.li,{children:["\xc7a veut donc dire que ",(0,r.jsx)(n.strong,{children:"le client devra avoir une connexion directe"})," avec quasi tous (ou m\xeame tous) les brokers, vu que tous les brokers peuvent \xeatre des leaders de partitions et qu’il risque de vouloir en lire plusieurs."]}),"\n",(0,r.jsxs)(n.li,{children:["Les brokers sont au courant de la topologie du cluster parce qu’ils ont l’info partag\xe9e via ZooKeeper.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le client peut donc ",(0,r.jsx)(n.strong,{children:"demander la liste des adresses IP des brokers \xe0 n’importe lequel d’entre eux"}),". Et donc, pour peu qu’il ait au moins une adresse de broker valide, il peut r\xe9obtenir toutes les autres."]}),"\n",(0,r.jsxs)(n.li,{children:["Le client est initialement fourni avec une ",(0,r.jsx)(n.em,{children:"bootstrap list"})," des brokers, et ensuite se d\xe9brouille pour la mettre \xe0 jour en leur demandant."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Cette technique de base de demander la liste des adresses \xe0 au moins un broker dont on a l’adresse valide n’est pas super fiable : si le client n’a plus aucune adresse valide parce qu’elles ont toutes chang\xe9, il est coinc\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ce que fait la communaut\xe9 pour r\xe9pondre \xe0 cette probl\xe9matique c’est d’utiliser des ",(0,r.jsx)(n.strong,{children:"alias DNS, pointant vers les bonnes adresses IP des brokers"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"La sp\xe9cification DNS permet m\xeame d’indiquer un seul nom qui sera associ\xe9 \xe0 une liste d’adresses IP pointant vers chacun des brokers."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il y a un probl\xe8me classique de configuration auquel beaucoup de monde se heurte, et qui emp\xeache la connexion du client aux brokers : le client demande la liste des adresses, et le broker lui r\xe9pond des adresses en ",(0,r.jsx)(n.code,{children:"localhost"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La solution est de configurer les ",(0,r.jsx)(n.strong,{children:"advertised listeners"})," dans le fichier ",(0,r.jsx)(n.code,{children:"config/server.properties"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Les propri\xe9t\xe9s sont initialement comment\xe9es dans le fichier, et donc c’est les valeurs par d\xe9faut qui s’appliquent (on peut les retrouver dans la ",(0,r.jsx)(n.a,{href:"https://kafka.apache.org/documentation/#brokerconfigs",children:"documentation de Kafka"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"advertised.listeners"})," permet d’indiquer les URI qui seront envoy\xe9es aux clients qui demandent la liste des adresses des brokers. C’est \xe7a qu’il faut configurer avec le bon hostname pour r\xe9soudre le probl\xe8me de config."]}),"\n",(0,r.jsxs)(n.li,{children:["Dans le cas o\xf9 on a des clients situ\xe9s dans des environnements r\xe9seau diff\xe9rents, on a besoin de leur advertiser des adresses diff\xe9rentes pour les m\xeames brokers.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est le cas par exemple si on a un VPC (virtual private cloud) avec le cluster Kafka et des clients, et d’autres clients situ\xe9s \xe0 l’ext\xe9rieur et ne pouvant pas acc\xe9der aux adresses IP internes au VPC."}),"\n",(0,r.jsxs)(n.li,{children:["Dans ce cas, on va pouvoir configurer plusieurs URI sur lesquels \xe9coute chaque broker (dans ",(0,r.jsx)(n.code,{children:"listeners"}),"), et plusieurs URI qui sont advertised (dans ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il faut faire attention \xe0 indiquer des ports diff\xe9rents pour chacune des URI si on ne veut pas de probl\xe8mes."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Les probl\xe9matiques de bootstrapping se posent largement dans les environnements conteneuris\xe9s. La simple utilisation de ",(0,r.jsx)(n.strong,{children:"docker-compose"})," nous am\xe8ne \xe0 avoir l’\xe9quivalent d’un VPC interne aux containers lanc\xe9s par docker-compose, et un mapping de port vers la machine h\xf4te.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Exemple de config Kafka dans un docker-compose :","\n",(0,r.jsx)(n.pre,{"data-language":"yml","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"yml","data-theme":"default",children:[(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"kafka"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"image"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"bitnami/kafka:2"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"ports"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    - "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"9092:9092"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"environment"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_CFG_ZOOKEEPER_CONNECT"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"zookeeper:2181"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"ALLOW_PLAINTEXT_LISTENER"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"yes"'})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_LISTENERS"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL://:29092,EXTERNAL://:9092"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_ADVERTISED_LISTENERS"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL://kafka:29092,EXTERNAL://localhost:9092"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_LISTENER_SECURITY_PROTOCOL_MAP"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:">-"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"      INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"})}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"KAFKA_INTER_BROKER_LISTENER_NAME"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:'"INTERNAL"'})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"  "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:"depends_on"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-keyword)"},children:":"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    - "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string-expression)"},children:"zookeeper"})]})]})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["On d\xe9finit ici deux protocoles propres \xe0 Kafka (et associ\xe9s au type ",(0,r.jsx)(n.code,{children:"PLAINTEXT"}),", donc non s\xe9curis\xe9s) : un qu’on appelle ",(0,r.jsx)(n.code,{children:"INTERNAL"})," pour l’URI depuis le r\xe9seau interne des containers docker-compose, et un autre qu’on appelle ",(0,r.jsx)(n.code,{children:"EXTERNAL"})," pour le r\xe9seau de l’h\xf4te."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_LISTENERS"})," est l’\xe9quivalent de ",(0,r.jsx)(n.code,{children:"listeners"})," dans ",(0,r.jsx)(n.code,{children:"config/server.properties"}),", c’est-\xe0-dire les sockets sur lesquels le broker \xe9coute.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On choisit deux ports diff\xe9rents qui permettent de diff\xe9rencier les connexions internes et externes, et on indique qu’on \xe9coute sur toutes les interfaces possibles (en n’indiquant aucun hostname ni adresse IP)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_ADVERTISED_LISTENERS"})," est l’\xe9quivalent de ",(0,r.jsx)(n.code,{children:"advertised.listeners"}),", c’est-\xe0-dire les adresses URI communiqu\xe9es aux clients pour joindre le broker.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On indique bien le hostname ",(0,r.jsx)(n.code,{children:"localhost"})," aux clients du r\xe9seau externe, et le hostname ",(0,r.jsx)(n.code,{children:"kafka"})," aux clients du r\xe9seau interne (le nom des containers sert aussi de hostname dans docker-compose)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"KAFKA_INTER_BROKER_LISTENER_NAME"})," permet d’indiquer quel protocole doit \xeatre utilis\xe9 pour la communication avec les autres brokers du cluster."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"depends_on"})," permet d’indiquer l’ordre dans lequel on start les containers dans docker-compose."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"9---broker-configuration",children:"9 - Broker Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La configuration peut se faire sur 4 entit\xe9s de Kafka : les ",(0,r.jsx)(n.strong,{children:"brokers"}),", les ",(0,r.jsx)(n.strong,{children:"topics"}),", les ",(0,r.jsx)(n.strong,{children:"clients"})," et les ",(0,r.jsx)(n.strong,{children:"users"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Il existe une ",(0,r.jsx)(n.strong,{children:"configuration statique"})," et une ",(0,r.jsx)(n.strong,{children:"configuration dynamique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Historiquement la configuration dynamique a \xe9t\xe9 introduite pour faciliter l’administration de gros clusters, et pour ne plus avoir besoin de restart.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La communaut\xe9 a d\xe9cid\xe9 qu’enlever la configuration statique \xe9tait trop radical, donc elle a \xe9t\xe9 gard\xe9e en fallback."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration statique se fait en changeant le fichier ",(0,r.jsx)(n.code,{children:"config/server.properties"})," et en red\xe9marrant le broker."]}),"\n",(0,r.jsxs)(n.li,{children:["La configuration dynamique se fait via l’admin API de Kafka, au niveau du broker ou du cluster entier.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Elle est stock\xe9e dans Zookeeper, mais ne n\xe9cessite pas la communication directe avec Zookeeper pour faire des modifications de config."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["C\xf4t\xe9 ",(0,r.jsx)(n.strong,{children:"pr\xe9c\xe9dence"}),", c’est d’abord la config dynamique par entit\xe9 qui prend le pas, puis la config dynamique au niveau du cluster, et enfin la config statique.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si rien n’est d\xe9fini, les valeurs par d\xe9faut s’appliquent."}),"\n",(0,r.jsx)(n.li,{children:"Dans le cas de propri\xe9t\xe9s d\xe9pr\xe9ci\xe9es et remplac\xe9es par d’autres, les propri\xe9t\xe9s d\xe9pr\xe9ci\xe9es sont prises en compte si elles sont utilis\xe9es, et sinon c’est la valeur par d\xe9faut des nouvelles propri\xe9t\xe9s qui est prise en compte."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quelques infos sur les ",(0,r.jsx)(n.strong,{children:"changements de config des brokers"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Sur la configuration ",(0,r.jsx)(n.strong,{children:"statique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Toutes les propri\xe9t\xe9s de ",(0,r.jsx)(n.code,{children:"config/server.properties"})," sont optionnelles, sauf ",(0,r.jsx)(n.code,{children:"zookeeper.connect"})," qui contient la liste des adresses des nœuds ZooKeeper."]}),"\n",(0,r.jsxs)(n.li,{children:["Il est consid\xe9r\xe9 comme une bonne pratique de sp\xe9cifier la propri\xe9t\xe9 ",(0,r.jsx)(n.code,{children:"broker.id"})," qui repr\xe9sente l’identifiant du broker. Si on ne le fait pas, ZooKeeper assignera un ID automatiquement \xe0 chaque broker (par d\xe9faut en commen\xe7ant par ",(0,r.jsx)(n.code,{children:"1001"}),").","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Pour changer cette propri\xe9t\xe9, il faut :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D’abord arr\xeater le broker."}),"\n",(0,r.jsxs)(n.li,{children:["Faire le changement dans ",(0,r.jsx)(n.code,{children:"server.properties"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Faire le changement dans le fichier ",(0,r.jsx)(n.code,{children:"meta.properties"})," (qui se trouve dans le dossier de log du broker), ou m\xeame supprimer le fichier ",(0,r.jsx)(n.code,{children:"meta.properties"})," qui sera r\xe9g\xe9n\xe9r\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le dossier de log contient des fichiers essentiels avec l’info des partitions et des records (rien \xe0 voir avec du logging)."}),"\n",(0,r.jsxs)(n.li,{children:["Son path est configur\xe9e avec l’option ",(0,r.jsx)(n.code,{children:"log.dirs"}),", par d\xe9faut c’est ",(0,r.jsx)(n.code,{children:"/tmp/kafka-logs"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Red\xe9marrer le broker."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Sur la configuration ",(0,r.jsx)(n.strong,{children:"dynamique"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["On peut changer la config via l’outil CLI fourni par Kafka sous forme de script bash : ",(0,r.jsx)(n.code,{children:"kafka-configs.sh"}),", ou via une librairie cliente qu’on tierce qui va se connecter \xe0 Kafka.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par exemple pour afficher la liste des configurations dynamiques pour le broker 1001 sur un Kafka qui tourne localement :","\n",(0,r.jsx)(n.pre,{"data-language":"bash","data-theme":"default",children:(0,r.jsxs)(n.code,{"data-language":"bash","data-theme":"default",children:[(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"."}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"/kafka-configs.sh"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    --bootstrap-server "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"localhost:"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"9092"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    --entity-"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-function)"},children:"type"}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:" "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-string)"},children:"brokers"})]}),"\n",(0,r.jsxs)(n.span,{className:"line",children:[(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    --entity-name "}),(0,r.jsx)(n.span,{style:{color:"var(--shiki-token-constant)"},children:"1001"})]}),"\n",(0,r.jsx)(n.span,{className:"line",children:(0,r.jsx)(n.span,{style:{color:"var(--shiki-color-text)"},children:"    --describe"})})]})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il faut faire attention avec les configurations dynamiques, on peut facilement mettre un cluster par terre si on fait une mauvaise manip.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Quand on modifie ",(0,r.jsx)(n.strong,{children:"une config pour tout le cluster"}),", c'est une bonne pratique de la modifier ",(0,r.jsx)(n.strong,{children:"d’abord pour un broker"}),", au cas o\xf9 elle aurait un impact non souhait\xe9 qui serait du coup plus limit\xe9."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["A propos de la ",(0,r.jsx)(n.strong,{children:"configuration des topics"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ils peuvent \xeatre configur\xe9s statiquement via ",(0,r.jsx)(n.code,{children:"config/server.properties"}),", ou dynamiquement au niveau du cluster (une configuration de topic par broker n’aurait pas de sens).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On peut aussi modifier dynamiquement certaines propri\xe9t\xe9s par topic."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"10---client-configuration",children:"10 - Client Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La configuration du client est beaucoup plus sensible, en partie parce qu’elle tombe ",(0,r.jsx)(n.strong,{children:"sous la responsabilit\xe9 des d\xe9veloppeurs applicatifs"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En g\xe9n\xe9ral la configuration des brokers se fait par des personnes sp\xe9cialistes de l’infra, g\xe9rant d’autres \xe9l\xe9ments d’infrastructure, et connaissant la mani\xe8re de g\xe9rer les risques.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"On voit aussi de plus un shift vers les versions de serveurs Kafka pr\xe9-configur\xe9es. \xc7a ne peut pas \xeatre le cas des clients."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"La plupart des probl\xe8mes"})," avec Kafka viennent d’une ",(0,r.jsx)(n.strong,{children:"mauvaise utilisation c\xf4t\xe9 client"}),", parce que les d\xe9veloppeurs ne le connaissent pas assez bien.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Exemple : il est notoire que Kafka offre des garanties importantes pour ce qui est de la durabilit\xe9 des records. Mais en r\xe9alit\xe9 \xe7a d\xe9pend des param\xe8tres.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il y a d\xe9j\xe0 la question du stockage, lui-m\xeame influenc\xe9 par le nombre de brokers."}),"\n",(0,r.jsxs)(n.li,{children:["Et ensuite il y a des configurations c\xf4t\xe9 client :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le replication factor et quelques autres pour ce qui est de s’assurer que la donn\xe9e reste en cas de probl\xe8me avec certaines machines."}),"\n",(0,r.jsx)(n.li,{children:"Le nombre d’acknowledgements que le broker leader de la partition doit demander avant de consid\xe9rer le record comme valid\xe9, et le fait d’attendre soi-m\xeame l’acknowledgement du leader avant de consid\xe9rer le message comme publi\xe9."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Les d\xe9veloppeurs imaginent aussi que le comportement par d\xe9faut de Kafka optimise la garantie d’ordre et de delivery des records. Mais ces valeurs sont issues de l’utilisation initiale de Linkedin qui avait surtout besoin de performance dans son cas d’usage."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"La 1\xe8re r\xe8gle de l’optimisation avec Kafka est : ne le faites pas"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"La plupart du temps, les configurations qui offrent des garanties vis-\xe0-vis des records n’ont pas un si grand impact que \xe7a. On peut attendre d’en avoir vraiment besoin."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ce qui est des ",(0,r.jsx)(n.strong,{children:"configurations communes"})," \xe0 tous les types de clients (producer, consumer, admin).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"bootstrap.servers"})," permet de contacter les brokers, mais ensuite le plus important c’est que les brokers envoient les bonnes adresses (cf. le chapitre pr\xe9c\xe9dent)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"client.dns.lookup"})," donne la possibilit\xe9 d’utiliser des alias DNS li\xe9s \xe0 plusieurs adresses."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"client.id"})," permet de d\xe9finir l’identifiant du client, comme on l’a fait pour le serveur dans le chapitre d’avant. \xc7a permet la tra\xe7abilit\xe9, et la gestion de quotas."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"retries"})," indique le nombre de fois qu’on va recommencer une op\xe9ration qui se termine par une erreur transiente, c’est-\xe0-dire qui peut potentiellement ne pas se reproduire en r\xe9essayant.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"retry.backoff.ms"})," indique la dur\xe9e d’attente avant de r\xe9essayer."]}),"\n",(0,r.jsx)(n.li,{children:"Par d\xe9faut on bourrine, en recommen\xe7ant un nombre infini de fois toutes les 100 ms."}),"\n",(0,r.jsx)(n.li,{children:"L’autre possibilit\xe9 c’est en gros de limiter les retries, en ayant conscience que du coup on se retrouvera \xe0 un moment o\xf9 un autre \xe0 avoir des op\xe9rations qui sont en erreur pour des raisons temporaires. Mais on ne bloquera pas pendant longtemps."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Quand on veut utiliser Kafka dans des ",(0,r.jsx)(n.strong,{children:"tests d’int\xe9gration"}),", il faut prendre en compte que le fait de le lancer dans un environnement virtualis\xe9 type Docker va ralentir consid\xe9rablement son d\xe9marrage.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Le fait que Kafka \xe9coute sur le port ne suffit pas pour qu’il soit pr\xeat \xe0 accepter des requ\xeates. Il peut donc falloir attendre un certain temps au d\xe9but des tests pour qu’il d\xe9marre."}),"\n",(0,r.jsx)(n.li,{children:"Et c’est encore pire avec Docker sur MacOS."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ce qui est de la ",(0,r.jsx)(n.strong,{children:"configuration du producer"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"acks"})," permet d’indiquer le nombre d’acknowledgements qu’on veut attendre de la part du broker leader avant de consid\xe9rer que le message est publi\xe9.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"0"})," indique qu’on ne veut pas attendre du tout."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"1"})," indique qu’on veut attendre que le leader lui-m\xeame ait \xe9crit le record dans son log \xe0 lui.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C’est la valeur par d\xe9faut si ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," est ",(0,r.jsx)(n.code,{children:"false"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"-1"})," permet d’indiquer qu’on veut attendre que le leader mais aussi tous les followers aient \xe9crit le record dans leurs log.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["C’est la valeur par d\xe9faut si ",(0,r.jsx)(n.code,{children:"enable.idempotence"})," est ",(0,r.jsx)(n.code,{children:"true"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.in.flight.per.connection"})," indique le nombre de records qu’on veut pouvoir publier (par d\xe9faut 5), avant d’avoir \xe0 attendre le nombre d’acknowledgements qu’on a indiqu\xe9 dans ",(0,r.jsx)(n.code,{children:"acks"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Augmenter ce nombre permet de se pr\xe9munir contre la lenteur du r\xe9seau, vu qu’attendre la confirmation \xe0 chaque fois qu’on veut publier nous emp\xeache de publier vite."}),"\n",(0,r.jsxs)(n.li,{children:["Par contre, on risque de ne pas publier dans le bon ordre pour les records entre deux acknowledgements.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Il suffit qu’un record A ait une erreur transiente qui est retent\xe9e puis r\xe9ussie, mais que le record suivant B ait r\xe9ussi imm\xe9diatement et avant le record A. Ce qui inverse l’ordre de publication de A et B."}),"\n",(0,r.jsxs)(n.li,{children:["Pour ne pas avoir le probl\xe8me il faudrait soit avoir ",(0,r.jsx)(n.code,{children:"max.in.flight.per.connection"})," \xe0 1 (attendre la confirmation \xe0 chaque publication), soit ",(0,r.jsx)(n.code,{children:"retries"})," \xe0 0 (ne jamais r\xe9essayer les erreurs transientes)."]}),"\n",(0,r.jsxs)(n.li,{children:["En r\xe9alit\xe9 il y a une 3\xe8me option qui est d’activer ",(0,r.jsx)(n.code,{children:"enable.idempotence"}),", o\xf9 Kafka va utiliser un m\xe9canisme qui remet le bon ordre pour les records qui arrivent avec le mauvais ordre."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"enable.idempotence"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Permet de garantir que :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les records soient publi\xe9s ",(0,r.jsx)(n.strong,{children:"au plus une fois"})," (donc d\xe9dupliqu\xe9s)."]}),"\n",(0,r.jsxs)(n.li,{children:["Les records sont publi\xe9s ",(0,r.jsx)(n.strong,{children:"dans l’ordre indiqu\xe9 par le client"})," producer."]}),"\n",(0,r.jsx)(n.li,{children:"Les records sont d’abord persist\xe9s sur l’ensemble des r\xe9plicas avant d’envoyer l’acknowledgement."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Il n\xe9cessite que (si ces propri\xe9t\xe9s ne sont pas renseign\xe9es, elles seront mises aux bonnes valeurs par d\xe9faut, mais il ne faut juste pas de conflit) :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"max.in.flight.per.connection"})," soit ",(0,r.jsx)(n.strong,{children:"entre 0 et 5"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"retries"})," soit plus grand que 0."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"acks"})," soit \xe0 -1."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Le probl\xe8me de duplication peut se produire dans le cas o\xf9 l’acknowledgement est en time out, o\xf9 le broker a re\xe7u les records, mais le client pensant que \xe7a n’a pas march\xe9, les renvoie."}),"\n",(0,r.jsxs)(n.li,{children:["Le m\xe9canisme c’est que chaque broker maintient un syst\xe8me d’ID pour les records qui arrivent, qui s’incr\xe9mente \xe0 la mani\xe8re d’un compteur pour les partitions dont il est leader.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Si le record qui arrive est identifi\xe9 comme \xe9tant d\xe9j\xe0 arriv\xe9, il est ignor\xe9 comme duplicata."}),"\n",(0,r.jsx)(n.li,{children:"Si le record qui arrive se voit attribuer un ID plus grand qu’un incr\xe9ment de 1, alors le message est consid\xe9r\xe9 comme \xe9tant dans le mauvais ordre, et le broker r\xe9pond une erreur indiquant qu’il faut le requeuer."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"compression.type"})," permet d’indiquer l’algo de ",(0,r.jsx)(n.strong,{children:"compression"})," qui sera utilis\xe9 par le producer (d\xe9taill\xe9 dans le chapitre 12).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Parmi les possibilit\xe9s :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.em,{children:"none"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.em,{children:"gzip"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"snappy"})," (optimis\xe9 pour le throughput, au d\xe9pend de la compression)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"lz4"})," (optimis\xe9 aussi pour le throughput, surtout la d\xe9compression)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.em,{children:"zstd"})," (nouvel algo, qui est cens\xe9 faire un bon ratio throughput / performance)."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"key.serializer"})," et ",(0,r.jsx)(n.strong,{children:"value.serializer"})," servent \xe0 indiquer la s\xe9rialisation des cl\xe9s et valeurs des records (cf. le chapitre 7)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"partitioner.class"})," permet d’indiquer une classe Java qui va d\xe9finir une mani\xe8re diff\xe9rente de la mani\xe8re par d\xe9faut d’associer les records et les partitions.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La mani\xe8re par d\xe9faut va, dans l’ordre :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - Si la partition est indiqu\xe9e explicitement dans la publication du record, elle sera utilis\xe9e."}),"\n",(0,r.jsx)(n.li,{children:"2 - Sinon, si on a indiqu\xe9 une cl\xe9, la cl\xe9 sera hash\xe9e pour d\xe9terminer la partition."}),"\n",(0,r.jsx)(n.li,{children:"3 - Sinon, si le batch courant a une partition qui lui est assign\xe9e, on utilise cette partition."}),"\n",(0,r.jsxs)(n.li,{children:["4 - Sinon, on assigne une partition au batch et on l’utilise.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Le 3 et 4 ont \xe9t\xe9 introduits dans Kafka plus r\xe9cemment, et permettent, dans le cas o\xf9 on n’a pas de pr\xe9f\xe9rence d’ordre li\xe9e \xe0 une cl\xe9, de ",(0,r.jsx)(n.strong,{children:"n’impliquer qu’un broker pour les records d’un batch."})," \xc7a ",(0,r.jsx)(n.strong,{children:"am\xe9liore les perfs par 2 ou 3"}),", tout en assurant une distribution entre brokers quand on a un grand nombre de batchs."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Le client Java a aussi deux autres classes disponibles :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"RoundRobinPartitioner"})," permet d’alterner entre les brokers, sans prendre en compte la cl\xe9."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"UniformStickyPartitioner"})," permet de garder les records d’un m\xeame batch pour une m\xeame partition, sans prendre en compte la cl\xe9."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"On peut aussi donner une classe perso, mais l’auteur conseille d’envisager aussi d’encoder notre ordre custom dans une cl\xe9."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"interceptor.classes"})," permet de d\xe9finir des classes Java qui vont faire quelque chose de particulier \xe0 l’envoi et \xe0 l’acknowledgement.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\xc7a peut \xeatre utile pour le c\xf4t\xe9 “plugin” r\xe9utilisable, parce qu’on est sur de l’AOP (Aspect Oriented Programming)."}),"\n",(0,r.jsx)(n.li,{children:"On peut par exemple l’utiliser pour ajouter une couche qui fait du logging, du tracing, de l’analyse de message pour emp\xeacher la fuite de donn\xe9es etc."}),"\n",(0,r.jsx)(n.li,{children:"Attention par contre : les exceptions dans les interceptors ne sont pas propag\xe9es."}),"\n",(0,r.jsx)(n.li,{children:"Globalement si on y met quelque chose, il vaut mieux que ce soit du code simple et non bloquant."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.block.ms"})," permet d’indiquer un timeout au processus de publication (par d\xe9faut 60 secondes)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"batch.size"})," permet d’attendre d’avoir une certaine taille de messages (par d\xe9faut 16 KB) avant d’envoyer un batch de publication.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"linger.ms"})," fait la m\xeame chose au niveau du temps (par d\xe9faut 0 ms) en ajoutant un temps minimal \xe0 attendre avant d’envoyer un autre batch."]}),"\n",(0,r.jsx)(n.li,{children:"L’int\xe9r\xeat est de faire moins de requ\xeates au serveur et donc d’augmenter le throughput."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"request.timeout"})," permet d’indiquer un timeout vis-\xe0-vis de la r\xe9ponse du broker pour faire l’acknowledgement (par d\xe9faut 30 secondes), avant de r\xe9essayer ou d’indiquer la publication comme \xe9chou\xe9e."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"delivery.timeout"})," permet d’indiquer un temps global pour une requ\xeate de publication, qui englobe l’envoi, les retries, et la r\xe9ponse du serveur.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Par d\xe9faut, c'est 120 secondes."}),"\n",(0,r.jsx)(n.li,{children:"Il doit \xeatre sup\xe9rieur aux autres timeouts r\xe9unis."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"transaction.id"})," et ",(0,r.jsx)(n.strong,{children:"transaction.timeout.ms"})," permettent de g\xe9rer le comportement des transactions (cf. le chapitre 18)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Pour ce qui est de la ",(0,r.jsx)(n.strong,{children:"configuration du consumer"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"key.serializer"})," et ",(0,r.jsx)(n.strong,{children:"value.serializer"})," servent \xe0 indiquer la d\xe9s\xe9rialisation des cl\xe9s et valeurs des records (cf. le chapitre 7)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"interceptor.classes"})," permet de faire la m\xeame chose que c\xf4t\xe9 consumer, en traitant les records par batch."]}),"\n",(0,r.jsxs)(n.li,{children:["Une des choses les plus importantes \xe0 r\xe9gler, c'est ",(0,r.jsx)(n.strong,{children:"la taille de ce qu’on va aller chercher en une requ\xeate"}),". \xc7a se configure en plusieurs propri\xe9t\xe9s.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Plus on prendra de donn\xe9es, et plus le throughput sera grand, mais moins on aura un bon d\xe9lai de propagation de bout en bout d’un record."}),"\n",(0,r.jsxs)(n.li,{children:["La propri\xe9t\xe9 ",(0,r.jsx)(n.strong,{children:"timeout"})," donn\xe9e \xe0 ",(0,r.jsx)(n.code,{children:"Consumer.poll()"})," permet de limiter son temps d’ex\xe9cution."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"fetch.min.bytes"})," (par d\xe9faut 1) permet de demander au broker d’attendre d’avoir au moins un minimum de donn\xe9es \xe0 envoyer avant de les envoyer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["En r\xe9alit\xe9, le broker doit quand m\xeame envoyer une requ\xeate m\xeame s’il n’a pas assez de donn\xe9es, dans le cas o\xf9 il d\xe9passe un timeout fix\xe9 par ",(0,r.jsx)(n.strong,{children:"fetch.max.wait.ms"})," (par d\xe9faut 500 ms)."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"fetch.max.bytes"})," (par d\xe9faut 50 MB) indique au broker \xe0 partir de quelle taille il doit arr\xeater d’ajouter des donn\xe9es. Vu qu’un record (et donc \xe0 fortiori un batch) peut de toute fa\xe7on d\xe9passer cette taille, la limite n’est qu’indicative.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La m\xeame propri\xe9t\xe9 limite existe pour la taille des partitions : ",(0,r.jsx)(n.strong,{children:"max.partition.fetch.bytes"})," (par d\xe9faut 1 MB).","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Cette propri\xe9t\xe9 permet de limiter l’impact des partitions “gourmandes”, en laissant de la place aux partitions qui ont moins de donn\xe9es."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Int\xe9ressant \xe0 savoir : les brokers ne font pas de traitement sur les batchs. ",(0,r.jsx)(n.strong,{children:"Les batchs sont envoy\xe9s par les producers, stock\xe9s tels quels, et envoy\xe9s tels quels aux consumers"}),". C’est un choix de design de Kafka pour garantir une grande performance."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.poll.records"})," (par d\xe9faut 500) permet de limiter le nombre de records retourn\xe9s par ",(0,r.jsx)(n.code,{children:"Consumer.poll()"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contrairement aux autres propri\xe9t\xe9s, celle-ci n’impacte pas le broker. C’est le client qui re\xe7oit le m\xeame nombre de records par batch, va lui-m\xeame limiter ceux qu’il rend disponible. Il bufferise les autres pour les rendre disponibles \xe0 l’appel suivant."}),"\n",(0,r.jsxs)(n.li,{children:["Elle est l\xe0 pour \xe9viter que le client n’ait \xe0 traiter trop de records, et ne puisse pas appeler \xe0 nouveau ",(0,r.jsx)(n.code,{children:"poll()"})," avant ",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"group.id"})," permet d’indiquer le groupe d’un consumer. Si on ne le fournit pas, il deviendra sans groupe, et ne pourra pas b\xe9n\xe9ficier des m\xe9canismes de d’assignation automatique de partition, d\xe9tection des \xe9checs, ni faire de commits au serveur pour sauvegarder son offset."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"group.instance.id"})," consiste \xe0 indiquer un identifiant \xe0 un consumer, unique dans son groupe, rendant le consumer ",(0,r.jsx)(n.em,{children:"static"}),". L’effet est que si le consumer n’est plus l\xe0, sa partition n’est pas r\xe9assign\xe9e, mais reste en attente de son retour.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"C’est pour \xe9viter les rebalancing trop fr\xe9quents dans un contextes de manque d’availability transient."}),"\n",(0,r.jsx)(n.li,{children:"Pour en savoir plus : chapitre 15."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["La ",(0,r.jsx)(n.strong,{children:"d\xe9tection d’\xe9checs"})," est contr\xf4l\xe9e par la combinaison de ",(0,r.jsx)(n.code,{children:"heartbeat.interval.ms"}),", ",(0,r.jsx)(n.code,{children:"session.timeout.ms"})," et ",(0,r.jsx)(n.code,{children:"max.poll.interval.ms"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ce sujet fait partie des sujets d\xe9licats, source de nombreux probl\xe8mes."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"heartbeat.interval.ms"})," (par d\xe9faut 3 secondes) contr\xf4le la fr\xe9quence \xe0 laquelle le consumer envoie des heartbeats."]}),"\n",(0,r.jsxs)(n.li,{children:["Le broker coordinateur du groupe de son c\xf4t\xe9 v\xe9rifie que le consumer n’envoie pas son prochain heartbeat apr\xe8s le d\xe9lai de ",(0,r.jsx)(n.strong,{children:"session.timeout.ms"})," (par d\xe9faut 10 secondes). Sinon il l’expulse et r\xe9assigne ses partitions dans le groupe."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"max.poll.interval.ms"})," (par d\xe9faut 5 minutes) est le d\xe9lai maximal pour qu’un consumer rappelle ",(0,r.jsx)(n.code,{children:"poll()"}),". S'il ne l’a pas fait, il va lui-m\xeame arr\xeater d’envoyer des heartbeats et demander \xe0 quitter le groupe.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Si le consumer est statique, il arr\xeate les heartbeats mais ne demande pas \xe0 quitter le groupe. Il sera \xe9vinc\xe9 par le broker s’il d\xe9passe la ",(0,r.jsx)(n.code,{children:"session.timeout.interval"})," sans avoir r\xe9\xe9mis de heartbeats."]}),"\n",(0,r.jsx)(n.li,{children:"Le but de ce comportement est d’\xe9viter les situations o\xf9 plusieurs consumers traitent les m\xeames messages."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"auto.reset.offset"})," permet d’indiquer ce qui se passe quand un consumer n’a pas d’offsets pour la partition qu’il consomme.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Les options sont : ",(0,r.jsx)(n.code,{children:"earliest"})," pour partir du low water mark, ",(0,r.jsx)(n.code,{children:"latest"})," pour partir du high water mark, et ",(0,r.jsx)(n.code,{children:"none"})," pour renvoyer une exception."]}),"\n",(0,r.jsxs)(n.li,{children:["Les offsets sont stock\xe9s par le group coordinator dans un topic nomm\xe9 ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),". Ce topic a un temps de r\xe9tention comme n’importe quel topic (par d\xe9faut 7 jours)."]}),"\n",(0,r.jsxs)(n.li,{children:["L’offset peut ne pas exister si :","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"1 - C’est le d\xe9but de la formation du groupe et que la partition n’a pas encore \xe9t\xe9 lue par lui."}),"\n",(0,r.jsxs)(n.li,{children:["2 - Quand rien n’a \xe9t\xe9 consomm\xe9 sur cette partition par le groupe (et donc aucun offset n’a \xe9t\xe9 commit\xe9 dans ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),") depuis plus longtemps que le d\xe9lai de r\xe9tention de ",(0,r.jsx)(n.code,{children:"__consumer_offsets"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"3 - Quand on a un offset qui pointe vers un record qui est dans un topic o\xf9 le d\xe9lai de r\xe9tention est plus faible, et a \xe9t\xe9 d\xe9pass\xe9. Donc l’offset pointe vers le vide."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"enable.auto.commit"})," permet d’indiquer si le commit automatique est activ\xe9 pour un consumer. Il s’agit d’envoyer un commit jusqu’au dernier record trait\xe9 par le dernier l’appel \xe0 ",(0,r.jsx)(n.code,{children:"poll()"}),", pour mettre \xe0 jour son offset.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Par d\xe9faut le client commit toutes les 5 secondes (temps r\xe9glable avec ",(0,r.jsx)(n.strong,{children:"auto.commit.interval.ms"}),")."]}),"\n",(0,r.jsxs)(n.li,{children:["Si \xe7a marchait vraiment comme \xe7a (tel que le dit la doc), le client mettrait \xe0 jour son offset au dernier record re\xe7u dans le batch envoy\xe9 par le dernier appel \xe0 ",(0,r.jsx)(n.code,{children:"poll()"}),", alors m\xeame qu’il n’a pas forc\xe9ment termin\xe9 de traiter le batch.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"En r\xe9alit\xe9, l’impl\xe9mentation r\xe8gle le probl\xe8me en envoyant le commit dans le m\xeame thread que celui qui traite les records, et seulement apr\xe8s que le batch ait \xe9t\xe9 trait\xe9."}),"\n",(0,r.jsx)(n.li,{children:"Mais ce comportement n’est pas garanti vu que la doc ne dit pas \xe7a, Kafka pourrait \xe0 tout moment mettre \xe0 jour le comportement pour faire le commit dans un autre thread toutes les 5 secondes."}),"\n",(0,r.jsxs)(n.li,{children:["Pour \xe9viter les probl\xe8mes, l’auteur conseille de ",(0,r.jsx)(n.strong,{children:"faire le commit \xe0 la main"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isolation.level"})," permet d’indiquer le type de comportement d’une transaction vis-\xe0-vis du consumer.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_uncommitted"})," va renvoyer tous les records sans prendre en compte les transactions."]}),"\n",(0,r.jsxs)(n.li,{children:["La valeur ",(0,r.jsx)(n.code,{children:"read_committed"})," va renvoyer les records qui ne font pas partie des transactions, et ceux qui font partie de transactions valid\xe9es, mais pas ceux qui font partie de transactions qui ne sont pas encore valid\xe9es.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pour garantir l’ordre, tous les records qui doivent se trouver apr\xe8s les records qui sont dans des transactions non valid\xe9es seront aussi bloqu\xe9s le temps de la transaction."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}n.default=(0,i.j)(o)}},function(e){e.O(0,[774,105,888,179],function(){return e(e.s=7382)}),_N_E=e.O()}]);