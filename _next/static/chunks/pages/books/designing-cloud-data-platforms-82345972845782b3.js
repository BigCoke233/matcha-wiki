(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[872],{514:function(e,n,s){(window.__NEXT_P=window.__NEXT_P||[]).push(["/books/designing-cloud-data-platforms",function(){return s(2441)}])},9923:function(e,n,s){"use strict";s.d(n,{Z:function(){return c}});var i=s(5893);s(7294);let r="My detailed reading notes from computer science books",l="/reading-notes";var a=s(1163),t=s(5675),d=s.n(t);let o={logo:(0,i.jsx)(function(){return(0,i.jsx)(d(),{src:"".concat(l,"/logo.png"),alt:"Reading notes homepage",width:30,height:30})},{}),project:{link:"https://github.com/mkrtchian/reading-notes"},docsRepositoryBase:"https://github.com/mkrtchian/reading-notes/blob/main",footer:{text:"Made by Roman Mkrtchian"},head:function(){let e="Reading notes";return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)("meta",{name:"msapplication-TileColor",content:"#fff"}),(0,i.jsx)("meta",{httpEquiv:"Content-Language",content:"en"}),(0,i.jsx)("meta",{name:"description",content:r}),(0,i.jsx)("meta",{property:"og:title",content:e}),(0,i.jsx)("meta",{property:"og:description",content:r}),(0,i.jsx)("meta",{name:"apple-mobile-web-app-title",content:e}),(0,i.jsx)("link",{rel:"icon",type:"image/x-icon",href:"".concat(l,"/favicon.ico")})]})},feedback:{content:()=>(0,i.jsx)(i.Fragment,{children:"Question? Give me feedback →"}),labels:"feedback"},useNextSeoProps:function(){let{route:e}=(0,a.useRouter)(),n={description:r};return"/"!==e?n.titleTemplate="%s – Reading notes":n.titleTemplate="%s",n},i18n:[]};var c=o},2441:function(e,n,s){"use strict";s.r(n);var i=s(5893),r=s(2673),l=s(902),a=s(9923);s(9966);var t=s(1151);s(5675);let d={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,t.ah)(),e.components);return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)},pageOpts:{filePath:"pages/books/designing-cloud-data-platforms.md",route:"/books/designing-cloud-data-platforms",headings:[{depth:1,value:"Designing Cloud Data Platforms",id:"designing-cloud-data-platforms"},{depth:2,value:"1 - Introducing the data platform",id:"1---introducing-the-data-platform"},{depth:2,value:"2 - Why a data platform and not just a data warehouse",id:"2---why-a-data-platform-and-not-just-a-data-warehouse"}],pageMap:[{kind:"Meta",data:{index:"Introduction",books:"Reading notes"}},{kind:"Folder",name:"books",route:"/books",children:[{kind:"Meta",data:{"continuous-discovery-habits":"Continuous Discovery Habits","designing-cloud-data-platforms":"Designing Cloud Data Platforms","designing-data-intensive-applications":"Designing Data-Intensive Applications","effective-kafka":"Effective Kafka","get-your-hands-dirty-on-clean-architecture":"Get Your Hands Dirty on Clean Architecture","learning-domain-driven-design":"Learning Domain-Driven Design","learning-to-scale":"Learning to Scale","monolith-to-microservices":"Monolith to Microservices",refactoring:"Refactoring: Improving the Design of Existing Code","reinventing-organizations":"Reinventing Organizations","team-topologies":"Team Topologies","the-design-of-web-apis":"The Design of Web APIs","unit-testing":"Unit Testing: Principles, Practices, and Patterns"}},{kind:"MdxPage",name:"continuous-discovery-habits",route:"/books/continuous-discovery-habits"},{kind:"MdxPage",name:"designing-cloud-data-platforms",route:"/books/designing-cloud-data-platforms"},{kind:"MdxPage",name:"designing-data-intensive-applications",route:"/books/designing-data-intensive-applications"},{kind:"MdxPage",name:"effective-kafka",route:"/books/effective-kafka"},{kind:"MdxPage",name:"get-your-hands-dirty-on-clean-architecture",route:"/books/get-your-hands-dirty-on-clean-architecture"},{kind:"MdxPage",name:"learning-domain-driven-design",route:"/books/learning-domain-driven-design"},{kind:"MdxPage",name:"learning-to-scale",route:"/books/learning-to-scale"},{kind:"MdxPage",name:"monolith-to-microservices",route:"/books/monolith-to-microservices"},{kind:"MdxPage",name:"refactoring",route:"/books/refactoring"},{kind:"MdxPage",name:"reinventing-organizations",route:"/books/reinventing-organizations"},{kind:"MdxPage",name:"team-topologies",route:"/books/team-topologies"},{kind:"MdxPage",name:"the-design-of-web-apis",route:"/books/the-design-of-web-apis"},{kind:"MdxPage",name:"unit-testing",route:"/books/unit-testing"}]},{kind:"MdxPage",name:"index",route:"/"}],flexsearch:{codeblocks:!0},title:"Designing Cloud Data Platforms"},pageNextRoute:"/books/designing-cloud-data-platforms",nextraLayout:l.ZP,themeConfig:a.Z};function o(e){let n=Object.assign({h1:"h1",h2:"h2",ul:"ul",li:"li",strong:"strong",em:"em"},(0,t.ah)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{children:"Designing Cloud Data Platforms"}),"\n",(0,i.jsx)(n.h2,{id:"1---introducing-the-data-platform",children:"1 - Introducing the data platform"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Les ",(0,i.jsx)(n.strong,{children:"analytics"})," permettent essentiellement d’obtenir des m\xe9triques pour faire des choix business.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Avant l’av\xe8nement des ordinateurs, les entreprises utilisaient des moyens manuels, et leur intuition."}),"\n",(0,i.jsx)(n.li,{children:"Dans les ann\xe9es 80 on a vu \xe9merger le concept de data warehouse, qui est une base centralis\xe9e de donn\xe9es venant de diverses sources."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Les ",(0,i.jsx)(n.strong,{children:"data warehouses"})," posent de plus en plus de ",(0,i.jsx)(n.strong,{children:"probl\xe8mes"})," de nos jours.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Les tendances suivantes y contribuent :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Les donn\xe9es sont issues de sources de diverses nature, y compris certaines d’entre-elles non structur\xe9es, et leur volume est de plus en plus important."}),"\n",(0,i.jsx)(n.li,{children:"Le d\xe9coupage des applications en microservices fait que collecter des donn\xe9es revient forc\xe9ment \xe0 devoir agr\xe9ger de multiples sources."}),"\n",(0,i.jsx)(n.li,{children:"Les data scientists ont aussi besoin d’acc\xe9der \xe0 une version brute de la donn\xe9e, et cet usage ne peut pas passer par un data warehouse."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Elles ont du mal avec les ",(0,i.jsx)(n.strong,{children:"3V"})," (Variety, Volume, Velocity).","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Variety"})," : les data warehouses ne supportent que les ",(0,i.jsx)(n.em,{children:"structured data"})," dont le sch\xe9ma est stable, c’est-\xe0-dire en pratique qui sont issues de DB relationnelles.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Or avec l’av\xe8nement des SaaS, des r\xe9seaux sociaux, et de l’IoT, on se retrouve avec :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Des ",(0,i.jsx)(n.em,{children:"semistructured data"})," du type JSON, Avro etc, dont le sch\xe9ma varie souvent."]}),"\n",(0,i.jsxs)(n.li,{children:["Des ",(0,i.jsx)(n.em,{children:"unstructured data"})," comme le binaire, le son, la vid\xe9o."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Volume"})," : le fait que dans un data warehouse, la puissance de calcul et le stockage doivent se trouver sur ",(0,i.jsx)(n.strong,{children:"la m\xeame machine physique"}),", implique qu’on ne peut pas scaler les deux s\xe9par\xe9ment, et donc les co\xfbts explosent.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"M\xeame les petites organisations peuvent \xeatre amen\xe9es \xe0 traiter plusieurs TB de donn\xe9es."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Velocity"})," : les data warehouses ne sont pas adapt\xe9es aux analytics en mode real time, elles sont plus orient\xe9es batch processing."]}),"\n",(0,i.jsx)(n.li,{children:"Le machine learning en particulier pose tous les probl\xe8mes en m\xeame temps : il n\xe9cessite une grande quantit\xe9 de donn\xe9es vari\xe9es, et accapare la puissance de calcul du data warehouse."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Les ",(0,i.jsx)(n.strong,{children:"data lakes"})," r\xe9pondent en partie \xe0 ces probl\xe8mes.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["L’id\xe9e principale des data lakes c’est qu’on ",(0,i.jsx)(n.strong,{children:"stocke de la donn\xe9e telle quelle"})," (ou quasi), et qu’on essayera de la traiter et de lui coller un sch\xe9ma d\xe8s qu’on en aura besoin."]}),"\n",(0,i.jsxs)(n.li,{children:["Les data lakes se sont g\xe9n\xe9ralis\xe9s \xe0 partir de 2006 avec l’arriv\xe9e de ",(0,i.jsx)(n.strong,{children:"Hadoop"}),", qui est un ",(0,i.jsx)(n.strong,{children:"filesystem distribu\xe9 sur plusieurs machines"})," pas ch\xe8res.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Hadoop r\xe9pond en partie aux 3V :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["A la ",(0,i.jsx)(n.em,{children:"Variety"})," par l’\xe9criture schema-less."]}),"\n",(0,i.jsxs)(n.li,{children:["Au ",(0,i.jsx)(n.em,{children:"Volume"})," par le fait que ce soit distribu\xe9 sur des machines pas ch\xe8res."]}),"\n",(0,i.jsxs)(n.li,{children:["A la ",(0,i.jsx)(n.em,{children:"Velocity"})," par la facilit\xe9 de streaming \xe0 partir du filesystem distribu\xe9."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Mais il a aussi des probl\xe8mes :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"C’est un syst\xe8me complexe qu’il faut installer sur un datacenter et g\xe9rer par des Ops exp\xe9riment\xe9s."}),"\n",(0,i.jsx)(n.li,{children:"D’un point de vue business, c’est plus difficile de travailler avec les outils qui traitent les donn\xe9es non structur\xe9es qu’avec du SQL comme dans un data warehouse."}),"\n",(0,i.jsx)(n.li,{children:"Bien qu’il soit distribu\xe9 sur de petites machines pas ch\xe8res, le computing et le stockage ne sont pas s\xe9par\xe9s, ce qui limite quand m\xeame la r\xe9duction de co\xfbt quand on a besoin de beaucoup de l’un sans l’autre."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Le ",(0,i.jsx)(n.strong,{children:"cloud public"})," vient r\xe9pondre aux probl\xe8mes de Hadoop.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Les data warehouses et les data lakes ont \xe9t\xe9 propos\xe9s par les cloud providers, avec de nombreux avantages :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"La possibilit\xe9 de scaler la puissance de calcul et le stockage s\xe9par\xe9ment."}),"\n",(0,i.jsx)(n.li,{children:"Payer uniquement \xe0 l’usage des machines qu’on emprunte."}),"\n",(0,i.jsx)(n.li,{children:"Ne plus avoir \xe0 g\xe9rer la complexit\xe9 de l’infrastructure."}),"\n",(0,i.jsx)(n.li,{children:"Des outils et frameworks avanc\xe9s d\xe9velopp\xe9s par les cloud providers autour de leurs produits."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Exemple : ",(0,i.jsx)(n.strong,{children:"AWS EMR"})," permet de lancer un cluster sur lequel on va pouvoir ex\xe9cuter des jobs ",(0,i.jsx)(n.strong,{children:"Hadoop"})," et ",(0,i.jsx)(n.strong,{children:"Spark"}),",","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On a juste \xe0 indiquer le nombre de nœuds qu’on veut, et les packages qu’on veut installer dessus."}),"\n",(0,i.jsxs)(n.li,{children:["Et on a la possibilit\xe9 de faire des allers-retours vers ",(0,i.jsx)(n.strong,{children:"S3"})," pour scaler diff\xe9remment le calcul et le stockage."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["La ",(0,i.jsx)(n.strong,{children:"cloud data platform"})," moderne utilise \xe0 la fois le data warehouse et le data lake, h\xe9berg\xe9s dans un cloud public, chacun d’entre eux remplissant un usage particulier.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Pour \xeatre polyvalente et pas ch\xe8re, la data platform doit avoir des ",(0,i.jsx)(n.strong,{children:"4 composants principaux faiblement coupl\xe9s"}),", interagissant entre-eux avec une API bien d\xe9finie.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Ingestion layer"})," : on va chercher les donn\xe9es chez les diff\xe9rents types de sources (DB relationnelle, DB NoSQL, API externes etc.).","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On va en g\xe9n\xe9ral utiliser un ensemble d’outils open source ou commerciaux pour chaque type de donn\xe9es \xe0 aller chercher."}),"\n",(0,i.jsxs)(n.li,{children:["Il ne faut ",(0,i.jsx)(n.strong,{children:"surtout pas alt\xe9rer la donn\xe9e \xe0 cette \xe9tape"}),", pour que la donn\xe9e brute soit disponible pour les data scientists qui en auraient l’usage."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Storage layer"})," : on utilise le stockage cloud comme stockage de notre ",(0,i.jsx)(n.em,{children:"data lake"}),", dans lequel on met ce qu’on a ing\xe9r\xe9.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Le stockage cloud a l’avantage de ne pas avoir besoin de planifier la capacit\xe9 de stockage : il grossit automatiquement au besoin."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Processing layer"})," : on transforme la donn\xe9e pour la rendre utilisable par la plupart des clients de la plateforme.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["C’est la partie calcul de notre ",(0,i.jsx)(n.em,{children:"data lake"}),", il va lire depuis le cloud storage puis \xe9crire \xe0 nouveau dedans."]}),"\n",(0,i.jsxs)(n.li,{children:["Dans le cas du ",(0,i.jsx)(n.strong,{children:"streaming"}),", on ne passe pas par le storage layer qui prend trop de temps, mais on envoie la donn\xe9e ",(0,i.jsx)(n.strong,{children:"directement au processing layer"}),", qui va ensuite la rendre disponible au layer d’apr\xe8s."]}),"\n",(0,i.jsxs)(n.li,{children:["Le processing est g\xe9n\xe9ralement fait avec des outils open source, les plus connus \xe9tant ",(0,i.jsx)(n.strong,{children:"Spark"}),", ",(0,i.jsx)(n.strong,{children:"Beam"})," et ",(0,i.jsx)(n.strong,{children:"Flink"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Serving layer"})," : on rend la donn\xe9e disponible sous divers formats, selon les besoins des clients de la plateforme.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Les usages peuvent \xeatre :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Des analystes qui ont besoin d’ex\xe9cuter des requ\xeates SQL sur la donn\xe9e.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["On peut charger la donn\xe9e dans un ",(0,i.jsx)(n.em,{children:"data warehouse"})," chez le cloud provider."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Des applications qui ont besoin d’un acc\xe8s rapide \xe0 la donn\xe9e.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On peut la charger dans une key / value DB, ou une document DB."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Des \xe9quipes de data scientists / engineers ont besoin de transformer la donn\xe9e eux-m\xeames.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["On peut leur donner acc\xe8s au storage du ",(0,i.jsx)(n.em,{children:"data lake"}),", et les laisser utiliser ",(0,i.jsx)(n.strong,{children:"Spark"}),", ",(0,i.jsx)(n.strong,{children:"Beam"})," ou ",(0,i.jsx)(n.strong,{children:"Flink"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["La cloud data platform r\xe9pond aux 3V :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["L’ingestion layer coupl\xe9 au stockage sans sch\xe9ma permet une grande ",(0,i.jsx)(n.em,{children:"Variety"})," des donn\xe9es."]}),"\n",(0,i.jsxs)(n.li,{children:["La s\xe9paration calcul / stockage et le fait de ne payer que ce qu’on utilise permet d’optimiser les co\xfbts, et d’avoir un gros ",(0,i.jsx)(n.em,{children:"Volume"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["La possibilit\xe9 d’envoyer directement au ",(0,i.jsx)(n.em,{children:"processing layer"})," permet de la ",(0,i.jsx)(n.em,{children:"Velocity"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["On peut aussi prendre en compte deux autres V :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["La ",(0,i.jsx)(n.em,{children:"Veracity"})," qui indique le niveau de ",(0,i.jsx)(n.em,{children:"data governance"}),", c’est-\xe0-dire la qualit\xe9 de la donn\xe9e. On l’obtient it\xe9rativement, au cours d’\xe9tapes au sein du data lake."]}),"\n",(0,i.jsxs)(n.li,{children:["Et la ",(0,i.jsx)(n.em,{children:"Value"})," qu’on peut tirer de la donn\xe9e, qui peut \xeatre plus \xe9lev\xe9e si on prend plus de donn\xe9es en amont de notre processus de nettoyage."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Il faut comprendre les ",(0,i.jsx)(n.strong,{children:"cas d’usages principaux"})," d’un ",(0,i.jsx)(n.em,{children:"data lake"}),", pour \xe9viter de le transformer en ",(0,i.jsx)(n.em,{children:"data swamp"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Parmi les plus courants il y a la ",(0,i.jsx)(n.strong,{children:"vue 360\xb0 des clients"}),", o\xf9 il s’agit de r\xe9cup\xe9rer toutes les donn\xe9es d’interaction avec eux, pour proposer ensuite des services plus personnalis\xe9s, vendre plus etc."]}),"\n",(0,i.jsxs)(n.li,{children:["Il y a aussi les ",(0,i.jsx)(n.strong,{children:"donn\xe9es venant d’IoT"}),", qui ont la particularit\xe9 d’\xeatre incertaines et d’avoir un gros volume, ce qui rend l’utilisation du ",(0,i.jsx)(n.em,{children:"data warehouse"})," peu int\xe9ressante."]}),"\n",(0,i.jsxs)(n.li,{children:["Et enfin il y a le ",(0,i.jsx)(n.strong,{children:"machine learning"})," qui a besoin d’une tr\xe8s grande quantit\xe9 de donn\xe9es, et qui tire avantage de puissance de calcul s\xe9par\xe9e des autres use-cases gr\xe2ce au ",(0,i.jsx)(n.em,{children:"data lake"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"2---why-a-data-platform-and-not-just-a-data-warehouse",children:"2 - Why a data platform and not just a data warehouse"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ce chapitre donne des ",(0,i.jsxs)(n.strong,{children:["arguments pour le choix d’une ",(0,i.jsx)(n.em,{children:"cloud data platform"}),", plut\xf4t qu’une simple ",(0,i.jsx)(n.em,{children:"data warehouse"})]}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["On impl\xe9mente les deux solutions pour une situation d’",(0,i.jsx)(n.strong,{children:"exemple"})," qu’on va utiliser dans ce chapitre :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Nous sommes l’\xe9quipe data, et le d\xe9partement marketing a besoin que nous r\xe9cup\xe9rions deux sources de donn\xe9es et qu’on les corr\xe8le r\xe9guli\xe8rement.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"L’une des sources est une table de campagnes de marketing, issue d’une DB MySQL interne."}),"\n",(0,i.jsxs)(n.li,{children:["Et l’autre est constitu\xe9e de fichiers CSV de clics utilisateurs, issus de logs applicatifs (et donc ",(0,i.jsx)(n.em,{children:"semistructured"}),")."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"On part sur Microsoft Azure pour les deux solutions."}),"\n",(0,i.jsxs)(n.li,{children:["Concernant l’impl\xe9mentation ",(0,i.jsx)(n.em,{children:"data warehouse only"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["1 - On va utiliser deux ",(0,i.jsx)(n.strong,{children:"Azure Data Factory"})," pour r\xe9cup\xe9rer la donn\xe9e dans le serveur de DB et dans les fichiers CSV dans le serveur SFTP. C’est notre ",(0,i.jsx)(n.em,{children:"ingest layer"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["2 - Ensuite on redirige \xe7a vers l’",(0,i.jsx)(n.strong,{children:"Azure Synapse"}),", qui est la data warehouse de chez Azure. Elle va faire office de ",(0,i.jsx)(n.em,{children:"store layer"}),", ",(0,i.jsx)(n.em,{children:"process layer"})," et ",(0,i.jsx)(n.em,{children:"serve layer"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Concernant l’impl\xe9mentation ",(0,i.jsx)(n.em,{children:"cloud data platform"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["1 - On a notre ",(0,i.jsx)(n.em,{children:"ingest layer"})," avec ",(0,i.jsx)(n.strong,{children:"Azure Data Factory"}),", qui redirige les donn\xe9es vers le ",(0,i.jsx)(n.em,{children:"store layer"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["2 - Le ",(0,i.jsx)(n.em,{children:"store layer"})," est impl\xe9ment\xe9 avec ",(0,i.jsx)(n.strong,{children:"Azure Blob Storage"}),". Il s’agit d’un stockage de type ",(0,i.jsx)(n.em,{children:"data lake"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["3 - On a un ",(0,i.jsx)(n.em,{children:"process layer"})," qui utilise ",(0,i.jsx)(n.strong,{children:"Azure Databricks"}),", et qui fait tourner ",(0,i.jsx)(n.strong,{children:"Spark"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["4 - Le ",(0,i.jsx)(n.em,{children:"serve layer"})," utilise enfin ",(0,i.jsx)(n.strong,{children:"Azure Synapse"})," qui est le data warehouse."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Concernant l’",(0,i.jsx)(n.strong,{children:"ingestion"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Pour la version ",(0,i.jsx)(n.em,{children:"data warehouse only"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["La pipeline contient :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Des ",(0,i.jsx)(n.em,{children:"linked services"})," : ici la ",(0,i.jsx)(n.em,{children:"data source"})," MySQL en entr\xe9e, et la ",(0,i.jsx)(n.em,{children:"data sink"})," ",(0,i.jsx)(n.strong,{children:"Azure Synapse"})," en sortie."]}),"\n",(0,i.jsxs)(n.li,{children:["Des ",(0,i.jsx)(n.em,{children:"data sets"})," : il s’agit de la description du sch\xe9ma de donn\xe9es d’entr\xe9e et de sortie, et leur mapping."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Si le sch\xe9ma de la DB source change, il faudra mettre \xe0 jour le sch\xe9ma d\xe9fini dans la pipeline et le mapping.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Mais surtout il faudra ",(0,i.jsx)(n.strong,{children:"g\xe9rer soi-m\xeame la migration"})," du ",(0,i.jsx)(n.em,{children:"data sink"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Pour la version ",(0,i.jsx)(n.em,{children:"cloud data platform"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Cette fois le ",(0,i.jsx)(n.em,{children:"data sink"})," est un ",(0,i.jsx)(n.strong,{children:"Azure Blob Storage"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Il n’y a plus besoin de sp\xe9cifier les sch\xe9mas et le mapping entre input et output puisque l’output accueille la donn\xe9e telle quelle."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Si le sch\xe9ma de la DB source change, il n’y a ",(0,i.jsx)(n.strong,{children:"rien \xe0 faire c\xf4t\xe9 ingestion"})," : on \xe9crira de toute fa\xe7on la donn\xe9e dans un nouveau fichier.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On d\xe9place le probl\xe8me de mapping plus loin."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Concernant le ",(0,i.jsx)(n.strong,{children:"processing"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Dans la version ",(0,i.jsx)(n.em,{children:"data warehouse only"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["On va charger les deux donn\xe9es :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"La DB MySQL sans charger sa structure parce qu’elle est d\xe9j\xe0 relationnelle."}),"\n",(0,i.jsx)(n.li,{children:"La donn\xe9e CSV semistructur\xe9e dans des rows de type texte qu’on parsera en JSON avec une fonction SQL built-in."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["La ",(0,i.jsx)(n.strong,{children:"requ\xeate SQL"})," qu’on va \xe9crire aura les d\xe9savantages suivants :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Elle sera ",(0,i.jsx)(n.strong,{children:"peu lisible"}),", \xe0 cause du code de parsing n\xe9cessaire.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On pourrait la rendre plus lisible en pr\xe9-parsant la donn\xe9e, mais \xe7a veut dire plus de temps et des co\xfbts plus \xe9lev\xe9s."}),"\n",(0,i.jsxs)(n.li,{children:["Une autre solution de lisibilit\xe9 pourrait \xeatre d’ajouter des UDF (User Defined Functions), qu’il faudrait maintenir et d\xe9ployer sur chaque instance d’",(0,i.jsx)(n.strong,{children:"Azure Synapse"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Elle sera ",(0,i.jsx)(n.strong,{children:"difficile \xe0 tester"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Elle risque de ne pas profiter de la ",(0,i.jsx)(n.strong,{children:"performance"})," offerte par la structure en colonne du data warehouse, parce que les donn\xe9es texte qu’on parse en JSON ne sont pas organisables physiquement en colonnes."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Dans la version ",(0,i.jsx)(n.em,{children:"cloud data platform"})," :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["On a la possibilit\xe9 d’utiliser un ",(0,i.jsx)(n.em,{children:"distributed data processing engine"})," comme ",(0,i.jsx)(n.strong,{children:"Apache Spark"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"On pourra \xe9crire des requ\xeates SQL pour des exp\xe9rimentations rapides."}),"\n",(0,i.jsxs)(n.li,{children:["Et on pourra aussi \xe9crire du code ",(0,i.jsx)(n.strong,{children:"lisible, maintenable et testable"})," dans un langage comme Python ou Scala, quand il s’agit de projet de plus long terme."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Concernant l’",(0,i.jsx)(n.strong,{children:"acc\xe8s \xe0 la donn\xe9e"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Il peut y avoir plusieurs types de consommateurs :","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Des utilisateurs plut\xf4t ",(0,i.jsx)(n.strong,{children:"orient\xe9s business"})," comme des \xe9quipes marketing.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ils vont pr\xe9f\xe9rer utiliser des outils de reporting type ",(0,i.jsx)(n.strong,{children:"Power BI"}),", et donc auront besoin de la donn\xe9e sous forme relationnelle, par exemple dans ",(0,i.jsx)(n.strong,{children:"Azure Synapse"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Des utilisateurs orient\xe9s ",(0,i.jsx)(n.strong,{children:"data analyse / data science"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ils pourront b\xe9n\xe9ficier de SQL qu’ils utilisent souvent directement, au travers de ",(0,i.jsx)(n.strong,{children:"Spark SQL"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["Ils pourront avoir acc\xe8s \xe0 des donn\xe9es non filtr\xe9es pour leur projets data science, gr\xe2ce ",(0,i.jsx)(n.strong,{children:"Spark"})," directement."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Au final la ",(0,i.jsx)(n.em,{children:"cloud data platform"}),", qui contient \xe0 la fois la donn\xe9e sous forme brute dans le ",(0,i.jsx)(n.em,{children:"data lake"}),", et la donn\xe9e dans le ",(0,i.jsx)(n.em,{children:"data warehouse"}),", est ",(0,i.jsx)(n.strong,{children:"adapt\xe9e \xe0 chaque usage"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["A propos des ",(0,i.jsx)(n.strong,{children:"co\xfbts financiers"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Il est difficile de comparer les co\xfbts des services cloud.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"En g\xe9n\xe9ral on constate que le stockage est plut\xf4t pas cher, et que l’essentiel des co\xfbts se trouve dans les calculs."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["L’",(0,i.jsx)(n.strong,{children:"elastic scaling"})," consiste \xe0 pouvoir calibrer le service pour l’usage exact qu’on en a, et de ne pas avoir \xe0 payer plus.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"C’est un des \xe9l\xe9ments qui permet de vraiment optimiser les co\xfbts."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Pour la version ",(0,i.jsx)(n.em,{children:"data warehouse only"}),", l’essentiel des co\xfbts va aller dans ",(0,i.jsx)(n.strong,{children:"Azure Synapse"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Le scaling de ce service peut prendre des dizaines de minutes, donc c’est quelque chose qu’on ne peut faire que de temps en temps."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["Pour la version ",(0,i.jsx)(n.em,{children:"cloud data platform"}),", l’essentiel des co\xfbts est port\xe9 par le ",(0,i.jsx)(n.em,{children:"processing layer"}),", par exemple ",(0,i.jsx)(n.strong,{children:"Spark"}),".","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Spark"})," est particuli\xe8rement \xe9lastique, au point o\xf9 il est commun de d\xe9marrer une instance juste le temps d’une requ\xeate."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}n.default=(0,r.j)(d)}},function(e){e.O(0,[774,105,888,179],function(){return e(e.s=514)}),_N_E=e.O()}]);