<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Designing Cloud Data Platforms – Reading notes</title><meta name="robots" content="index,follow"/><meta name="description" content="My detailed reading notes from computer science books"/><meta property="og:title" content="Designing Cloud Data Platforms – Reading notes"/><meta property="og:description" content="My detailed reading notes from computer science books"/><meta name="theme-color" content="#111" media="(prefers-color-scheme: dark)"/><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover"/><style>
        :root {
          --nextra-primary-hue: 212deg;
          --nextra-navbar-height: 4rem;
          --nextra-menu-height: 3.75rem;
          --nextra-banner-height: 2.5rem;
        }
        
        .dark {
          --nextra-primary-hue: 204deg;
        }
      </style><meta name="msapplication-TileColor" content="#fff"/><meta http-equiv="Content-Language" content="en"/><meta name="description" content="My detailed reading notes from computer science books"/><meta property="og:title" content="Reading notes"/><meta property="og:description" content="My detailed reading notes from computer science books"/><meta name="apple-mobile-web-app-title" content="Reading notes"/><link rel="icon" type="image/x-icon" href="/reading-notes/favicon.ico"/><meta name="next-head-count" content="16"/><link rel="preload" href="/reading-notes/_next/static/css/fe0970de4b0fbea1.css" as="style"/><link rel="stylesheet" href="/reading-notes/_next/static/css/fe0970de4b0fbea1.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/reading-notes/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/reading-notes/_next/static/chunks/webpack-94b934e1f7075309.js" defer=""></script><script src="/reading-notes/_next/static/chunks/framework-7a7e500878b44665.js" defer=""></script><script src="/reading-notes/_next/static/chunks/main-a6c33fc2996ba69b.js" defer=""></script><script src="/reading-notes/_next/static/chunks/pages/_app-bf3cc75fdfa436db.js" defer=""></script><script src="/reading-notes/_next/static/chunks/673-ec1ccb4c07296023.js" defer=""></script><script src="/reading-notes/_next/static/chunks/pages/books/designing-cloud-data-platforms-ec2c9deeda26b02b.js" defer=""></script><script src="/reading-notes/_next/static/kDVEfpXkzKEZdtDkMyubK/_buildManifest.js" defer=""></script><script src="/reading-notes/_next/static/kDVEfpXkzKEZdtDkMyubK/_ssgManifest.js" defer=""></script></head><body><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div dir="ltr"><script>document.documentElement.setAttribute('dir','ltr')</script><div class="nextra-nav-container nx-sticky nx-top-0 nx-z-20 nx-w-full nx-bg-transparent print:nx-hidden"><div class="nextra-nav-container-blur nx-pointer-events-none nx-absolute nx-z-[-1] nx-h-full nx-w-full nx-bg-white dark:nx-bg-dark nx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] dark:nx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:nx-shadow-[0_0_0_1px_#000] contrast-more:dark:nx-shadow-[0_0_0_1px_#fff]"></div><nav class="nx-mx-auto nx-flex nx-h-[var(--nextra-navbar-height)] nx-max-w-[90rem] nx-items-center nx-justify-end nx-gap-2 nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]"><a class="nx-flex nx-items-center hover:nx-opacity-75 ltr:nx-mr-auto rtl:nx-ml-auto" href="/reading-notes/"><img alt="Reading notes homepage" loading="lazy" width="30" height="30" decoding="async" data-nimg="1" style="color:transparent" src="/reading-notes/logo.png"/></a><div class="nextra-search nx-relative md:nx-w-64 nx-hidden md:nx-inline-block mx-min-w-[200px]"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div><a href="https://github.com/mkrtchian/reading-notes" target="_blank" rel="noreferrer" class="nx-p-2 nx-text-current"><svg width="24" height="24" fill="currentColor" viewBox="3 3 18 18"><title>GitHub</title><path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path></svg><span class="nx-sr-only">GitHub</span><span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a><button type="button" aria-label="Menu" class="nextra-hamburger -nx-mr-2 nx-rounded nx-p-2 active:nx-bg-gray-400/20 md:nx-hidden"><svg fill="none" width="24" height="24" viewBox="0 0 24 24" stroke="currentColor" class=""><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16"></path></g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 12h16"></path><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 18h16"></path></g></svg></button></nav></div><div class="nx-mx-auto nx-flex nx-max-w-[90rem]"><div class="motion-reduce:nx-transition-none [transition:background-color_1.5s_ease] nx-bg-transparent"></div><aside class="nextra-sidebar-container nx-flex nx-flex-col md:nx-top-16 md:nx-shrink-0 motion-reduce:nx-transform-none nx-transform-gpu nx-transition-all nx-ease-in-out print:nx-hidden md:nx-w-64 md:nx-sticky md:nx-self-start max-md:[transform:translate3d(0,-100%,0)]"><div class="nx-px-4 nx-pt-4 md:nx-hidden"><div class="nextra-search nx-relative md:nx-w-64"><div class="nx-relative nx-flex nx-items-center nx-text-gray-900 contrast-more:nx-text-gray-800 dark:nx-text-gray-300 contrast-more:dark:nx-text-gray-300"><input spellcheck="false" class="nx-block nx-w-full nx-appearance-none nx-rounded-lg nx-px-3 nx-py-2 nx-transition-colors nx-text-base nx-leading-tight md:nx-text-sm nx-bg-black/[.05] dark:nx-bg-gray-50/10 focus:nx-bg-white dark:focus:nx-bg-dark placeholder:nx-text-gray-500 dark:placeholder:nx-text-gray-400 contrast-more:nx-border contrast-more:nx-border-current" type="search" placeholder="Search documentation…" value=""/></div></div></div><div class="nx-overflow-y-auto nx-overflow-x-hidden nx-p-4 nx-grow md:nx-h-[calc(100vh-var(--nextra-navbar-height)-var(--nextra-menu-height))] nextra-scrollbar"><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100"><ul class="nx-flex nx-flex-col nx-gap-1 max-md:nx-hidden"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/">Introduction</a></li><li class="open"><button class="nx-items-center nx-justify-between nx-gap-2 nx-text-left nx-w-full nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">Reading notes<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]"></path></svg></button><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1"><ul class="nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[&quot;&quot;] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/continuous-discovery-habits/">Continuous Discovery Habits</a></li><li class="nx-flex nx-flex-col nx-gap-1 active"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500" href="/reading-notes/books/designing-cloud-data-platforms/">Designing Cloud Data Platforms</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/designing-data-intensive-applications/">Designing Data-Intensive Applications</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/effective-kafka/">Effective Kafka</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/get-your-hands-dirty-on-clean-architecture/">Get Your Hands Dirty on Clean Architecture</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/grokking-algorithms/">Grokking Algorithms</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-domain-driven-design/">Learning Domain-Driven Design</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-to-scale/">Learning to Scale</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/monolith-to-microservices/">Monolith to Microservices</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/refactoring/">Refactoring: Improving the Design of Existing Code</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/reinventing-organizations/">Reinventing Organizations</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/team-topologies/">Team Topologies</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/the-design-of-web-apis/">The Design of Web APIs</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/unit-testing/">Unit Testing: Principles, Practices, and Patterns</a></li></ul></div></div></li></ul></div></div><ul class="nx-flex nx-flex-col nx-gap-1 md:nx-hidden"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/">Introduction</a></li><li class="open"><button class="nx-items-center nx-justify-between nx-gap-2 nx-text-left nx-w-full nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">Reading notes<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-h-[18px] nx-min-w-[18px] nx-rounded-sm nx-p-0.5 hover:nx-bg-gray-800/5 dark:hover:nx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="nx-origin-center nx-transition-transform rtl:-nx-rotate-180 ltr:nx-rotate-90 rtl:nx-rotate-[-270deg]"></path></svg></button><div class="nx-transform-gpu nx-overflow-hidden nx-transition-all nx-ease-in-out motion-reduce:nx-transition-none"><div class="nx-transition-opacity nx-duration-500 nx-ease-in-out motion-reduce:nx-transition-none nx-opacity-100 ltr:nx-pr-0 rtl:nx-pl-0 nx-pt-1"><ul class="nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[&quot;&quot;] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3"><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/continuous-discovery-habits/">Continuous Discovery Habits</a></li><li class="nx-flex nx-flex-col nx-gap-1 active"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-bg-primary-100 nx-font-semibold nx-text-primary-800 dark:nx-bg-primary-400/10 dark:nx-text-primary-600 contrast-more:nx-border-primary-500 contrast-more:dark:nx-border-primary-500" href="/reading-notes/books/designing-cloud-data-platforms/">Designing Cloud Data Platforms</a><ul class="nx-flex nx-flex-col nx-gap-1 nx-relative before:nx-absolute before:nx-inset-y-1 before:nx-w-px before:nx-bg-gray-200 before:nx-content-[&quot;&quot;] dark:before:nx-bg-neutral-800 ltr:nx-pl-3 ltr:before:nx-left-0 rtl:nx-pr-3 rtl:before:nx-right-0 ltr:nx-ml-3 rtl:nx-mr-3"><li><a href="#1---introducing-the-data-platform" class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-flex nx-gap-2 before:nx-opacity-25 before:nx-content-[&quot;#&quot;] nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">1 - Introducing the data platform</a></li><li><a href="#2---why-a-data-platform-and-not-just-a-data-warehouse" class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-flex nx-gap-2 before:nx-opacity-25 before:nx-content-[&quot;#&quot;] nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">2 - Why a data platform and not just a data warehouse</a></li><li><a href="#3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-flex nx-gap-2 before:nx-opacity-25 before:nx-content-[&quot;#&quot;] nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google</a></li><li><a href="#4---getting-data-into-the-platform" class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-flex nx-gap-2 before:nx-opacity-25 before:nx-content-[&quot;#&quot;] nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">4 - Getting data into the platform</a></li><li><a href="#5---organizing-and-processing-data" class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-flex nx-gap-2 before:nx-opacity-25 before:nx-content-[&quot;#&quot;] nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50">5 - Organizing and processing data</a></li></ul></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/designing-data-intensive-applications/">Designing Data-Intensive Applications</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/effective-kafka/">Effective Kafka</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/get-your-hands-dirty-on-clean-architecture/">Get Your Hands Dirty on Clean Architecture</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/grokking-algorithms/">Grokking Algorithms</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-domain-driven-design/">Learning Domain-Driven Design</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/learning-to-scale/">Learning to Scale</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/monolith-to-microservices/">Monolith to Microservices</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/refactoring/">Refactoring: Improving the Design of Existing Code</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/reinventing-organizations/">Reinventing Organizations</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/team-topologies/">Team Topologies</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/the-design-of-web-apis/">The Design of Web APIs</a></li><li class="nx-flex nx-flex-col nx-gap-1"><a class="nx-flex nx-rounded nx-px-2 nx-py-1.5 nx-text-sm nx-transition-colors [word-break:break-word] nx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:nx-border nx-text-gray-500 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:nx-text-neutral-400 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50 contrast-more:nx-text-gray-900 contrast-more:dark:nx-text-gray-50 contrast-more:nx-border-transparent contrast-more:hover:nx-border-gray-900 contrast-more:dark:hover:nx-border-gray-50" href="/reading-notes/books/unit-testing/">Unit Testing: Principles, Practices, and Patterns</a></li></ul></div></div></li></ul></div><div class="nx-sticky nx-bottom-0 nx-bg-white dark:nx-bg-dark nx-mx-4 nx-py-4 nx-shadow-[0_-12px_16px_#fff] nx-flex nx-items-center nx-gap-2 dark:nx-border-neutral-800 dark:nx-shadow-[0_-12px_16px_#111] contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-shadow-none nx-border-t" data-toggle-animation="off"><div class="nx-grow nx-flex nx-flex-col"><button title="Change theme" class="nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50" id="headlessui-listbox-button-:Rlsr6:" type="button" aria-haspopup="listbox" aria-expanded="false" data-headlessui-state=""><div class="nx-flex nx-items-center nx-gap-2 nx-capitalize"><svg fill="none" viewBox="3 3 18 18" width="12" height="12" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" fill="currentColor" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path></svg><span class="">Light</span></div></button></div></div></aside><nav class="nextra-toc nx-order-last nx-hidden nx-w-64 nx-shrink-0 xl:nx-block print:nx-hidden nx-px-4" aria-label="table of contents"><div class="nextra-scrollbar nx-sticky nx-top-16 nx-overflow-y-auto nx-pr-4 nx-pt-6 nx-text-sm [hyphens:auto] nx-max-h-[calc(100vh-var(--nextra-navbar-height)-env(safe-area-inset-bottom))] ltr:-nx-mr-4 rtl:-nx-ml-4"><p class="nx-mb-4 nx-font-semibold nx-tracking-tight">On This Page</p><ul><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#1---introducing-the-data-platform" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">1 - Introducing the data platform</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#2---why-a-data-platform-and-not-just-a-data-warehouse" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">2 - Why a data platform and not just a data warehouse</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#4---getting-data-into-the-platform" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">4 - Getting data into the platform</a></li><li class="nx-my-2 nx-scroll-my-6 nx-scroll-py-6"><a href="#5---organizing-and-processing-data" class="nx-font-semibold nx-inline-block nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-300 contrast-more:nx-text-gray-900 contrast-more:nx-underline contrast-more:dark:nx-text-gray-50 nx-w-full nx-break-words">5 - Organizing and processing data</a></li></ul><div class="nx-mt-8 nx-border-t nx-bg-white nx-pt-8 nx-shadow-[0_-12px_16px_white] dark:nx-bg-dark dark:nx-shadow-[0_-12px_16px_#111] nx-sticky nx-bottom-0 nx-flex nx-flex-col nx-items-start nx-gap-2 nx-pb-8 dark:nx-border-neutral-800 contrast-more:nx-border-t contrast-more:nx-border-neutral-400 contrast-more:nx-shadow-none contrast-more:dark:nx-border-neutral-400"><a href="https://github.com/mkrtchian/reading-notes/issues/new?title=Feedback%20for%20%E2%80%9CDesigning%20Cloud%20Data%20Platforms%E2%80%9D&amp;labels=feedback" target="_blank" rel="noreferrer" class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50">Question? Give me feedback →<span class="nx-sr-only nx-select-none"> (opens in a new tab)</span></a><a class="nx-text-xs nx-font-medium nx-text-gray-500 hover:nx-text-gray-900 dark:nx-text-gray-400 dark:hover:nx-text-gray-100 contrast-more:nx-text-gray-800 contrast-more:dark:nx-text-gray-50" href="https://github.com/mkrtchian/reading-notes/blob/main/pages/books/designing-cloud-data-platforms.md">Edit this page</a></div></div></nav><div id="reach-skip-nav"></div><article class="nx-w-full nx-break-words nextra-content nx-flex nx-min-h-[calc(100vh-var(--nextra-navbar-height))] nx-min-w-0 nx-justify-center nx-pb-8 nx-pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12"><div class="nextra-breadcrumb nx-mt-1.5 nx-flex nx-items-center nx-gap-1 nx-overflow-hidden nx-text-sm nx-text-gray-500 dark:nx-text-gray-400 contrast-more:nx-text-current"><div class="nx-whitespace-nowrap nx-transition-colors nx-min-w-[24px] nx-overflow-hidden nx-text-ellipsis" title="Reading notes">Reading notes</div><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-w-3.5 nx-shrink-0"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg><div class="nx-whitespace-nowrap nx-transition-colors nx-font-medium nx-text-gray-700 contrast-more:nx-font-bold contrast-more:nx-text-current dark:nx-text-gray-100 contrast-more:dark:nx-text-current" title="Designing Cloud Data Platforms">Designing Cloud Data Platforms</div></div><h1 class="nx-mt-2 nx-text-4xl nx-font-bold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100" id="designing-cloud-data-platforms">Designing Cloud Data Platforms</h1>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">1 - Introducing the data platform<span class="nx-absolute -nx-mt-20" id="1---introducing-the-data-platform"></span><a href="#1---introducing-the-data-platform" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <strong>analytics</strong> permettent essentiellement d’obtenir des métriques pour faire des choix business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Avant l’avènement des ordinateurs, les entreprises utilisaient des moyens manuels, et leur intuition.</li>
<li class="nx-my-2">Dans les années 80 on a vu émerger le concept de data warehouse, qui est une base centralisée de données venant de diverses sources.</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>data warehouses</strong> posent de plus en plus de <strong>problèmes</strong> de nos jours.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les tendances suivantes y contribuent :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les données sont issues de sources de diverses nature, y compris certaines d’entre-elles non structurées, et leur volume est de plus en plus important.</li>
<li class="nx-my-2">Le découpage des applications en microservices fait que collecter des données revient forcément à devoir agréger de multiples sources.</li>
<li class="nx-my-2">Les data scientists ont aussi besoin d’accéder à une version brute de la donnée, et cet usage ne peut pas passer par un data warehouse.</li>
</ul>
</li>
<li class="nx-my-2">Elles ont du mal avec les <strong>3V</strong> (Variety, Volume, Velocity).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Variety</strong> : les data warehouses ne supportent que les <em>structured data</em> dont le schéma est stable, c’est-à-dire en pratique qui sont issues de DB relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Or avec l’avènement des SaaS, des réseaux sociaux, et de l’IoT, on se retrouve avec :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des <em>semistructured data</em> du type JSON, Avro etc, dont le schéma varie souvent.</li>
<li class="nx-my-2">Des <em>unstructured data</em> comme le binaire, le son, la vidéo.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Volume</strong> : le fait que dans un data warehouse, la puissance de calcul et le stockage doivent se trouver sur <strong>la même machine physique</strong>, implique qu’on ne peut pas scaler les deux séparément, et donc les coûts explosent.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Même les petites organisations peuvent être amenées à traiter plusieurs TB de données.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Velocity</strong> : les data warehouses ne sont pas adaptées aux analytics en mode real time, elles sont plus orientées batch processing.</li>
<li class="nx-my-2">Le machine learning en particulier pose tous les problèmes en même temps : il nécessite une grande quantité de données variées, et accapare la puissance de calcul du data warehouse.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>data lakes</strong> répondent en partie à ces problèmes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’idée principale des data lakes c’est qu’on <strong>stocke de la donnée telle quelle</strong> (ou quasi), et qu’on essayera de la traiter et de lui coller un schéma dès qu’on en aura besoin.</li>
<li class="nx-my-2">Les data lakes se sont généralisés à partir de 2006 avec l’arrivée de <strong>Hadoop</strong>, qui est un <strong>filesystem distribué sur plusieurs machines</strong> pas chères.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Hadoop répond en partie aux 3V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">A la <em>Variety</em> par l’écriture schema-less.</li>
<li class="nx-my-2">Au <em>Volume</em> par le fait que ce soit distribué sur des machines pas chères.</li>
<li class="nx-my-2">A la <em>Velocity</em> par la facilité de streaming à partir du filesystem distribué.</li>
</ul>
</li>
<li class="nx-my-2">Mais il a aussi des problèmes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C’est un système complexe qu’il faut installer sur un datacenter et gérer par des Ops expérimentés.</li>
<li class="nx-my-2">D’un point de vue business, c’est plus difficile de travailler avec les outils qui traitent les données non structurées qu’avec du SQL comme dans un data warehouse.</li>
<li class="nx-my-2">Bien qu’il soit distribué sur de petites machines pas chères, le computing et le stockage ne sont pas séparés, ce qui limite quand même la réduction de coût quand on a besoin de beaucoup de l’un sans l’autre.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>cloud public</strong> vient répondre aux problèmes de Hadoop.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les data warehouses et les data lakes ont été proposés par les cloud providers, avec de nombreux avantages :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La possibilité de scaler la puissance de calcul et le stockage séparément.</li>
<li class="nx-my-2">Payer uniquement à l’usage des machines qu’on emprunte.</li>
<li class="nx-my-2">Ne plus avoir à gérer la complexité de l’infrastructure.</li>
<li class="nx-my-2">Des outils et frameworks avancés développés par les cloud providers autour de leurs produits.</li>
</ul>
</li>
<li class="nx-my-2">Exemple : <strong>AWS EMR</strong> permet de lancer un cluster sur lequel on va pouvoir exécuter des jobs <strong>Hadoop</strong> et <strong>Spark</strong>,<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a juste à indiquer le nombre de nœuds qu’on veut, et les packages qu’on veut installer dessus.</li>
<li class="nx-my-2">Et on a la possibilité de faire des allers-retours vers <strong>S3</strong> pour scaler différemment le calcul et le stockage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La <strong>cloud data platform</strong> moderne utilise à la fois le data warehouse et le data lake, hébergés dans un cloud public, chacun d’entre eux remplissant un usage particulier.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour être polyvalente et pas chère, la data platform doit avoir des <strong>4 composants principaux faiblement couplés</strong>, interagissant entre-eux avec une API bien définie.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Ingestion layer</strong> : on va chercher les données chez les différents types de sources (DB relationnelle, DB NoSQL, API externes etc.).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va en général utiliser un ensemble d’outils open source ou commerciaux pour chaque type de données à aller chercher.</li>
<li class="nx-my-2">Il ne faut <strong>surtout pas altérer la donnée à cette étape</strong>, pour que la donnée brute soit disponible pour les data scientists qui en auraient l’usage.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Storage layer</strong> : on utilise le stockage cloud comme stockage de notre <em>data lake</em>, dans lequel on met ce qu’on a ingéré.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le stockage cloud a l’avantage de ne pas avoir besoin de planifier la capacité de stockage : il grossit automatiquement au besoin.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Processing layer</strong> : on transforme la donnée pour la rendre utilisable par la plupart des clients de la plateforme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C’est la partie calcul de notre <em>data lake</em>, il va lire depuis le cloud storage puis écrire à nouveau dedans.</li>
<li class="nx-my-2">Dans le cas du <strong>streaming</strong>, on ne passe pas par le storage layer qui prend trop de temps, mais on envoie la donnée <strong>directement au processing layer</strong>, qui va ensuite la rendre disponible au layer d’après.</li>
<li class="nx-my-2">Le processing est généralement fait avec des outils open source, les plus connus étant <strong>Spark</strong>, <strong>Beam</strong> et <strong>Flink</strong>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Serving layer</strong> : on rend la donnée disponible sous divers formats, selon les besoins des clients de la plateforme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les usages peuvent être :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des analystes qui ont besoin d’exécuter des requêtes SQL sur la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut charger la donnée dans un <em>data warehouse</em> chez le cloud provider.</li>
</ul>
</li>
<li class="nx-my-2">Des applications qui ont besoin d’un accès rapide à la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut la charger dans une key / value DB, ou une document DB.</li>
</ul>
</li>
<li class="nx-my-2">Des équipes de data scientists / engineers ont besoin de transformer la donnée eux-mêmes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut leur donner accès au storage du <em>data lake</em>, et les laisser utiliser <strong>Spark</strong>, <strong>Beam</strong> ou <strong>Flink</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La cloud data platform répond aux 3V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’ingestion layer couplé au stockage sans schéma permet une grande <em>Variety</em> des données.</li>
<li class="nx-my-2">La séparation calcul / stockage et le fait de ne payer que ce qu’on utilise permet d’optimiser les coûts, et d’avoir un gros <em>Volume</em>.</li>
<li class="nx-my-2">La possibilité d’envoyer directement au <em>processing layer</em> permet de la <em>Velocity</em>.</li>
<li class="nx-my-2">On peut aussi prendre en compte deux autres V :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La <em>Veracity</em> qui indique le niveau de <em>data governance</em>, c’est-à-dire la qualité de la donnée. On l’obtient itérativement, au cours d’étapes au sein du data lake.</li>
<li class="nx-my-2">Et la <em>Value</em> qu’on peut tirer de la donnée, qui peut être plus élevée si on prend plus de données en amont de notre processus de nettoyage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Il faut comprendre les <strong>cas d’usages principaux</strong> d’un <em>data lake</em>, pour éviter de le transformer en <em>data swamp</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi les plus courants il y a la <strong>vue 360° des clients</strong>, où il s’agit de récupérer toutes les données d’interaction avec eux, pour proposer ensuite des services plus personnalisés, vendre plus etc.</li>
<li class="nx-my-2">Il y a aussi les <strong>données venant d’IoT</strong>, qui ont la particularité d’être incertaines et d’avoir un gros volume, ce qui rend l’utilisation du <em>data warehouse</em> peu intéressante.</li>
<li class="nx-my-2">Et enfin il y a le <strong>machine learning</strong> qui a besoin d’une très grande quantité de données, et qui tire avantage de puissance de calcul séparée des autres use-cases grâce au <em>data lake</em>.</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">2 - Why a data platform and not just a data warehouse<span class="nx-absolute -nx-mt-20" id="2---why-a-data-platform-and-not-just-a-data-warehouse"></span><a href="#2---why-a-data-platform-and-not-just-a-data-warehouse" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce chapitre donne des <strong>arguments pour le choix d’une <em>cloud data platform</em>, plutôt qu’une simple <em>data warehouse</em></strong>.</li>
<li class="nx-my-2">On implémente les deux solutions pour une situation d’<strong>exemple</strong> qu’on va utiliser dans ce chapitre :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Nous sommes l’équipe data, et le département marketing a besoin que nous récupérions deux sources de données et qu’on les corrèle régulièrement.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’une des sources est une table de campagnes de marketing, issue d’une DB MySQL interne.</li>
<li class="nx-my-2">Et l’autre est constituée de fichiers CSV de clics utilisateurs, issus de logs applicatifs (et donc <em>semistructured</em>).</li>
</ul>
</li>
<li class="nx-my-2">On part sur Microsoft Azure pour les deux solutions.</li>
<li class="nx-my-2">Concernant l’implémentation <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On va utiliser deux <strong>Azure Data Factory</strong> pour récupérer la donnée dans le serveur de DB et dans les fichiers CSV dans le serveur SFTP. C’est notre <em>ingest layer</em>.</li>
<li class="nx-my-2">2 - Ensuite on redirige ça vers l’<strong>Azure Synapse</strong>, qui est la data warehouse de chez Azure. Elle va faire office de <em>store layer</em>, <em>process layer</em> et <em>serve layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Concernant l’implémentation <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On a notre <em>ingest layer</em> avec <strong>Azure Data Factory</strong>, qui redirige les données vers le <em>store layer</em>.</li>
<li class="nx-my-2">2 - Le <em>store layer</em> est implémenté avec <strong>Azure Blob Storage</strong>. Il s’agit d’un stockage de type <em>data lake</em>.</li>
<li class="nx-my-2">3 - On a un <em>process layer</em> qui utilise <strong>Azure Databricks</strong>, et qui fait tourner <strong>Spark</strong>.</li>
<li class="nx-my-2">4 - Le <em>serve layer</em> utilise enfin <strong>Azure Synapse</strong> qui est le data warehouse.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant l’<strong>ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour la version <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La pipeline contient :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des <em>linked services</em> : ici la <em>data source</em> MySQL en entrée, et la <em>data sink</em> <strong>Azure Synapse</strong> en sortie.</li>
<li class="nx-my-2">Des <em>data sets</em> : il s’agit de la description du schéma de données d’entrée et de sortie, et leur mapping.</li>
</ul>
</li>
<li class="nx-my-2">Si le schéma de la DB source change, il faudra mettre à jour le schéma défini dans la pipeline et le mapping.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Mais surtout il faudra <strong>gérer soi-même la migration</strong> du <em>data sink</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette fois le <em>data sink</em> est un <strong>Azure Blob Storage</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il n’y a plus besoin de spécifier les schémas et le mapping entre input et output puisque l’output accueille la donnée telle quelle.</li>
</ul>
</li>
<li class="nx-my-2">Si le schéma de la DB source change, il n’y a <strong>rien à faire côté ingestion</strong> : on écrira de toute façon la donnée dans un nouveau fichier.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On déplace le problème de mapping plus loin.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le <strong>processing</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Dans la version <em>data warehouse only</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va charger les deux données :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La DB MySQL sans charger sa structure parce qu’elle est déjà relationnelle.</li>
<li class="nx-my-2">La donnée CSV semistructurée dans des rows de type texte qu’on parsera en JSON avec une fonction SQL built-in.</li>
</ul>
</li>
<li class="nx-my-2">La <strong>requête SQL</strong> qu’on va écrire aura les désavantages suivants :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elle sera <strong>peu lisible</strong>, à cause du code de parsing nécessaire.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourrait la rendre plus lisible en pré-parsant la donnée, mais ça veut dire plus de temps et des coûts plus élevés.</li>
<li class="nx-my-2">Une autre solution de lisibilité pourrait être d’ajouter des UDF (User Defined Functions), qu’il faudrait maintenir et déployer sur chaque instance d’<strong>Azure Synapse</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Elle sera <strong>difficile à tester</strong>.</li>
<li class="nx-my-2">Elle risque de ne pas profiter de la <strong>performance</strong> offerte par la structure en colonne du data warehouse, parce que les données texte qu’on parse en JSON ne sont pas organisables physiquement en colonnes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Dans la version <em>cloud data platform</em> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a la possibilité d’utiliser un <em>distributed data processing engine</em> comme <strong>Apache Spark</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourra écrire des requêtes SQL pour des expérimentations rapides.</li>
<li class="nx-my-2">Et on pourra aussi écrire du code <strong>lisible, maintenable et testable</strong> dans un langage comme Python ou Scala, quand il s’agit de projet de plus long terme.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant l’<strong>accès à la donnée</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il peut y avoir plusieurs types de consommateurs :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Des utilisateurs plutôt <strong>orientés business</strong> comme des équipes marketing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils vont préférer utiliser des outils de reporting type <strong>Power BI</strong>, et donc auront besoin de la donnée sous forme relationnelle, par exemple dans <strong>Azure Synapse</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Des utilisateurs orientés <strong>data analyse / data science</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils pourront bénéficier de SQL qu’ils utilisent souvent directement, au travers de <strong>Spark SQL</strong>.</li>
<li class="nx-my-2">Ils pourront avoir accès à des données non filtrées pour leur projets data science, grâce <strong>Spark</strong> directement.</li>
</ul>
</li>
<li class="nx-my-2">Au final la <em>cloud data platform</em>, qui contient à la fois la donnée sous forme brute dans le <em>data lake</em>, et la donnée dans le <em>data warehouse</em>, est <strong>adaptée à chaque usage</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">A propos des <strong>coûts financiers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est difficile de comparer les coûts des services cloud.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">En général on constate que le stockage est plutôt pas cher, et que l’essentiel des coûts se trouve dans les calculs.</li>
</ul>
</li>
<li class="nx-my-2">L’<strong>elastic scaling</strong> consiste à pouvoir calibrer le service pour l’usage exact qu’on en a, et de ne pas avoir à payer plus.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C’est un des éléments qui permet de vraiment optimiser les coûts.</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>data warehouse only</em>, l’essentiel des coûts va aller dans <strong>Azure Synapse</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le scaling de ce service peut prendre des dizaines de minutes, donc c’est quelque chose qu’on ne peut faire que de temps en temps.</li>
</ul>
</li>
<li class="nx-my-2">Pour la version <em>cloud data platform</em>, l’essentiel des coûts est porté par le <em>processing layer</em>, par exemple <strong>Spark</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Spark</strong> est particulièrement élastique, au point où il est commun de démarrer une instance juste le temps d’une requête.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">3 - Getting bigger and leveraging the Big 3: Amazon, Microsoft, and Google<span class="nx-absolute -nx-mt-20" id="3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google"></span><a href="#3---getting-bigger-and-leveraging-the-big-3-amazon-microsoft-and-google" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe un trade off entre choisir des <strong>services vendor-specific</strong> de type PaaS, et choisir des <strong>services open source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">D’un côté on se couple au vendor mais on minimise les coûts d’Ops, et de l’autre on permet une meilleure portabilité mais on augmente les coûts d’Ops.</li>
<li class="nx-my-2">Les auteurs trouvent que la solution vendor-specific est celle qui a en général le moins de désavantages.</li>
</ul>
</li>
<li class="nx-my-2">Pour répondre aux problématiques de la data moderne, il faut une <strong>architecture en 6 couches</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Data ingestion layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Se connecter aux sources et récupérer la donnée dans le data lake sans trop la modifier.</li>
<li class="nx-my-2">Enregistrer des statistiques et un statut dans le <em>metadata repository</em>.</li>
</ul>
</li>
<li class="nx-my-2">Selon les auteurs, il vaut mieux mettre en place <strong>à la fois un mécanisme de type batch et un mécanisme de type streaming</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L&#x27;industrie est en train de se diriger vers le streaming, mais de nombreuses sources externes fournissent la donnée sous un format de type batch avec des éléments groupés, par exemple CSV, JSON, XML.</li>
<li class="nx-my-2">On pourrait utiliser la partie batch pour ingérer des données par petits batchs, et éviter de faire la version streaming. Mais ça créerait de la <strong>dette technique</strong> parce qu’on finira par avoir besoin du streaming à un moment ou un autre.</li>
<li class="nx-my-2">La <em>lambda architecture</em> consiste à avoir la donnée qui passe à la fois par le mécanisme de batch et par le mécanisme de streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette duplication était nécessaire parce que le streaming n’était pas fiable dans les débuts de Hadoop, mais ce n’est plus le cas.</li>
<li class="nx-my-2">Le <em>cloud data platform</em> ne consiste pas à faire une telle duplication : selon la source, la donnée va passer par le mécanisme de streaming ou de batch.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On entend parfois plusieurs choses différentes quand on parle de <em>real time</em> pour des analytics :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La <em>real time ingestion</em> consiste à avoir la donnée disponible pour de l’analyse dès qu’elle arrive.</li>
<li class="nx-my-2">2 - Le <em>real time analytics</em> consiste à avoir des fonctionnalités d’analytics qui se mettent à jour à chaque arrivée de donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette dernière est plus difficile à faire, donc il vaut mieux bien clarifier les besoins.</li>
<li class="nx-my-2">Exemple : détection de fraude en temps réel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Storage layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Stocker la donnée pour du court terme et du long terme.</li>
<li class="nx-my-2">La rendre disponible pour la consommation streaming et la consommation batch.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>slow storage</strong> est là pour le mode batch.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La donnée y est persistée pour pas cher, grâce à la possibilité de scaler le stockage sans ajouter de capacité de calcul.</li>
<li class="nx-my-2">Par contre les temps d’accès sont grands.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>fast storage</strong> est là pour le mode streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit d’utiliser un outil qui est fait pour l’accès rapide, comme <strong>Apache Kafka</strong>.</li>
<li class="nx-my-2">Par contre, on n’a en général pas la possibilité de scaler le stockage sans ajouter de puissance de calcul, et donc les coûts sont plus grands.</li>
<li class="nx-my-2">On va donc purger régulièrement la donnée du fast storage, et de la transférer dans le slow storage.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - Processing layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Lire la donnée depuis le stockage et y appliquer de la business logic.</li>
<li class="nx-my-2">Persister la donnée modifiée à nouveau dans le stockage pour un usage par les data scientists.</li>
<li class="nx-my-2">Délivrer la donnée aux autres consumers.</li>
</ul>
</li>
<li class="nx-my-2">Il faut un ou plusieurs outils qui permettent de réaliser des transformations de données, y compris avec du calcul distribué.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un exemple peut être <strong>Google Dataflow</strong>, qui est une version PaaS d’<strong>Apache Beam</strong>, qui supporte à la fois le mode streaming et le mode batch.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Technical metadata layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Stocker des informations techniques sur chaque layer.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça peut être les schémas d’ingestion, le statut de telle ou telle étape, des statistiques sur les données ou les erreurs, etc.</li>
</ul>
</li>
<li class="nx-my-2">Permettre à chaque d’ajouter/modifier ou consulter des informations.</li>
</ul>
</li>
<li class="nx-my-2">Par exemple, le processing layer peut vérifier dans la <em>technical metadata layer</em> qu’une certaine donnée est disponible pour aller la chercher, plutôt que de demander à l’ingestion layer.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce qui permet un certain <strong>découplage</strong>.</li>
</ul>
</li>
<li class="nx-my-2">D’autres exemples peuvent impliquer des usages de <strong>monitoring</strong>.</li>
<li class="nx-my-2">La <em>business metadata</em> est une autre notion qui peut avoir son layer, mais qui n’est pas explorée dans ce livre.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit d’identifier l’usage business qui est fait de chaque donnée qu’on récupère des sources, et d’en faire un catalogue.</li>
</ul>
</li>
<li class="nx-my-2">Il n’y a pas vraiment d’outil unique qui permette de remplir ce rôle pour le moment, donc on devra sans doute en utiliser plusieurs.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple <strong>Confluent Schema Registry</strong> et <strong>Amazon Glue</strong> peuvent supporter certains des cas d’usages.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>5 - Serving layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Servir les consumers qui ont besoin de données relationnelles via une <em>data warehouse</em>.</li>
<li class="nx-my-2">Servir les consumers qui ont besoin de la donnée brute, en accédant directement au <em>data lake</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les data scientistes vont en général vouloir y accéder via le slow storage.</li>
<li class="nx-my-2">Et l’accès via le fast storage va plutôt intéresser les applications qui s’abonnent en mode streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple un système de recommandation ecommerce en temps réel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>6.1 - Orchestration overlay layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Coordonner l’exécution de jobs, sous la forme d’un graphe de dépendance.</li>
<li class="nx-my-2">Gérer les échecs et les retries.</li>
</ul>
</li>
<li class="nx-my-2">C’est un peu le complément du <em>technical metadata layer</em> pour permettre le faible couplage entre les layers.</li>
<li class="nx-my-2">L’outil le plus connu d’orchestration est <strong>Apache Airflow</strong>, adopté par Google Cloud Platform sous le nom de <strong>Google Composer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">AWS et Azure ont quant à eux choisi d’inclure des fonctionnalités d’orchestration dans leur outil d’ETL.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>6.2 - ETL overlay layer</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Son but est de :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Prendre en charge les fonctionnalités de certains layers (ingestion, processing, metadata, orchestration) <strong>avec peu ou pas de code</strong>.</li>
</ul>
</li>
<li class="nx-my-2">On pourrait faire l’ensemble de notre pipeline avec cet outil ETL, la question à se poser c’est : <strong>à quel point il est ouvert à l’extension ?</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut vouloir à l’avenir par exemple utiliser un autre outil de processing, ou s’interfacer avec un outil open source.</li>
<li class="nx-my-2">Dans le cas où il y a une incompatibilité avec un usage qu’on a, on peut toujours l’implémenter à part de l’outil ETL.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le problème c’est qu’au bout d’un moment, les usages à côté deviennent aussi complexes que la solution entière sans l’outil ETL, mais avec une <strong>architecture spaghetti</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Parmi les outils ETL il y a <strong>AWS Glue</strong>, <strong>Azure Data Factory</strong> et <strong>Google Cloud Data Fusion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe des solutions commerciales non cloud-natives comme <strong>Talend</strong> et <strong>Informatica</strong>, mais ce livre se limite au cloud-native et aux outils open source.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>couches</strong> doivent être bien <strong>séparées et découplées</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une première raison est de pouvoir utiliser les outils les plus adaptés aux besoins de chaque couche.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le cloud bougeant très vite, on voudra sans doute pouvoir changer seulement l’un d’entre eux quand on a une meilleure alternative pour une couche en particulier.</li>
</ul>
</li>
<li class="nx-my-2">Une autre raison est qu’on peut avoir plusieurs équipes en charge de la data platform, et il vaut mieux qu’elles ne se gênent pas.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple, on voudra souvent avoir l’ingestion plutôt centralisée, et le processing plutôt en mode libre service pour chaque équipe qui en a besoin.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les <strong>outils</strong> pouvant servir dans une des couches de notre plateforme sont classés en 4 catégories (les auteurs les priorisent dans cet ordre) :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Solutions <strong>cloud-native PaaS</strong> d’AWS, GCP ou Azure.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leur avantage principal c’est le gain de temps : on n’a pas à se préoccuper de la compatibilité. On configure très facilement et c’est en prod.</li>
<li class="nx-my-2">Par contre, c’est la solution qui va être la moins extensible : si par exemple un connecteur n’est pas supporté, on aura du mal à l’ajouter.</li>
<li class="nx-my-2">Elle est aussi peu portable, vu qu’on n’a pas les mêmes services d’un cloud provider à un autre.</li>
</ul>
</li>
<li class="nx-my-2">2 - Solutions <strong>serverless</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit de pouvoir déployer son code custom, mais sans avoir à se préoccuper des serveurs, de leur configuration, du scaling etc.</li>
<li class="nx-my-2">C’est une solution intermédiaire d’un point de vue trade-offs sur la flexibilité, la portabilité et le gain de temps.</li>
</ul>
</li>
<li class="nx-my-2">3 - Solutions <strong>open-source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leur avantage c’est c’est la flexibilité et la portabilité maximales, mais de l’autre côté on a à gérer soi-même des VMs dans le cloud donc plus de travail d’Ops.</li>
</ul>
</li>
<li class="nx-my-2">4 - Solutions <strong>SaaS commerciales</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elles peuvent avoir un intérêt si elles ont une fonctionnalité non disponible sous forme PaaS ou open source.</li>
</ul>
</li>
<li class="nx-my-2">Dans les faits, on va utiliser un <strong>mix de solutions des 4 catégories</strong> en fonction des layers et des besoins qu’on a.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a de plus en plus d’entreprises qui utilisent des solutions de <strong>plusieurs cloud providers</strong>. Par exemple le gros des services sur AWS, et le use-case machine learning sur GCP.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>AWS</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Glue</strong> supporte l’ingestion à partir de <strong>AWS S3</strong>, ou à partir d’une connexion JDBC.</li>
<li class="nx-my-2"><strong>AWS Database Migration Service</strong> sert à la base à transférer ses DBs vers AWS, mais on peut l’utiliser comme ingestion layer.</li>
<li class="nx-my-2"><strong>AWS DMS</strong> permet d’implémenter un mécanisme de change data capture à partir d’une DB.</li>
<li class="nx-my-2">Si aucune des solutions PaaS ne supporte notre data source, on peut utiliser la solution serverless <strong>AWS Lambda</strong> où il faudra écrire et maintenir du code.</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Kinesis</strong> est un message broker pour lequel il faudra écrire du code pour publier dedans. Il a malheureusement très peu de connecteurs entrants.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">En revanche il a des connecteurs sortants appelés <strong>Kinesis Firehose</strong>, qui permettent par exemple d’envoyer la donnée de Kinesis dans un <strong>S3</strong> sous format Parquet.</li>
</ul>
</li>
<li class="nx-my-2"><strong>AWS Managed Streaming for Apache Kafka (MSK)</strong> est une version de <strong>Kafka</strong> entièrement managée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut l’utiliser à la place de <strong>Kinesis</strong>, par exemple si on migre une application avec <strong>Kafka</strong> vers AWS.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS S3</strong> permet de stocker de la donnée de manière scalable, avec la possibilité de choisir entre plusieurs formules avec des latences plus ou moins grandes.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Elastic MapReduce (EMR)</strong> est une version managée de <strong>Spark</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va en général lire la donnée depuis <strong>S3</strong>, faire le calcul, puis détruire le cluster <strong>EMR</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Kinesis Data Analytics</strong> permet de se brancher sur <strong>Kinesis</strong>, et de faire du processing en streaming.</li>
<li class="nx-my-2">Si on utilise <strong>AWS MSK</strong>, on peut brancher dessus <strong>Kafka Streams</strong> pour le processing en streaming.</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Redshift</strong> est un data warehouse distributé sur plusieurs noeuds.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Redshift Spectrum</strong> permet de faire des requêtes depuis <strong>Redshift</strong> pour obtenir des données qui sont en fait sur <strong>S3</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra définir des “tables externes”, et la performance de la query sera moins bonne, mais ça permet d’économiser de la place dans le data warehouse.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Athena</strong> permet de faire une requête SQL distribuée en utilisant directement la donnée sur <strong>S3</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On lance l’instance le temps de la requête, puis on détruit l’instance.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Glue</strong> est un outil d’ETL complet.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est construit autour de <strong>Spark</strong>, et possède des templates pour faciliter de nombreuses transformations.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a aussi des add-ons <strong>Spark</strong> non-standards, ce qui nuit à la portabilité par rapport à un simple <strong>Spark</strong> managé.</li>
</ul>
</li>
<li class="nx-my-2">Il maintient un <em>Data Catalog</em> à partir des données disponibles sur <strong>S3</strong>.</li>
<li class="nx-my-2">Il maintient un ensemble de statistiques sur l’exécution des jobs.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Step Functions</strong> permet de créer des workflows qui mettent en jeu différents services, y compris ceux qui ne seraient pas gérés par <strong>Glue</strong> comme <strong>AWS Lambda</strong> avec du code custom.</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour les outils comme <strong>Tableau</strong> qui ont besoin d’une connexion JDBC/ODBC qui supporte SQL, elles peuvent se connecter à <strong>Redshift</strong> ou <strong>Athena</strong>.</li>
<li class="nx-my-2">Pour du streaming avec faible latence, on peut envoyer la donnée dans un key/value store comme <strong>DynamoDB</strong>, ou dans une DB comme <strong>AWS RDS</strong> ou <strong>AWS Aurora</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>GCP</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Cloud Data Fusion</strong> est un ETL overlay qui permet d’ingérer des données depuis une DB relationnelle avec JDBC, des fichiers depuis <strong>Google Cloud Storage</strong>, et même depuis un FTP ou depuis <strong>AWS S3</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est basé sur un projet open source, et donc supporte des connecteurs custom.</li>
</ul>
</li>
<li class="nx-my-2"><strong>BigQuery Data Transfer Service</strong> permet d’ingérer de la donnée depuis les services SaaS de Google, et depuis des centaines d’autres services SaaS connus grâce à un partenariat avec Fivetran.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par contre, la donnée va directement dans le data warehouse, ce qui ne permet pas vraiment l’architecture modulaire qu’on vise.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Cloud Functions</strong> représente l’équivalent d’<strong>AWS Lambda</strong>, avec le désavantage d’avoir une limite de temps d’exécution des fonctions serverless.</li>
</ul>
</li>
<li class="nx-my-2">Stream ingrestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Cloud Pub/Sub</strong> est un broker équivalent à <strong>AWS Kinesis</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Google Cloud Storage</strong> est un équivalent à <strong>AWS S3</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Dataproc</strong> est un <strong>Spark</strong> managé équivalent à <strong>AWS EMR</strong>.</li>
<li class="nx-my-2"><strong>Cloud Dataflow</strong> est un <strong>Apache Beam</strong> managé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Beam</strong> a l’avantage d’offrir une même API pour le batch processing et le streaming processing, là où <strong>Spark</strong> ne supporte que le batch mais est une techno plus mature.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Cloud Dataflow</strong> représente la manière clou-native de faire du streaming sur GCP.</li>
<li class="nx-my-2"><strong>Dataproc</strong> avec <strong>Spark Streaming</strong> peut représenter une alternative, mais il s’agit en fait de micro-batch et non pas de traiter les messages un par un.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent <strong>Beam</strong>, sauf si on a déjà investi en temps ou connaissances sur <strong>Spark</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>BigQuery</strong> est un équivalent à <strong>AWS RedShift</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a l’avantage de scaler le nombre de nœuds tout seul.</li>
<li class="nx-my-2">Par contre il a un modèle de facturation basé sur la donnée lue par chaque requête, ce qui peut rendre les coûts difficiles à prédire.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">GCP ne propose pas de services pour accéder au <em>data lake</em> directement avec du SQL.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut éventuellement créer des tables vers de la donnée externe (donc dans le <em>data lake</em>) à partir de <strong>BigQuery</strong>.</li>
<li class="nx-my-2">On peut aussi utiliser <strong>Spark SQL</strong> pour identifier et lire de la donnée sur le <em>data lake</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Cloud Data Fusion</strong> est un ETL overlay équivalent à <strong>AWS Glue</strong>. Il fournit une UI qui permet de configurer la pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il met à disposition un moyen d’analyser quelle partie de la pipeline peut affecter telle ou telle donnée.</li>
<li class="nx-my-2">Il met aussi à disposition des statistiques sur l’exécution des jobs.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Cloud Composer</strong> permet de créer des flows d’orchestration entre jobs.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est basé sur <strong>Apache Airflow</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>BigQuery</strong> n’a pas de connexion JDBC/ODBC pour y connecter un outil BI par exemple.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a une API REST, et il est directement compatible avec certains outils BI.</li>
</ul>
</li>
<li class="nx-my-2">Si on veut consommer la donnée avec une faible latence, on peut la mettre dans le key/value store <strong>Cloud Bigtable</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Outils sur <strong>Azure</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Data Factory</strong> est un ETL overlay permettant de faire de l’ingestion depuis diverses sources (DB, SaaS externes, <strong>S3</strong>, <strong>GCS</strong> etc.).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est celui qui a le plus de connecteurs comparé à <strong>AWS Glue</strong> et <strong>Cloud Data Fusion</strong>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Azure Functions</strong> est l’équivalent d’<strong>AWS Lambda</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il ne supporte que Java et Python.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Event Hubs</strong> est équivalent à <strong>AWS Kinesis</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a la particularité d’être compatible avec <strong>Apache Kafka</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Storage.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Blob Storage</strong> est équivalent à <strong>AWS S3</strong>.</li>
<li class="nx-my-2"><strong>Azure Data Lake Storage</strong> est une version améliorée qui supporte mieux le calcul distribué avec de grandes quantités de données.</li>
</ul>
</li>
<li class="nx-my-2">Batch processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour le batch processing, Azure a choisi de miser sur un partenariat avec <strong>Databricks</strong>, qui est un service créé par les créateurs de <strong>Spark</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La version managée de <strong>Databricks</strong> est disponible sur AWS et Azure, mais elle est celle par défaut sur Azure, donc mieux supportée par son écosystème.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming processing.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Azure Stream Analytics se branche sur Event Hubs et permet de faire du streaming processing.</li>
</ul>
</li>
<li class="nx-my-2">Data warehouse.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Synapse</strong> est le <em>data warehouse</em> d’Azure.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il est entre <strong>AWS Redshift</strong> et <strong>Google BigQuery</strong> dans la mesure où il nécessite de choisir la capacité de calcul, mais il scale l’espace disque tout seul.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Direct access.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Databricks</strong> est la manière privilégiée d’accéder à la donnée sur le <em>data lake</em>, soit par l’API native de <strong>Spark</strong>, soit en SQL avec <strong>Spark SQL</strong>.</li>
</ul>
</li>
<li class="nx-my-2">ETL overlay et metadata repository.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Data Factory</strong> est équivalent à <strong>AWS Glue</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’intègre parfaitement avec <strong>Databricks</strong> pour les transformations complexes.</li>
<li class="nx-my-2">Il fournit des métriques sur la data pipeline.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La partie orchestration des jobs est prise en charge par Azure Data Factory.</li>
</ul>
</li>
<li class="nx-my-2">Consumers.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Synapse</strong> fournit une connexion JDBC/ODBC pour connecter les outils de BI.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Databricks</strong> fournit la même chose, mais il faut un cluster Spark toujours allumé, ce qui peut coûter cher.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Cosmos DB</strong> est une DB orientée document où on peut stocker les résultats de processings pour un accès faible latence.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Alternatives <strong>commerciales</strong> ou <strong>open source</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains logiciels open source sont trop difficiles à mettre en place, par exemple un <em>data warehouse</em> distribué comme <strong>Apache Druid</strong>.</li>
<li class="nx-my-2">Batch ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il existe pas mal d’outils open source et commerciaux qui permettent d’ingérer des données, leur valeur ajoutée étant en général le grand nombre de sources supportées.</li>
<li class="nx-my-2"><strong>Apachi NiFi</strong> est une solution open source qui supporte de nombreuses sources, et permet d’en ajouter soi-même en Java.</li>
<li class="nx-my-2">Il existe de nombreux outils SaaS commerciaux qui gèrent l’ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ces outils vont souvent envoyer la donnée directement dans un data warehouse.</li>
<li class="nx-my-2">Il faut bien réfléchir à la problématique de la sécurité.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Streaming ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Apache Kafka</strong> est le principal outil utilisé en dehors d’une solution managée de streaming.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il a l’avantage de pouvoir se connecter à de nombreuses sources avec <strong>Kafka Connect</strong>, et il a un moyen d’implémenter des applications de streaming avec <strong>Kafka Streams</strong>.</li>
<li class="nx-my-2">Les raisons de choisir <strong>Kafka</strong> plutôt qu’une solution cloud-native peuvent être l’investissement qu’on a déjà dans <strong>Kafka</strong> (par exemple connaissances), ou le besoin de performance nécessitant le fine-tuning du serveur <strong>Kafka</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Apache Airflow</strong> est le principal outil utilisé en dehors d’une solution managée d’orchestration.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La raison de l’utiliser en mode non managé peut être de profiter de sa flexibilité, avec ses fichiers en Python.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">4 - Getting data into the platform<span class="nx-absolute -nx-mt-20" id="4---getting-data-into-the-platform"></span><a href="#4---getting-data-into-the-platform" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le layer d’ingestion peut avoir besoin d’ingérer différents types de données :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Les bases de données relationnelles</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Leurs données sont organisées en colonnes et typées, mais chaque vendor a des types à lui.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a donc un <strong>mapping</strong> à faire entre le type de chaque colonne et notre modèle.</li>
<li class="nx-my-2">Ce mapping va changer régulièrement en fonction des évolutions fonctionnelles des applications qui utilisent cette DB.</li>
</ul>
</li>
<li class="nx-my-2">Vu que la donnée est normalisée, elle se trouve dans des centaines de tables qu’on peut joindre au moment des queries.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra donc <strong>automatiser le mapping</strong> pour éviter de le faire à la main.</li>
</ul>
</li>
<li class="nx-my-2">La donnée change régulièrement dans la DB, pour refléter l’état de l’application, elle est <strong>volatile</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra donc aller chercher régulièrement les derniers changements.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Les fichiers.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers sont structurés selon divers types de format texte ou binaire (CSV, JSON XML, Avro, Protobuf etc.) qui ne contiennent pas d’information de type.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc pouvoir <strong>supporter le parsing de tous ces formats</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers ne garantissent aucun schéma, et on voit beaucoup plus souvent des changements dans celui-ci que pour les DB relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc gérer les <strong>changements de schéma fréquents</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers représentent en général de la <strong>donnée figée</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La nouvelle donnée est écrite dans un autre fichier, donc on se retrouve à devoir ingérer <strong>de nombreux fichiers</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>3 - La donnée SaaS via API.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les données SaaS sont en général disponibles via une API REST, qui renvoie du JSON.</li>
<li class="nx-my-2">Chaque provider a sa propre API, et son propre format. Il faudra donc <strong>implémenter la partie ingestion pour chacun des providers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra faire la validation du schéma à chaque fois.</li>
<li class="nx-my-2">Il faudra la tenir à jour en fonction des changements d’API.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Les streams</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les mêmes données peuvent arriver plusieurs fois, donc il faut que notre pipeline puisse <strong>gérer les duplicatas</strong>.</li>
<li class="nx-my-2">Les events des streams sont immutables, et peuvent être corrigés en ajoutant un autre message modifié au stream.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Donc il faut que notre pipeline <strong>gère la réconciliation entre plusieurs versions d’un même message</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Les données de streaming ont en général un <strong>grand volume</strong>, donc il faut une infrastructure qui le supporte.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>bases de données relationnelles</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il y a deux moyens d’ingérer de la donnée depuis une DB relationnelle :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - L’utilisation de requêtes SQL</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit d’avoir un composant qui va :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Exécuter la requête vers la DB concernée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ca peut être un simple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="sql" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="sql" data-theme="default"><span class="line"><span style="color:var(--shiki-token-keyword)">SELECT</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">*</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">FROM</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">table</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Récupérer la donnée sous un format qu’il comprend.</li>
<li class="nx-my-2">3 - Mapper la donnée dans le bon format pour la stocker sur le <em>storage layer</em>.</li>
<li class="nx-my-2">Il y a donc <strong>2 mappings</strong> qui se produisent pendant l’opération.</li>
</ul>
</li>
<li class="nx-my-2">Alors que la donnée opérationnelle s’intéresse à l’état actuel (“Quels sont les articles dans le panier ?”), <strong>la donnée analytique s’intéresse à l’évolution de l’état dans le temps</strong> (“Quels articles ont été ajoutés ou enlevés et dans quel ordre ?”).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut donc un moyen pour capturer l’évolution de la donnée dans le temps.</li>
</ul>
</li>
<li class="nx-my-2">Une 1ère solution pour garder l’évolution dans le temps est de faire une <strong>full table ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va récupérer l’ensemble des données d’une table à intervals réguliers, sauver ces snapshots dans le <em>data lake</em>, et les charger dans le <em>data warehouse</em>.</li>
<li class="nx-my-2">Pour en tirer quelque chose, il faut** superposer les rows des snapshots** dans la même table du <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour différencier les rows de chaque snapshot, on peut ajouter une colonne <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">INGEST_DATE</code>.</li>
<li class="nx-my-2">On peut directement utiliser du SQL pour obtenir les données qu’on veut, mais pour certains usages on aura besoin de faire une transformation dans le <em>processing layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les données dérivées qu’on voudra créer, il peut y avoir :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Créer une <em>view</em> qui ne montre que les rows du dernier snapshot.</li>
<li class="nx-my-2">De la donnée qui <strong>identifie les suppressions</strong>, en identifiant les rows qui existaient dans un snapshot et n’existaient plus dans le suivant.</li>
<li class="nx-my-2">Une version “compactée”, qui élimine les rows qui n’ont pas changé par rapport au snapshot précédent.</li>
</ul>
</li>
<li class="nx-my-2">Le problème de la full table ingestion, c’est la charge sur la machine de DB, et l’<strong>énorme quantité de données</strong> qu’on finit par avoir.</li>
</ul>
</li>
<li class="nx-my-2">Une autre solution peut être l’<strong>incremental table ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit toujours de récupérer des snapshots à intervalles réguliers, mais <strong>seulement de la donnée qui a changé</strong> depuis le précédent snapshot.</li>
<li class="nx-my-2">Pour savoir quelle donnée a changé :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La table d’origine doit avoir un champ <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">LAST_MODIFIED</code>, mis à jour automatiquement par la DB.</li>
<li class="nx-my-2">En retenant le <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">MAX(LAST_MODIFIED)</code> du dernier run d’ingestion (qu’on appelle le <em>highest watermark</em>), on peut construire une query qui récupère uniquement les nouvelles données :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="sql" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="sql" data-theme="default"><span class="line"><span style="color:var(--shiki-token-keyword)">SELECT</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">*</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-keyword)">FROM</span><span style="color:var(--shiki-color-text)"> subscriptions </span><span style="color:var(--shiki-token-keyword)">WHERE</span><span style="color:var(--shiki-color-text)"> LAST_MODIFIED </span><span style="color:var(--shiki-token-keyword)">&gt;</span><span style="color:var(--shiki-color-text)"> </span><span style="color:var(--shiki-token-string-expression)">&quot;2019-05-01 17:01:00&quot;</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">On pourra mettre le <em>highest watermark</em> dans le <em>technical metadata layer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>AWS Glue</strong> gère nativement le stockage de ce genre de données, mais on peut le mettre dans une DB managée comme <strong>Google Cloud SQL</strong> ou <strong>Azure SQL Database</strong>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Cette <em>incremental table ingestion</em> permet d’ingérer moins de données dupliquées, mais elle a encore des inconvénients :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut faire du processing pour faire apparaître les données supprimées, en comparant les snapshots entre eux.</li>
<li class="nx-my-2">Les données qui sont insérées puis supprimées entre deux snapshots ne seront pas capturées par ce mécanisme, donc <strong>on perd des informations</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>2 - Le Change Data Capture (CDC)</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le CDC permet de récupérer <strong>l’ensemble des opérations</strong> qui ont lieu sur la table, <strong>sans aucun doublon</strong>.</li>
<li class="nx-my-2">Il s’agit de lire le log de changements créé par la DB, à l’aide d’une application qui sait le faire.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’application peut être fournie par la DB, ou une application cloud-native comme <strong>AWS Database Migration Service</strong>, ou une application open source comme <strong>Debezium</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Etant donné que les DBs ne gardent pas longtemps leur log de changements, <strong>le CDC nécessite une infrastructure de type streaming</strong> pour être récupéré.</li>
<li class="nx-my-2">Le format des messages récupérés depuis le log de changements contient la valeur du row avant, sa valeur après l’opération, le type d’opération, et des metadata.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va vouloir mettre dans le <em>data warehouse</em> uniquement la valeur après l’opération et le type d’opération.</li>
<li class="nx-my-2">La table dans le <em>data warehouse</em> ressemble du coup au cas de l’<em>incremental table ingestion</em> : on a une entrée par changement.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <strong>Oracle</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Oracle fournit <strong>Oracle GoldenGate</strong>, une application qui permet de lire son log de changement et de le transférer vers diverses plateformes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut acheter la licence pour pouvoir l’utiliser.</li>
</ul>
</li>
<li class="nx-my-2">On peut mettre en place <strong>Debezium</strong> qui est open source, mais il faudra qu’il puisse se connecter à <strong>Oracle XStream API</strong>, qui lui-même nécessite quand même une licence <strong>GoldenGate</strong>.</li>
<li class="nx-my-2">Oracle fournit un outil d’analyse qui s’appelle <strong>LogMiner</strong>, qui est considéré comme pas 100% fiable.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains outils comme <strong>AWS Database Migration Service</strong> l’utilisent malgré tout.</li>
</ul>
</li>
<li class="nx-my-2">Une alternative moins chère à <strong>GoldenGate</strong> peut être <strong>SharePlex</strong>, un produit fait par Quest.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <strong>MySQL</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>MySQL</strong> écrit les changements dans un log servant principalement à la réplication, pour ajouter des DBs followers.</li>
<li class="nx-my-2">Vu que c’est une DB open source, il existe de nombreux outils pour servir d’application CDC à partir de ce log, par exemple : <strong>Debezium</strong> et <strong>Apache NiFi</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <strong>MS SQL Server</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>MS SQL Server</strong> fournit la possibilité de rediriger le log de changements d’une table vers une table créée spécialement pour ça.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut donc facilement implémenter un outil CDC qui n’a qu’à utiliser SQL pour lire cette nouvelle table régulièrement.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les outils qui supportent le CDC sur <strong>MS SQL Server</strong>, il y a par exemple: <strong>Debezium</strong>, <strong>Apache NiFi</strong> et <strong>AWS Database Migration Service</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Le CDC sur une DB <strong>PostgreSQL</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>PostgreSQL</strong> supporte le fait de fournir son log de changements sous un format Protobuf ou JSON, ce qui facilite le travail des applications CDC.</li>
<li class="nx-my-2">Il existe de nombreux outils qui savent lire ces données, par exemple : <strong>Debezium</strong> et <strong>AWS Database Migration Service</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le <strong>mapping des données</strong> depuis la DB vers le <em>data warehouse</em>, il va falloir faire une <strong>analyse pour vérifier la compatibilité</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - On prépare une liste des types de données supportées par la DB dont on veut capturer les données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il vaut mieux prendre l’ensemble des types, en prévision d’ajout de colonnes avec des types qui n’étaient pas utilisés jusque là par l’application.</li>
</ul>
</li>
<li class="nx-my-2">2 - On prépare une liste des types supportés par le <em>data warehouse</em> de destination, et on identifie les différences avec la précédente.</li>
<li class="nx-my-2">3 - On identifie les types qui ne correspondent pas exactement, mais permetteront une conversion sans perte d’information.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple un type <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">SMALLINT</code> sur <strong>MySQL</strong> comme source, et le seul entier disponible sur <strong>Google BigQuery</strong> qui est l’équivalent d’un <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">BIGINT</code>.</li>
</ul>
</li>
<li class="nx-my-2">4 - On identifie les types qui n’ont pas de correspondance satisfaisante, et pourraient mener à une perte d’information.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On essaye de voir si on ne peut pas trouver un workaround, par exemple transformer des données géospatiales en string, puis utiliser du processing pour les parser au moment de la lecture.</li>
</ul>
</li>
<li class="nx-my-2">5 - Si on est devant une impasse, on essaye de voir s’il n’y a pas un outil de <em>data warehouse</em> plus adapté.</li>
<li class="nx-my-2">6 - Dans le cas où notre application d’ingestion n’est pas faite à la main, on vérifie les types qu’elle supporte, et leur compatibilité avec la source et la destination.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent de faire plusieurs PoC, et disent de ne pas faire confiance aux documentations de ces outils.</li>
</ul>
</li>
<li class="nx-my-2">7 - Si on écrit l’application d’ingestion à la main, il faut vérifier les types supportés par le driver qui nous permet d’accéder à la DB. Par exemple le driver JDBC.</li>
</ul>
</li>
<li class="nx-my-2">Les DBs <strong>NoSQL</strong> sont à traiter différemment des DBs relationnelles.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi les solutions courantes :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut utiliser un outil SaaS commercial qui supporte notre DB NoSQL : dans ce cas rien de plus à faire.</li>
<li class="nx-my-2">Implémenter l’application d’ingestion à la main, en utilisant l’API de notre DB NoSQL directement pour accéder aux données.</li>
<li class="nx-my-2">Utiliser une application CDC si c’est disponible.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple <strong>Debezium</strong> supporte MongoDB.</li>
</ul>
</li>
<li class="nx-my-2">On peut utiliser l’outil d’export de données de notre DB NoSQL, et le faire tourner régulièrement pour avoir un snapshot des données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>MongoDB</strong> permet d’obtenir les données sous un format CSV ou JSON, et l’outil permet d’ajouter des requêtes, donc on peut avoir une colonne qui a la date de la dernière modification, et faire un <em>incremental table ingestion</em>.</li>
<li class="nx-my-2"><strong>Cassandra</strong> permet d’obtenir les données sous un format CSV, mais uniquement en mode <em>full table ingestion</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata liées à l’ingestion</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut sauvegarder un certain nombre de statistiques pour pouvoir ensuite faire des vérifications sur la <strong>qualité des données</strong> ingérées, et du <strong>monitoring</strong> de l’ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va mettre tout ça dans notre <em>technical metadata layer</em>.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>statistiques</strong> qu’on veut :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le nom et l’adresse IP du serveur de DB.</li>
<li class="nx-my-2">Le nom de la base de données ou du schéma.</li>
<li class="nx-my-2">Le nom de la table.</li>
<li class="nx-my-2">Le type de DB dans le cas où on en gère plusieurs.</li>
<li class="nx-my-2">Pour de l’ingestion en batch, le nombre de rows ingérées.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On pourra à partir de ça vérifier que l’ensemble des données sont arrivées à destination.</li>
<li class="nx-my-2">On peut monitorer ce chiffre pour être alerté dans le cas d’une variation anormale.</li>
</ul>
</li>
<li class="nx-my-2">La durée de chaque job d’ingestion, de même que le début et la fin de l’ingestion.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">C’est un moyen de monitorer la santé de la pipeline.</li>
</ul>
</li>
<li class="nx-my-2">Pour de l’ingestion en streaming, on prend les statistiques par <strong>fenêtre temporelle</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Par exemple insérer un row toutes les 5 mn dans notre DB de technical metadata. Plus on a besoin de réagir vite, et plus on va choisir une fenêtre petite.</li>
<li class="nx-my-2">On peut aussi ajouter le nombre d’inserts, updates, deletes etc. pour chaque fenêtre.</li>
</ul>
</li>
<li class="nx-my-2">Les changements dans le schéma de la DB source, ce qui nous permettra d’être alerté et d’adapter la pipeline.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>fichiers</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers (par exemple CSV, JSON) permettent un bon découplage entre deux systèmes.</li>
<li class="nx-my-2">On a en général deux moyens de mettre à disposition des fichiers :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Via un serveur dédié qui expose un protocole <strong>FTP</strong>.</li>
<li class="nx-my-2">Via le service de <strong>storage d’un cloud provider</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les avantages sont l’aspect <em>elastic</em>, et les mécanismes de sécurité pré-configurés.</li>
<li class="nx-my-2">Le désavantage principal c’est que c’est cloud provider met en place des coûts pour faire sortir la donnée de son infrastructure.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Les fichiers sont <strong>immutables</strong> une fois qu’ils sont écrits, ce qu’on aura besoin de tracker c’est <strong>quels fichiers ont déjà été ingérés</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - Une approche recommandée par les auteurs c’est d’avoir <strong>deux dossiers</strong> dans le système source qui met à disposition les fichiers : <strong>incoming</strong> et <strong>processed</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’application d’ingestion va ingérer un fichier depuis <em>incoming</em>, puis une fois que l’ingestion est terminée, elle va le copier dans <em>processed</em> et le supprimer d’<em>incoming</em>.</li>
<li class="nx-my-2">On le laisse dans <em>processed</em> pendant quelques jours dans un but de débug et de replay, avant de le supprimer.</li>
<li class="nx-my-2">Parmi les avantages :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On n’a pas besoin de tracker quels fichiers ont été traités : il suffit de traiter ceux du dossier <em>incoming</em>.</li>
<li class="nx-my-2">On peut facilement rejouer l’ingestion en replaçant le fichier depuis <em>processed</em> vers <em>incoming</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">2 - Dans le cas où l’approche des deux dossiers n’est pas possible, parce que le système source veut organiser autrement ses fichiers, ou qu’on n’a pas la possibilité de les modifier, on peut mettre en place l’approche des <strong>timestamps</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque fichier va avoir un timestamp de la dernière fois qu’il a été modifié, et on va devoir garder le timestamp le plus récent dont on a ingéré un fichier dans le <em>technical metadata layer</em>.</li>
<li class="nx-my-2">Vu que le filesystem ne fournit pas de système d’indexation, on va devoir lire à chaque fois les metadata de l’ensemble des fichiers pour savoir s’ils sont plus récents ou moins récents que notre timestamp sauvegardé.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut se retrouver face à un problème de performance, surtout avec les stockages cloud de masse.</li>
</ul>
</li>
<li class="nx-my-2">Cette méthode rend plus compliqué le replay des fichiers : on devra possiblement modifier notre dernier timestamp sauvegardé, et on aura du mal avec les fichiers qui ont le même timestamp de modification.</li>
<li class="nx-my-2">Certains outils comme <strong>Apache NiFi</strong> implémentent déjà ce mécanisme.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faudra faire attention à faire un backup de ces données pour ne pas avoir à reprocesser tous les fichiers.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">3 - Une variante de l’approche des timestamps consiste à organiser les fichiers source dans une <strong>arborescence de dossiers représentant la date d’ajout</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="bash" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="bash" data-theme="default"><span class="line"><span style="color:var(--shiki-token-function)">/ftp/inventory_data/incoming/2019/05/28/sales_1_081232</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">On peut s’en servir pour ne lire que les metadata des fichiers qui sont à la date qu’on veut ingérer.</li>
</ul>
</li>
<li class="nx-my-2">4 - Des <strong>outils cloud-native</strong> existent pour copier des fichiers d’un storage à un autre, et de ne copier que les nouveaux fichiers à chaque fois qu’il y en a.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>gsutil</strong> permet de le faire chez Google Cloud, <strong>blobxfer</strong> chez Azure, et <strong>s3 sync</strong> chez AWS.</li>
<li class="nx-my-2">Il est compliqué de faire du replay avec ces outils, parce qu’il n’y a pas de dernier timestamp stocké à modifier.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On ne va pas à ce stade récupérer de statistiques sur le nombre de rows dans le fichier, parce que ce serait techniquement coûteux pour l’ingestion layer.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On le fait pour les DBs parce que c’est pas cher.</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>statistiques à récupérer</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Nom permettant d’identifier la source.</li>
<li class="nx-my-2">Taille du fichier.</li>
<li class="nx-my-2">Durée de l’ingestion.</li>
<li class="nx-my-2">Le nom du fichier et le path où il était (peut contenir des infos importantes).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>streams</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit ici de lire de la donnée disponible dans Kafka, ou encore dans un équivalent cloud-native.</li>
<li class="nx-my-2">On parle ici seulement d’<strong>ingestion en mode streaming</strong>, c’est-à-dire que la donnée est disponible dans la plateforme dès que possible, mais elle sera exploitée plus tard.</li>
<li class="nx-my-2">Les étapes à mettre en place sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">1 - La 1ère étape est de l<strong>ire le stream source, et de l’écrire dans le <em>fast storage</em></strong> de notre <em>cloud data platform</em>, qui est aussi un stream.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut faire ça avec <strong>Kafka Connect</strong>, qui permet de lire et écrire entre deux topics <strong>Kafka</strong>, mais aussi de lire depuis <strong>Kafka</strong> et écrire dans une solution de streaming cloud-native, ou l’inverse.</li>
<li class="nx-my-2">On peut aussi faire notre propre application <strong>consumer Kafka à la main</strong>, mais il faudra alors s’occuper de la gestion des erreurs, du logging, et du scaling de notre consumer. Les auteurs le <strong>déconseillent</strong>.</li>
</ul>
</li>
<li class="nx-my-2">2 - On va ensuite <strong>l’écrire dans le <em>data warehouse</em></strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent fortement d’utiliser une solution <strong>cloud-native</strong> pour ça, en fonction de notre fast storage :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Azure Stream Analytics</strong> qui lit depuis <strong>Azure Event Hubs</strong> pour écrire dans <strong>Azure SQL Warehouse</strong>.</li>
<li class="nx-my-2"><strong>Google Cloud Dataflow</strong> qui lit depuis <strong>Cloud Pub/Sub</strong> pour écrire dans <strong>BigQuery</strong>.</li>
<li class="nx-my-2"><strong>AWS Kinesis Data Firehose</strong> qui lit depuis <strong>AWS Kinesis</strong> pour écrire dans <strong>Redshift</strong>.</li>
</ul>
</li>
<li class="nx-my-2">Pour <strong>BigQuery</strong> on peut ingérer dans le data warehouse en streaming, mais pour les deux autres, il faudra faire de petits batchs.</li>
</ul>
</li>
<li class="nx-my-2">3 - L’autre chose à faire en parallèle c’est d’écrire la donnée <strong>depuis le <em>fast storage</em> vers le <em>slow storage</em></strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut là aussi utiliser les solutions cloud-natives.</li>
<li class="nx-my-2">Il va falloir écrire la donnée par batchs pour des raisons de performance. Les auteurs recommandent des <strong>batchs de plusieurs centaines de MB</strong> si c’est possible.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Kafka</strong> (et les solutions cloud-natives similaires) doit faire le commit de son offset, et en général il le fait après avoir traité plusieurs messages pour des raisons de performance;<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça veut dire que si il y a un crash, les message traités mais non commités seront traités à nouveau. Donc il faut <strong>gérer la duplication</strong>.</li>
<li class="nx-my-2">Un des moyens de le faire c’est d’avoir un identifiant unique par message, et ensuite d’enlever les doublons dans la phase de processing.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Kafka</strong> a en général une <em>cleanup policy</em> qui est de l’ordre de la semaine, ce qui fait que pour <strong>rejouer de la donnée</strong>, il faut prévoir une étape qui va la chercher dans le <em>slow storage</em>, et la remet dans le <em>fast storage</em>.</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les metadata à garder ressemblent à ceux du cas CDC depuis les DBs relationnelles.</li>
<li class="nx-my-2">On mesure le nombre de messages ingérés par fenêtre de temps (dont la taille dépendra du type de données ingérées).</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant le cas des <strong>applications SaaS</strong> qui fournissent de la donnée.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les applications SaaS vont en général exposer leurs données via une API REST, le contenu étant formaté en JSON ou parfois en XML.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il faut d’abord s’authentifier, souvent avec OAuth.</li>
<li class="nx-my-2">Et ensuite il faut étudier la documentation du provider SaaS pour savoir quel call faire.</li>
</ul>
</li>
<li class="nx-my-2">Il y a un certain nombre de difficultés.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque provider va <strong>designer son API selon ses contraintes</strong>. Et donc si on veut supporter de nombreux providers, il va falloir adapter l’<em>ingestion layer</em> pour chacun d’eux.</li>
<li class="nx-my-2">Chaque provider va fournir soit du <strong>full data export</strong> soit de l’<strong>incremental data export</strong>, et parfois les deux.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le <em>full data export</em> consiste à obtenir une liste d’objets, puis à aller chercher les données pour chacun d’entre eux.</li>
<li class="nx-my-2">L’<em>incremental data export</em> consiste à obtenir une liste d’objets qui ont changé entre deux timestamps qu’on fournit, pour ensuite aller chercher leurs données récentes uniquement.</li>
</ul>
</li>
<li class="nx-my-2">Le <strong>JSON</strong> reçu est en général <strong>imbriqué sur plusieurs niveaux</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Certains <em>data warehouses</em> gèrent les données imbriquées, mais ce n’est pas le cas de <strong>Redshift</strong> pour lequel il faudra faire une étape de processing pour mettre ces données à plat.</li>
<li class="nx-my-2">De manière générale, mettre les données à plat dans plusieurs tables plus petites est plus pratique pour les data scientists.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Etant donné la difficulté à implémenter et maintenir une pipeline ingérant de la donnée de sources SaaS, les auteurs conseillent de <strong>bien réfléchir à l’implémenter soi-même</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">S’il s’agit d’une source pas trop compliquée, ça peut passer.</li>
<li class="nx-my-2">Si par contre il s’agit de nombreuses sources, alors il nous faudra une grande quantité de code et de maintenance.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs conseillent plutôt une solution off-the-shelf comme <strong>Fivetran</strong> qui supporte la plupart des sources SaaS connues.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Concernant les <strong>metadata techniques à garder</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit du même type de metadata que pour les sources en batch comme les DBs ou les fichiers.</li>
<li class="nx-my-2">On voudra notamment :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le nom de la source.</li>
<li class="nx-my-2">Le nom de l’objet qu’on va chercher dans la source.</li>
<li class="nx-my-2">Les temps de début et fin d’ingestion.</li>
<li class="nx-my-2">Le nombre de rows qu’on récupère.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour des questions de <strong>sécurité</strong>, il est préférable d’encapsuler notre cloud data platform dans un <strong>virtual private cloud (VPC)</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Pour faire le lien entre la plateforme dans le VPC et la donnée qu&#x27;on veut aller chercher, on peut utiliser un <strong>VPN Gateway</strong>, qui permet de passer par internet de manière sécurisée.</li>
<li class="nx-my-2">Dans le cas des SaaS comme source, ils fournissent des APIs sécurisées par HTTPS, et disponibles globalement sur internet, donc il n’est pas nécessaire d’établir une connexion via <em>VPN Gateway</em>.</li>
<li class="nx-my-2">Dans le cas où on veut transférer des centaines de GB par jour, il vaut mieux mettre en place une <strong>connexion directe</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les solutions cloud-natives ont leur outil de connexion directe : <strong>AWS Direct Connect</strong>, <strong>Azure ExpressRoute</strong>, <strong>Google Cloud Interconnect</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="nx-font-semibold nx-tracking-tight nx-text-slate-900 dark:nx-text-slate-100 nx-mt-10 nx-border-b nx-pb-1 nx-text-3xl nx-border-neutral-200/70 contrast-more:nx-border-neutral-400 dark:nx-border-primary-100/10 contrast-more:dark:nx-border-neutral-400">5 - Organizing and processing data<span class="nx-absolute -nx-mt-20" id="5---organizing-and-processing-data"></span><a href="#5---organizing-and-processing-data" class="subheading-anchor" aria-label="Permalink for this section"></a></h2>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les architectes de l’ancienne école ont encore tendance à recommander de <strong>faire le processing dans le data warehouse</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les auteurs du livre suggèrent que la manière moderne est de le faire <strong>sur des machines à part</strong>, par exemple avec <strong>Spark</strong>, qui lirait et écrirait dans le <em>data lake</em>.</li>
<li class="nx-my-2">Les arguments sont les suivants ((1) pour faire le calcul dans le <em>data warehouse</em>, et (2) pour utiliser la <em>layered architecture</em>) :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>Flexibility</strong> : avec la (1) le résultat du processing n’est utilisable que dans le <em>data warehouse</em>, avec la (2) on peut facilement le rediriger ailleurs.</li>
<li class="nx-my-2"><strong>Developer productivity</strong> : il y a plus de personnes qui connaissent le SQL, donc le (1) a un avantage court terme, bien que <strong>Spark</strong> soit plus puissant, il faut souvent former les devs.</li>
<li class="nx-my-2"><strong>Data governance</strong> : la source principale étant le <em>data lake</em>, faire les transformations au même endroit permet d’être sûr d’avoir toutes les versions alignées. Dans le cas où on fait ça dans le <em>data warehouse</em>, il est préférable de ne pas le faire dans le <em>data lake</em> pour ne pas avoir de divergence.</li>
<li class="nx-my-2"><strong>Cross-platform portability</strong> : changer de cloud vendor est bien plus simple avec <strong>Spark</strong> qu’avec du code SQL qu’il faudra au moins tester.</li>
<li class="nx-my-2"><strong>Performance</strong> : avec la (1) le processing impacte le data warehouse, avec le (2) on fait le calcul complètement à part et on n’impacte personne.</li>
<li class="nx-my-2"><strong>Speed of processing</strong> : avec la (1) on peut faire du <em>real time analytics</em> dans certains cas avec difficulté, avec la (2) ça marche facilement.</li>
<li class="nx-my-2"><strong>Cost</strong> : tous les providers de <em>data warehouse</em> ne le font pas (mais ils vont finir par le faire), mais pour ceux qui font payer le processing ça revient plus cher que de faire le processing sur des machines complètement à part.</li>
<li class="nx-my-2"><strong>Reusability</strong> : avec la (1) on peut parfois utiliser des <em>stored procedures</em>, avec la (2) on a du code qu’on peut directement réutiliser.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Le processing se décompose en <strong>stages</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Chaque <em>stage</em> contient : une <em>area</em> de stockage dans le data lake, et un job de calcul distribué (par exemple avec <strong>Spark</strong>), qui va créer la donnée pour l’étape suivante.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les jobs sont coordonnés par l’<em>orchestration layer</em>.</li>
<li class="nx-my-2">Les jobs peuvent être de deux types :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">**Common **data processing : les transformations communes, par exemple dédupliquer les messages, valider les dates etc.</li>
<li class="nx-my-2">**Business logic specific **processing : les transformations spécifiques à chaque use-case, qui vont par exemple filtrer les campagnes de marketing à succès uniquement si le use-case c’est d’afficher les meilleures campagnes.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Avoir un ensemble de <em>stages</em> standardisés est important pour que chacun puisse s’y retrouver malgré le scale.</li>
<li class="nx-my-2">Les étapes proposés par les auteurs sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>1 - Landing area</strong> : c’est là que la donnée arrive en premier, il ne s’agit pas d’un stockage long terme.</li>
<li class="nx-my-2"><strong>2 - Staging area</strong> : la donnée subit des checks basiques de qualité, et on vérifie qu’elle est conforme au schéma attendu. Elle est stockée sous format <strong>Avro</strong>.</li>
<li class="nx-my-2"><strong>3 - Archive area</strong> : la donnée est copiée depuis la <em>landing area</em> vers l’<em>archive area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Cette opération n’est effectuée qu’après que la donnée ait pu aller vers la <em>staging area</em> avec succès.</li>
<li class="nx-my-2">On pourra refaire le processing de la donnée simplement en la copiant depuis l’<em>archive area</em> vers la <em>landing area</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4 - Production area</strong> : la donnée subit la transformation business nécessaire pour un use-case particulier avant d’aller là.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Elle est aussi transformée du format <strong>Avro</strong> vers <strong>Parquet</strong>, qui est plus adapté pour faire de l’analytics.</li>
<li class="nx-my-2"><strong>4.1 - Pass-through job</strong> : il s’agit d’un job qui copie la donnée de la <em>staging area</em> vers la <em>production area</em> sans transformation autre que le format <strong>Parquet</strong>, et ensuite la copie dans le <em>data warehouse</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ce use-case “basique” est utile pour débugguer les autres use-cases.</li>
</ul>
</li>
<li class="nx-my-2"><strong>4.2 - Cloud data warehouse and production area</strong> : les use-cases qui ont besoin de la donnée dans le <em>data warehouse</em> passent d’abord par le processing de la <em>staging area</em> vers la <em>production area</em>.</li>
</ul>
</li>
<li class="nx-my-2"><strong>5 - Failed area</strong> : chaque étape peut être face à des erreurs, qu’elles soient liées à la donnée ou à des échecs temporaires de la pipeline.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les messages qui n’ont pas réussi une étape vont dans cette area où on pourra les examiner et voir ce qu’il faut corriger.</li>
<li class="nx-my-2">Une fois la correction faite, il suffit de les copier dans l’area de l’étape où ils ont échoués.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Chaque <strong>area</strong> doit être dans un <strong>container</strong> du service de stockage de notre cloud provider.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les <em>containers</em> contiennent des <em>folders</em>.</li>
<li class="nx-my-2">Ils sont appelés <em>buckets</em> chez AWS et GCP.</li>
<li class="nx-my-2">C’est au niveau de ces containers qu’on peut configurer les droits d’accès, et choisir le prix qu’on paye pour les performances qu’on aura (hot / cold / archive storage).<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Parmi nos 5 areas, toutes sont de type <em>hot</em>, sauf l’archive area qui peut être <em>cold</em> / <em>archive</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On a besoin d’une <strong>organisation des folders</strong> claire dans chaque <em>area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les éléments communs sont :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Le <strong>namespace</strong> représente la catégorisation la plus high level, pour les petites organisations ça peut être juste le nom de l’organisation, mais pour les plus grandes ça peut être le nom du département.</li>
<li class="nx-my-2">Le <strong>pipeline name</strong> représente le nom d’un job en particulier. Il faut qu’il soit clair par rapport à ce que fait le job, et utilisé partout pour parler de lui.</li>
<li class="nx-my-2">Le <strong>data source name</strong> identifie une source. C’est l’<em>ingestion layer</em> qui choisit ce nom et le note dans le <em>metadata layer</em>.</li>
<li class="nx-my-2">Le <strong>batchId</strong> représente l’identifiant de chaque batch de donnée écrit dans la <em>landing area</em> par l’<em>ingestion layer</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut utiliser un UUID pour le représenter, ou encore un ULID, qui a la particularité d’être plus court et de permettre de savoir facilement si un autre ULID est plus grand ou plus petit.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>landing area</em>, les auteurs proposent la folder structure :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">landing/NAMESPACE/PIPELINE/SOURCE_NAME/BATCH_ID/</code>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><em>landing</em> représente le nom du container.</li>
</ul>
</li>
<li class="nx-my-2">Exemple : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">/landing/my_company/sales_oracle_ingest/customers/01DFTQ028FX89YDFAXREPJTR94/</code></li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>staging area</em>, de même que pour les autres <em>areas</em>, il s’agit de stocker la donnée sur le long terme, donc on aimerait une structure qui fasse apparaître le <strong>temps</strong>, avec 3 folders supplémentaires :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Il s’agit d’ajouter 3 folders supplémentaires qui viennent de la convention de <strong>Hadoop</strong> : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">year=YYYY/month=MM/day=DD</code>.</li>
<li class="nx-my-2">Exemple : <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">/staging/my_company/sales_oracle_ingest/customers/year=2019/month=07/day=03/01DFTQ028FX89YDFAXREPJTR94/</code></li>
<li class="nx-my-2">De nombreux outils (y compris <strong>Spark</strong>) vont reconnaître ce format, et si notre batchId est un ULID, les folders les plus récents seront présentés en premier.</li>
</ul>
</li>
<li class="nx-my-2">Pour la <em>production area</em>, on ne peut pas vraiment reporter les sources qui ont servi à la donnée dans le folder name - il y en a potentiellement des dizaines.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On va donc plutôt créer des <strong>sources dérivées</strong> dont on mettra le nom à la place de la source, et on documentera ces sources dérivées dans le <em>metadata layer</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">La donnée qui arrive en <strong>streaming</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Va passer directement vers la version streaming du <em>processing layer</em> sans être stockée d’abord dans le <em>slow storage</em>. C’est traité au chapitre 6.</li>
<li class="nx-my-2">Mais on va quand même l’envoyer dans le slow storage en parallèle pour un but d’archivage et rejeu si besoin.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Un job va lire depuis le fast storage où arrive la donnée en streaming, par batchs suffisamment gros, et va écrire ça dans la <em>landing area</em>.</li>
<li class="nx-my-2">Les fichiers seront ensuite passés de stage en stage jusqu&#x27;à la production area.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Parmi les <strong>common processing steps</strong> :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2"><strong>File format conversion.</strong>
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">L’approche data lake traditionnelle consiste à laisser les données telles quelles, et laisser chaque pipeline parser elle-même la donnée et faire les traitements dont elle a besoin.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Mais cette approche a du mal à scaler.</li>
<li class="nx-my-2">Dans la <em>cloud data platform architecture</em>, on choisit de faire certains traitements en amont, pour éviter d’avoir à tester et maintenir du code qui fait ça dans chaque pipeline.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Avro</strong> et <strong>Parquet</strong> sont des formats binaires intégrant un schéma.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ils permettent de ne pas répéter le nom des champs, et donc d’économiser de la place.</li>
<li class="nx-my-2">Ils permettent de garantir le schéma de la donnée.</li>
<li class="nx-my-2">Avro est organisé en blocs de <em>rows</em>, alors que Parquet est organisé en blocs de <em>columns</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Les fichiers organisés en <em>rows</em> sont utiles quand on lit la donnée de toutes les colonnes pour certains <em>rows</em> donnés. La <em>staging area</em> sert principalement à faire des transformations ou de l’exploration ad-hoc, donc <strong>Avro</strong> est adapté.</li>
<li class="nx-my-2">Les fichiers organisés en <em>columns</em> sont utiles quand on ne veut traiter qu’une <em>column</em> sur un grand nombre de <em>rows</em>. La production area sert à faire des requêtes d’analytics, donc <strong>Parquet</strong> est adapté.</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">Pour la conversion depuis le format initial vers <strong>Avro</strong>, puis vers <strong>Parquet</strong>, <strong>Spark</strong> permet de lire et écrire ces différents formats.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">clicks_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">json</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">clicks_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">write</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;avro&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">save</span><span style="color:var(--shiki-token-punctuation)">(out_path)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Data deduplication</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On s’intéresse ici au fait d’avoir un attribut sur notre donnée qui soit unique dans l’ensemble des données.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">A partir du moment où on n’a pas de garanties d’unicité, on peut se retrouver dans une situation de duplication, par exemple si le <em>metadata repository</em> est corrompu, la source envoie une donnée dupliquée, ou encore un dev rejoue certaines données qui avaient déjà marché.</li>
<li class="nx-my-2">Le problème existe aussi avec <strong>Kafka</strong>, où des transactions existent si on lit un record et qu’on écrit dans un topic <strong>Kafka</strong>, mais pas si on écrit sur un service de storage.</li>
</ul>
</li>
<li class="nx-my-2"><strong>Spark</strong> a une fonction intégrée <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">dropDuplicates()</code> qui permet de dédupliquer en fonction d’une ou plusieurs colonnes.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut dédupliquer sur un batch qui arrive dans la <em>landing area</em> pour pas cher :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;csv&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_deduplicate_df </span><span style="color:var(--shiki-token-keyword)">=</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">dropDuplicates</span><span style="color:var(--shiki-token-punctuation)">([</span><span style="color:var(--shiki-token-string-expression)">&quot;user_id&quot;</span><span style="color:var(--shiki-token-punctuation)">])</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">Si on veut vraiment dédupliquer sérieusement, il faut aussi joindre l’ensemble des données déjà présentes dans la <em>staging area</em> au batch courant, et appliquer la déduplication dessus, par exemple avec du SQL qu’on passe à <strong>Spark</strong>.<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">incoming_users_df</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  </span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">createOrReplaceTempView</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;incomgin_users&quot;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">staging</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">users_df</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  </span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">createOrReplaceTempView</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;staging_users&quot;</span><span style="color:var(--shiki-token-punctuation)">)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_deduplicate_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">sql</span><span style="color:var(--shiki-token-punctuation)">(</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  </span><span style="color:var(--shiki-token-string-expression)">&quot;SELECT * FROM incoming_users u1</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  LEFT JOIN staging_users u2</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  ON u1.user_id </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-token-punctuation)"> u2.user_id</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  WHERE u2.user_id IS NULL</span><span style="color:var(--shiki-token-string-expression)">&quot;</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
<li class="nx-my-2">Le problème c’est que la déduplication à chaque fois avec l’ensemble des données coûte cher. Donc il faut vérifier que notre use-case le nécessite d’un point de vue business.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On peut aussi dédupliquer avec seulement les fichiers dans le dossier de l’année actuelle, du mois actuel etc. depuis la <em>staging area</em>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2"><strong>Data quality checks</strong>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Une vérification minimale de la qualité de la donnée est en général nécessaire pour la plupart des cas d’usages. Par exemple :<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">La longueur de certaines colonnes.</li>
<li class="nx-my-2">La valeur numérique acceptable de certaines colonnes.</li>
<li class="nx-my-2">Le fait d’avoir certaines colonnes “obligatoires”.</li>
<li class="nx-my-2">Le fait d’avoir certaines colonnes respecter un pattern, par exemple l’email.</li>
</ul>
</li>
<li class="nx-my-2">Spark a la fonction <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">filter()</code> qui permet d’obtenir les colonnes qui respectent une mauvaise condition.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">On a aussi <code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr">subtract()</code> qui permet d’enlever ces rows du batch, pour passer les rows valides à la <em>production area</em>, et les rows invalides à la <em>failed area</em>.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Attention à la <strong>consistance des données</strong>, en fonction du contexte business, il peut être plus judicieux de laisser passer la donnée, et de simplement informer les data engineers du problème.</li>
<li class="nx-my-2">De manière générale, il faut réfléchir à <strong>la criticité de chaque problème de qualité</strong> pour décider quoi faire en cas de donnée malformée : filtrer la donnée, laisser passer et prévenir quelqu’un, ou annuler l’ingestion du batch entier.</li>
</ul>
</li>
<li class="nx-my-2">Exemple :<!-- -->
<div class="nextra-code-block nx-relative nx-mt-6 first:nx-mt-0"><pre class="nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-font-medium nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em] contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40 nx-py-4" data-language="python" data-theme="default"><code class="nx-border-black nx-border-opacity-[0.04] nx-bg-opacity-[0.03] nx-bg-black nx-break-words nx-rounded-md nx-border nx-py-0.5 nx-px-[.25em] nx-text-[.9em] dark:nx-border-white/10 dark:nx-bg-white/10" dir="ltr" data-language="python" data-theme="default"><span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> spark</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-color-text)">read</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">format</span><span style="color:var(--shiki-token-punctuation)">(</span><span style="color:var(--shiki-token-string-expression)">&quot;csv&quot;</span><span style="color:var(--shiki-token-punctuation)">).</span><span style="color:var(--shiki-token-function)">load</span><span style="color:var(--shiki-token-punctuation)">(in_path)</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">bad_user_rows </span><span style="color:var(--shiki-token-keyword)">=</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">  users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">filter</span><span style="color:var(--shiki-token-punctuation)">(</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">    </span><span style="color:var(--shiki-token-string-expression)">&quot;length(email) &gt; 100 OR username IS NULL&quot;</span></span>
<span class="line"><span style="color:var(--shiki-token-punctuation)">  )</span></span>
<span class="line"><span style="color:var(--shiki-color-text)">users_df </span><span style="color:var(--shiki-token-keyword)">=</span><span style="color:var(--shiki-color-text)"> users_df</span><span style="color:var(--shiki-token-punctuation)">.</span><span style="color:var(--shiki-token-function)">subtract</span><span style="color:var(--shiki-token-punctuation)">(bad_user_rows)</span></span></code></pre><div class="nx-opacity-0 nx-transition [div:hover&gt;&amp;]:nx-opacity-100 focus-within:nx-opacity-100 nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0 nx-top-0"><button class="nextra-button nx-transition-all active:nx-opacity-50 nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5 dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50 md:nx-hidden" title="Toggle word wrap"><svg viewBox="0 0 24 24" width="24" height="24" class="nx-pointer-events-none nx-h-4 nx-w-4"><path fill="currentColor" d="M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"></path></svg></button></div></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="nx-my-2">On peut créer des <strong>jobs configurables</strong> : l’orchestration layer lance un job, en lui donnant d’abord la configuration contenant les sources à traiter, le schéma à valider en fonction des sources, la folder structure où insérer les nouveaux fichiers etc.<!-- -->
<ul class="nx-mt-6 nx-list-disc first:nx-mt-0 ltr:nx-ml-6 rtl:nx-mr-6">
<li class="nx-my-2">Ça permet d’économiser du code, au moins pour les jobs de transformation “common”.</li>
<li class="nx-my-2">Le bon endroit pour la configuration c’est le <em>metadata layer</em>.</li>
<li class="nx-my-2">Pour déclencher nos jobs, il faut qu’il y ait une forme de monitoring de la <em>landing area</em>, soit avec du code qu’on écrit nous-mêmes, soit avec la fonctionnalité de monitoring d’un outil d’orchestration cloud.</li>
</ul>
</li>
</ul><div class="nx-mt-16"></div><div class="nx-mb-8 nx-flex nx-items-center nx-border-t nx-pt-8 dark:nx-border-neutral-800 contrast-more:nx-border-neutral-400 dark:contrast-more:nx-border-neutral-400 print:nx-hidden"><a title="Continuous Discovery Habits" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-pr-4 rtl:nx-pl-4" href="/reading-notes/books/continuous-discovery-habits/"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 ltr:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>Continuous Discovery Habits</a><a title="Designing Data-Intensive Applications" class="nx-flex nx-max-w-[50%] nx-items-center nx-gap-1 nx-py-4 nx-text-base nx-font-medium nx-text-gray-600 nx-transition-colors [word-break:break-word] hover:nx-text-primary-600 dark:nx-text-gray-300 md:nx-text-lg ltr:nx-ml-auto ltr:nx-pl-4 ltr:nx-text-right rtl:nx-mr-auto rtl:nx-pr-4 rtl:nx-text-left" href="/reading-notes/books/designing-data-intensive-applications/">Designing Data-Intensive Applications<svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="nx-inline nx-h-5 nx-shrink-0 rtl:nx-rotate-180"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg></a></div></main></article></div><footer class="nx-bg-gray-100 nx-pb-[env(safe-area-inset-bottom)] dark:nx-bg-neutral-900 print:nx-bg-transparent"><div class="nx-mx-auto nx-flex nx-max-w-[90rem] nx-gap-2 nx-py-2 nx-px-4 nx-hidden"><button title="Change theme" class="nx-h-7 nx-rounded-md nx-px-2 nx-text-left nx-text-xs nx-font-medium nx-text-gray-600 nx-transition-colors dark:nx-text-gray-400 hover:nx-bg-gray-100 hover:nx-text-gray-900 dark:hover:nx-bg-primary-100/5 dark:hover:nx-text-gray-50" id="headlessui-listbox-button-:Rkt6:" type="button" aria-haspopup="listbox" aria-expanded="false" data-headlessui-state=""><div class="nx-flex nx-items-center nx-gap-2 nx-capitalize"><svg fill="none" viewBox="3 3 18 18" width="12" height="12" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" fill="currentColor" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path></svg><span class="">Light</span></div></button></div><hr class="dark:nx-border-neutral-800"/><div class="nx-mx-auto nx-flex nx-max-w-[90rem] nx-justify-center nx-py-12 nx-text-gray-600 dark:nx-text-gray-400 md:nx-justify-start nx-pl-[max(env(safe-area-inset-left),1.5rem)] nx-pr-[max(env(safe-area-inset-right),1.5rem)]">Made by Roman Mkrtchian</div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/books/designing-cloud-data-platforms","query":{},"buildId":"kDVEfpXkzKEZdtDkMyubK","assetPrefix":"/reading-notes","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>